{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Agricultural Crop (Paddy) Disease Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrieDWICn9S-"
   },
   "source": [
    "##### **Introduction:**\n",
    "\n",
    "Image classification has long been one of the standard tasks for benchmarking the performances of alogrithms in computer vision. In the past decade, variants of deep Convolutional Neural Network (CNN) like VGGNet, Inception, ResNet, etc. have made extraordinary success within the field. While for another mainstream in deep learning dealing with natural language, attention and bidirectional encoding mechanisms adopted in Transformer has tremendously driven a shift in the mainstream applications of language models. Several years before researchers have investigated implanting the Transformer design into the computer vision task, giving rise to the families of Vision Transformer (ViT) models. \n",
    "\n",
    "Below project aimed to classify the diseases appeared in the paddy (a common agricultural crop in South and South-east Asia as a main staple. 9 disease classes and 1 class reserved as normal class were annotated on over 10,000 images in the dataset. From below 10 images per class were sampled in random and visualized through openCV. The images were generally looking similar and quite challenging to be distinguished through human eyes. \n",
    "\n",
    "<br>\n",
    "\n",
    "There were 3 models being tested: <br>\n",
    "\n",
    "<ol>\n",
    "<li>a Inception-ResNet model, which could customize the depth of residual convolution blocks and in between each sequence of these blocks, an inception convolution block would be used to down-sample the image pixels;  </li><br>\n",
    "<li>a Vision Transformer model, with the standard components of Transformer encoder and a MLP head feed forward network to project the features to the 10 classes. </li><br>\n",
    "<li>a convolution and pooling based Vision Transformer model, with all dense layer operations in the Transformer encoder and subsequent pooling layer replaced by 2D-convolution layer operations. </li><br>\n",
    "</ol>\n",
    "\n",
    "The idea of Vision Transformer is to partition the image into patches of smaller sizes. These patches contained the spatial sequential and proximity information of the pixels in an image, like words within a sentence or paragraph. Then, the patches would be arranged in order, and padded with positional embeddings, to be fed into the multi-head attention layer. The output from the attention layer would be passed to feed-forward network to proceed with the classification training.\n",
    "\n",
    "The Vision Transformers codes were referred from the following github repo:  <a href=\"https://github.com/lucidrains/vit-pytorch\">https://github.com/lucidrains/vit-pytorch</a>,  while for the convolution-based vision transformer model (the 3rd model), the codes were modified in this notebook to combine the ideas in Cvt and PiT models.\n",
    "\n",
    "Results had shown that the Inception-ResNet, though adding more dropout rates and having the fewest parameters compared to the two Vision Transformers, severely overfitted. It simply failed to learn the key features from the images of high similarity, with a 19% accuracy on the testing set. The Vision Transformer, on the other hand, had much milder overfitting problem, and achieved much higher accuracy of 75% (convolution-based) and 82% (standard ViT) on the testing set.\n",
    "\n",
    "To explain this, generally the attention mechanism in the Vision Transformers might have inspiringly been able to capture tiny and hard-to-recognize features from the images, and hence boosting the performance of the model to classify the disease classes.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wSNFbzBLAhyM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import math\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FSrGe9rtC9C-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vlAO4pypBbkt"
   },
   "outputs": [],
   "source": [
    "## Add configuration\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp '/content/drive/MyDrive/Colab Notebooks/kaggle.json' ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8l0ZMuiBpmk",
    "outputId": "0eb7e5d8-b7ba-499f-8cf4-072bd7555f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading paddy-disease-classification.zip to /content\n",
      "100% 1.02G/1.02G [00:42<00:00, 51.9MB/s]\n",
      "100% 1.02G/1.02G [00:42<00:00, 25.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "## Download dataset from Kaggle\n",
    "!kaggle competitions download -c paddy-disease-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JV_jzAm4DYFU"
   },
   "outputs": [],
   "source": [
    "!unzip paddy-disease-classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OYWwlVqVBp7E"
   },
   "outputs": [],
   "source": [
    "## image dataloader\n",
    "img_norm = transforms.Compose([\n",
    "           transforms.Resize((640,480)),\n",
    "           transforms.ToTensor()\n",
    "           ])\n",
    "train_data = datasets.ImageFolder(root = \"/content/train_images/\", transform = img_norm)\n",
    "train_data_loader = DataLoader(train_data, batch_size = 16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-02T11:40:12.480732Z",
     "iopub.status.busy": "2022-07-02T11:40:12.480385Z",
     "iopub.status.idle": "2022-07-02T11:40:12.498861Z",
     "shell.execute_reply": "2022-07-02T11:40:12.497706Z",
     "shell.execute_reply.started": "2022-07-02T11:40:12.480703Z"
    },
    "id": "pyOXjzBNTNNF",
    "outputId": "a7cfba59-684f-4768-fda0-6e1e54a192df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 10407\n",
      "Number of Classes: 10\n",
      "Image Shape: torch.Size([3, 640, 480])\n"
     ]
    }
   ],
   "source": [
    "## check image dataset\n",
    "img, _ = train_data[0]\n",
    "print(\"Number of Images: \" + str(len(train_data)))\n",
    "print(\"Number of Classes: \" + str(len(train_data.classes)))\n",
    "print(\"Image Shape: \" + str(img.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-30T17:57:56.947307Z",
     "iopub.status.busy": "2022-06-30T17:57:56.946931Z",
     "iopub.status.idle": "2022-06-30T17:57:56.959216Z",
     "shell.execute_reply": "2022-06-30T17:57:56.958078Z",
     "shell.execute_reply.started": "2022-06-30T17:57:56.947276Z"
    },
    "id": "-YwyXptCTNNG",
    "outputId": "cf22b330-48a2-44e1-8947-e8f289a771c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bacterial_leaf_blight', 479),\n",
       " ('bacterial_leaf_streak', 380),\n",
       " ('bacterial_panicle_blight', 337),\n",
       " ('blast', 1738),\n",
       " ('brown_spot', 965),\n",
       " ('dead_heart', 1442),\n",
       " ('downy_mildew', 620),\n",
       " ('hispa', 1594),\n",
       " ('normal', 1764),\n",
       " ('tungro', 1088)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## number of images per class\n",
    "[(x, y[1]) for x, y in zip(train_data.classes, list(collections.Counter(train_data.targets).items()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T10:48:22.354063Z",
     "iopub.status.busy": "2022-07-02T10:48:22.352901Z",
     "iopub.status.idle": "2022-07-02T11:02:49.238850Z",
     "shell.execute_reply": "2022-07-02T11:02:49.237800Z",
     "shell.execute_reply.started": "2022-07-02T10:48:22.354012Z"
    },
    "id": "ICiyF8EITNNH"
   },
   "outputs": [],
   "source": [
    "query_pos = [[pos for pos, (x, y) in enumerate(train_data) if y == n] for n in range(len(train_data.classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-02T11:09:54.115311Z",
     "iopub.status.busy": "2022-07-02T11:09:54.114326Z",
     "iopub.status.idle": "2022-07-02T11:09:54.121002Z",
     "shell.execute_reply": "2022-07-02T11:09:54.119817Z",
     "shell.execute_reply.started": "2022-07-02T11:09:54.115257Z"
    },
    "id": "i5F9ZF-VTNNI",
    "outputId": "4ec591f4-1929-45db-978f-d6c15ecc8c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[479, 380, 337, 1738, 965, 1442, 620, 1594, 1764, 1088]\n"
     ]
    }
   ],
   "source": [
    "print(len(query_pos))\n",
    "print([len(x) for x in query_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T11:54:20.320803Z",
     "iopub.status.busy": "2022-07-04T11:54:20.320303Z",
     "iopub.status.idle": "2022-07-04T11:54:20.327380Z",
     "shell.execute_reply": "2022-07-04T11:54:20.326318Z",
     "shell.execute_reply.started": "2022-07-04T11:54:20.320756Z"
    },
    "id": "tCutyQocTNNM"
   },
   "outputs": [],
   "source": [
    "## set class weight for class imbalance\n",
    "class_weights = list(collections.Counter(train_data.targets).items())\n",
    "class_weights = torch.Tensor([c[1] for c in class_weights])\n",
    "class_weights_norm = 1 / (class_weights / torch.max(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-01T18:39:23.610504Z",
     "iopub.status.busy": "2022-07-01T18:39:23.609500Z",
     "iopub.status.idle": "2022-07-01T18:39:23.617479Z",
     "shell.execute_reply": "2022-07-01T18:39:23.616309Z",
     "shell.execute_reply.started": "2022-07-01T18:39:23.610466Z"
    },
    "id": "SFVYTiVoTNNN",
    "outputId": "1aa36611-d8e4-4d1d-9c9f-8a66c7750eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 479.,  380.,  337., 1738.,  965., 1442.,  620., 1594., 1764., 1088.])\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-02T14:08:15.285184Z",
     "iopub.status.busy": "2022-07-02T14:08:15.284520Z",
     "iopub.status.idle": "2022-07-02T14:08:15.291454Z",
     "shell.execute_reply": "2022-07-02T14:08:15.290316Z",
     "shell.execute_reply.started": "2022-07-02T14:08:15.285148Z"
    },
    "id": "f3ZyM6DHTNNO",
    "outputId": "a2869a9a-a62a-4bb3-8e4b-b468885db3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6827, 4.6421, 5.2344, 1.0150, 1.8280, 1.2233, 2.8452, 1.1066, 1.0000,\n",
      "        1.6213])\n"
     ]
    }
   ],
   "source": [
    "print(class_weights_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QDUPw7IBx5c",
    "outputId": "ece819b8-e279-4a93-92ac-d47a34927627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting einops\n",
      "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pg0c8Plb9FBY"
   },
   "outputs": [],
   "source": [
    "## Inception ResNet\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(dim_in, dim_out, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2a = nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=4, padding=1)\n",
    "        self.conv2b = nn.Conv2d(dim_out, dim_out * 4, kernel_size=3, stride=4, padding=1)\n",
    "        self.conv2c = nn.Conv2d(dim_out * 4, dim_out, kernel_size=1, stride=1, padding=0)\n",
    "        self.postconv = nn.Conv2d(dim_out * 3, dim_out, kernel_size=1, stride=1, padding=0)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=4, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(dim_out)\n",
    "        self.act = nn.LeakyReLU()\n",
    "    def forward(self, x):\n",
    "        x1 = self.maxpool(self.act(self.bn(self.conv1(x))))\n",
    "        x2 = self.act(self.bn(self.conv2a(x)))\n",
    "        x3 = self.act(self.bn(self.conv2c(self.conv2b(self.conv1(x)))))\n",
    "        x = torch.cat((x1, x2, x3), 1)\n",
    "        x = self.act(self.bn(self.postconv(x)))\n",
    "        return x\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(dim_in, dim_out, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(dim_out, dim_in, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn = nn.BatchNorm2d(dim_in)\n",
    "        self.act = nn.LeakyReLU()\n",
    "    def forward(self, x):\n",
    "        x_re = self.conv3(self.conv2(self.conv1(x)))\n",
    "        x_re = self.act(self.bn(x_re))\n",
    "        x = torch.add(x, x_re)\n",
    "        return x\n",
    "\n",
    "class InceptionResNet(nn.Module):\n",
    "    def __init__(self, depth, res_depth, dim_in, dim_out, height, width, nclass):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.nclass = nclass\n",
    "        self.res_depth = res_depth\n",
    "        self.height, self.width = height, width\n",
    "        self.out_height = self.height // (4 ** self.depth) \\\n",
    "                            if self.height % (4 ** self.depth) == 0 \\\n",
    "                            else self.height // (4 ** self.depth) + 1\n",
    "        self.out_width = self.width // (4 ** self.depth) \\\n",
    "                            if self.width % (4 ** self.depth) == 0 \\\n",
    "                            else self.width // (4 ** self.depth) + 1\n",
    "\n",
    "        self.conv_in = nn.Conv2d(dim_in, dim_out, kernel_size=1, stride=1, padding=0)\n",
    "        dim_in, dim_out = dim_out, dim_out\n",
    "        layers = nn.ModuleList([])\n",
    "        for n in range(self.depth):\n",
    "            for m in range(self.res_depth):\n",
    "                layers.append(ResBlock(dim_in, dim_out * 2))\n",
    "            layers.append(InceptionBlock(dim_in, dim_out * 4))\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            dim_in, dim_out = dim_out * 4, dim_out * 4\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.dense1 = nn.Linear(dim_out * self.out_height * self.out_width, self.out_height * self.out_width)\n",
    "        self.dense2 = nn.Linear(self.out_height * self.out_width, self.nclass)\n",
    "        self.bn = nn.BatchNorm1d(self.out_height * self.out_width)\n",
    "        self.act = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.bn(self.dense1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "00rPyDepISvw"
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionResNet(depth=3, res_depth=2, dim_in=3, dim_out=8, height=640, width=480, nclass=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AWkLYdQMTNCS"
   },
   "outputs": [],
   "source": [
    "cnn_model = cnn_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:37:47.116887Z",
     "iopub.status.busy": "2022-07-02T13:37:47.116532Z",
     "iopub.status.idle": "2022-07-02T13:37:47.145329Z",
     "shell.execute_reply": "2022-07-02T13:37:47.144096Z",
     "shell.execute_reply.started": "2022-07-02T13:37:47.116855Z"
    },
    "id": "SX3jPWAbTNNP"
   },
   "outputs": [],
   "source": [
    "## Vision-Transformer\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "## Dense layer for outputting Attention vectors\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "## Multi-head Transformer Attention module\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "        \n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## map and split\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        ## 3-dim to 4-dim and reshape\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "        ## dot product\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "        ## attention\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "        ## attention output and v\n",
    "        out = torch.matmul(attn, v)\n",
    "        ## reshape 4-dim to 3-dim and dense output\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "## Transformer Encoder\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "## Projected patch embedding -> Positional Embedding -> Transformer Encoder -> MLP head\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', \n",
    "                 channels = 3, dim_head = 64, dropout = 0.1, emb_dropout = 0.01):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        \n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "        )\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:37:51.078856Z",
     "iopub.status.busy": "2022-07-02T13:37:51.078441Z",
     "iopub.status.idle": "2022-07-02T13:37:51.442170Z",
     "shell.execute_reply": "2022-07-02T13:37:51.441191Z",
     "shell.execute_reply.started": "2022-07-02T13:37:51.078819Z"
    },
    "id": "tsHWzGnpTNNR"
   },
   "outputs": [],
   "source": [
    "vit_model = ViT(\n",
    "    image_size = (640, 480),\n",
    "    patch_size = 32,\n",
    "    num_classes = 10,\n",
    "    dim = 1024,\n",
    "    depth = 5,\n",
    "    heads = 10,\n",
    "    dim_head = 128,\n",
    "    mlp_dim = 2048,\n",
    "    pool = 'cls', \n",
    "    channels = 3, \n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:37:54.525412Z",
     "iopub.status.busy": "2022-07-02T13:37:54.525020Z",
     "iopub.status.idle": "2022-07-02T13:37:54.581350Z",
     "shell.execute_reply": "2022-07-02T13:37:54.580349Z",
     "shell.execute_reply.started": "2022-07-02T13:37:54.525379Z"
    },
    "id": "xhMSMwqNTNNS"
   },
   "outputs": [],
   "source": [
    "vit_model = vit_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T11:54:40.225639Z",
     "iopub.status.busy": "2022-07-04T11:54:40.225228Z",
     "iopub.status.idle": "2022-07-04T11:54:40.281799Z",
     "shell.execute_reply": "2022-07-04T11:54:40.280771Z",
     "shell.execute_reply.started": "2022-07-04T11:54:40.225600Z"
    },
    "id": "AgdDY9VgTNNT"
   },
   "outputs": [],
   "source": [
    "## Convolution-based Vision-Transformer\n",
    "\n",
    "from math import sqrt\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import torch.nn.functional as F\n",
    "from fractions import Fraction\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "def cast_tuple(val, num):\n",
    "    return val if isinstance(val, tuple) else (val,) * num\n",
    "\n",
    "def conv_output_size(image_size, kernel_size, stride, padding = 0):\n",
    "    return int(((image_size - kernel_size + (2 * padding)) / stride) + 1)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
    "        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n",
    "    def forward(self, x):\n",
    "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
    "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
    "        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x, **kwargs)\n",
    "    \n",
    "# depthwise convolution, for attention-projection & token-pooling\n",
    "class DepthWiseConv2d(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, kernel_size, padding, stride, bias = True):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size = kernel_size, stride = stride, \n",
    "                      padding = padding, groups = dim_in, bias = bias),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size = 1, bias = bias)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, aspect_ratio, hidden_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.aspect_ratio = aspect_ratio\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim, hidden_dim, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(hidden_dim, dim, 1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, aspect_ratio, proj_kernel, heads = 8, dim_head = 64, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        padding = proj_kernel // 2\n",
    "        self.aspect_ratio = aspect_ratio\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.to_q = DepthWiseConv2d(dim, inner_dim, proj_kernel, padding = padding, stride = 1, bias = False)\n",
    "        self.to_kv = DepthWiseConv2d(dim, inner_dim * 2, proj_kernel, padding = padding, stride = 1, bias = False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Conv2d(inner_dim, dim, 1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## split along first dimension into 3 tensors\n",
    "        b, n, _, y, h = *x.shape, self.heads\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(x).chunk(2, dim = 1))\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b (h d) x y -> (b h) (x y) d', h = h), (q, k, v))\n",
    "        \n",
    "        dots = torch.einsum('b i d, b j d -> b i j', q, k) * self.scale\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        out = torch.einsum('b i j, b j d -> b i d', attn, v)\n",
    "        out = rearrange(out, '(b h) (x y) d -> b (h d) x y', h = h, y = y)\n",
    "        out = self.to_out(out)\n",
    "        return out\n",
    "\n",
    "## Transformer Encoder\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, aspect_ratio, proj_kernel, depth, heads, dim_head, mlp_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, aspect_ratio, \n",
    "                                       proj_kernel = proj_kernel, \n",
    "                                       heads = heads, \n",
    "                                       dim_head = dim_head, \n",
    "                                       dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, aspect_ratio, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "    \n",
    "## Pooling layer\n",
    "class Pool(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.downsample = DepthWiseConv2d(dim, dim * 2, kernel_size = 3, stride = 2, padding = 1)\n",
    "    def forward(self, x):\n",
    "        tokens = self.downsample(x)\n",
    "        return tokens\n",
    "\n",
    "class PoolConViT(nn.Module):\n",
    "    def __init__(\n",
    "        self, *,\n",
    "        image_size,\n",
    "        patch_size,\n",
    "        num_classes,\n",
    "        proj_kernel = 3, \n",
    "        dim = 256,\n",
    "        depth = (3, 3, 3), \n",
    "        heads = 10,\n",
    "        mlp_dim = 2048,\n",
    "        dim_head = 64,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.01,\n",
    "        channels = 3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        heads = cast_tuple(heads, len(depth))\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        aspect_ratio = image_height / image_width\n",
    "\n",
    "        unfold_height = image_height // (patch_size // 2)\n",
    "        unfold_width = image_width // (patch_size // 2)\n",
    "        output_height_size = conv_output_size(image_height, patch_height, patch_height // 2)\n",
    "        output_width_size = conv_output_size(image_width, patch_width, patch_width // 2)\n",
    "        num_patches = output_height_size * output_width_size\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            nn.Unfold(kernel_size = patch_size, stride = patch_size // 2),\n",
    "            Rearrange('b n c -> b c n'),\n",
    "            nn.Linear(patch_dim, dim * heads[0])\n",
    "        )\n",
    "        \n",
    "        self.pre_encoder_head = nn.Sequential(\n",
    "            nn.Linear(dim * heads[0], dim),\n",
    "            Rearrange('b c n -> b n c'),\n",
    "            nn.Linear(num_patches + 1, unfold_height * unfold_width),\n",
    "            Rearrange('b c (m n) -> b c m n', m = unfold_height)\n",
    "        )\n",
    "        \n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim * heads[0]))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim * heads[0]))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        layers = []\n",
    "        aspect_height = unfold_height\n",
    "        for ind, (layer_depth, layer_heads) in enumerate(zip(depth, heads)):\n",
    "            not_last = ind < (len(depth) - 1)\n",
    "            layers.append(Transformer(dim, aspect_ratio, \n",
    "                                      proj_kernel, layer_depth, \n",
    "                                      layer_heads, dim_head, mlp_dim, dropout))\n",
    "            if not_last:\n",
    "                layers.append(Pool(dim))\n",
    "                dim *= 2\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.mlp_head = nn.Sequential(\n",
    "            Rearrange('b c m n -> b (c m n)'),\n",
    "            nn.Linear(dim * \\\n",
    "                      math.ceil(unfold_height / (2 ** (len(depth) - 1))) * \\\n",
    "                      math.ceil(unfold_width / (2 ** (len(depth) - 1))), \n",
    "                      num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n+1)]\n",
    "        x = self.dropout(x)\n",
    "        x = self.pre_encoder_head(x)\n",
    "        x = self.layers(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.mlp_head(x[:, 0])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T11:54:55.036508Z",
     "iopub.status.busy": "2022-07-04T11:54:55.035728Z",
     "iopub.status.idle": "2022-07-04T11:54:55.360308Z",
     "shell.execute_reply": "2022-07-04T11:54:55.359338Z",
     "shell.execute_reply.started": "2022-07-04T11:54:55.036465Z"
    },
    "id": "KofqZ2eGTNNV"
   },
   "outputs": [],
   "source": [
    "pcvit_model = PoolConViT(image_size = (640, 480), \n",
    "                         patch_size = 32,\n",
    "                         num_classes = 10,\n",
    "                         proj_kernel = 3,\n",
    "                         dim = 160,\n",
    "                         depth = (3, 3, 3), \n",
    "                         heads = 10,\n",
    "                         dim_head = 64,\n",
    "                         mlp_dim = 1600,\n",
    "                         dropout = 0.1,\n",
    "                         emb_dropout = 0.01,\n",
    "                         channels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T11:54:58.441762Z",
     "iopub.status.busy": "2022-07-04T11:54:58.440857Z",
     "iopub.status.idle": "2022-07-04T11:55:01.369334Z",
     "shell.execute_reply": "2022-07-04T11:55:01.368380Z",
     "shell.execute_reply.started": "2022-07-04T11:54:58.441726Z"
    },
    "id": "eR6FbLT9TNNY"
   },
   "outputs": [],
   "source": [
    "pcvit_model = pcvit_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKKmqS-NCIyl",
    "outputId": "72f6ab88-4ce2-4f14-c22e-f49580c4841d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lW4bDDaYTX_e",
    "outputId": "eca33975-fb10-4078-8452-9a2e29e503d6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 640, 480]              32\n",
      "            Conv2d-2         [-1, 16, 640, 480]             144\n",
      "            Conv2d-3         [-1, 16, 640, 480]           2,320\n",
      "            Conv2d-4          [-1, 8, 640, 480]             136\n",
      "       BatchNorm2d-5          [-1, 8, 640, 480]              16\n",
      "         LeakyReLU-6          [-1, 8, 640, 480]               0\n",
      "          ResBlock-7          [-1, 8, 640, 480]               0\n",
      "            Conv2d-8         [-1, 16, 640, 480]             144\n",
      "            Conv2d-9         [-1, 16, 640, 480]           2,320\n",
      "           Conv2d-10          [-1, 8, 640, 480]             136\n",
      "      BatchNorm2d-11          [-1, 8, 640, 480]              16\n",
      "        LeakyReLU-12          [-1, 8, 640, 480]               0\n",
      "         ResBlock-13          [-1, 8, 640, 480]               0\n",
      "           Conv2d-14         [-1, 32, 640, 480]             288\n",
      "      BatchNorm2d-15         [-1, 32, 640, 480]              64\n",
      "        LeakyReLU-16         [-1, 32, 640, 480]               0\n",
      "        MaxPool2d-17         [-1, 32, 160, 120]               0\n",
      "           Conv2d-18         [-1, 32, 160, 120]           2,336\n",
      "      BatchNorm2d-19         [-1, 32, 160, 120]              64\n",
      "        LeakyReLU-20         [-1, 32, 160, 120]               0\n",
      "           Conv2d-21         [-1, 32, 640, 480]             288\n",
      "           Conv2d-22        [-1, 128, 160, 120]          36,992\n",
      "           Conv2d-23         [-1, 32, 160, 120]           4,128\n",
      "      BatchNorm2d-24         [-1, 32, 160, 120]              64\n",
      "        LeakyReLU-25         [-1, 32, 160, 120]               0\n",
      "           Conv2d-26         [-1, 32, 160, 120]           3,104\n",
      "      BatchNorm2d-27         [-1, 32, 160, 120]              64\n",
      "        LeakyReLU-28         [-1, 32, 160, 120]               0\n",
      "   InceptionBlock-29         [-1, 32, 160, 120]               0\n",
      "          Dropout-30         [-1, 32, 160, 120]               0\n",
      "           Conv2d-31         [-1, 64, 160, 120]           2,112\n",
      "           Conv2d-32         [-1, 64, 160, 120]          36,928\n",
      "           Conv2d-33         [-1, 32, 160, 120]           2,080\n",
      "      BatchNorm2d-34         [-1, 32, 160, 120]              64\n",
      "        LeakyReLU-35         [-1, 32, 160, 120]               0\n",
      "         ResBlock-36         [-1, 32, 160, 120]               0\n",
      "           Conv2d-37         [-1, 64, 160, 120]           2,112\n",
      "           Conv2d-38         [-1, 64, 160, 120]          36,928\n",
      "           Conv2d-39         [-1, 32, 160, 120]           2,080\n",
      "      BatchNorm2d-40         [-1, 32, 160, 120]              64\n",
      "        LeakyReLU-41         [-1, 32, 160, 120]               0\n",
      "         ResBlock-42         [-1, 32, 160, 120]               0\n",
      "           Conv2d-43        [-1, 128, 160, 120]           4,224\n",
      "      BatchNorm2d-44        [-1, 128, 160, 120]             256\n",
      "        LeakyReLU-45        [-1, 128, 160, 120]               0\n",
      "        MaxPool2d-46          [-1, 128, 40, 30]               0\n",
      "           Conv2d-47          [-1, 128, 40, 30]          36,992\n",
      "      BatchNorm2d-48          [-1, 128, 40, 30]             256\n",
      "        LeakyReLU-49          [-1, 128, 40, 30]               0\n",
      "           Conv2d-50        [-1, 128, 160, 120]           4,224\n",
      "           Conv2d-51          [-1, 512, 40, 30]         590,336\n",
      "           Conv2d-52          [-1, 128, 40, 30]          65,664\n",
      "      BatchNorm2d-53          [-1, 128, 40, 30]             256\n",
      "        LeakyReLU-54          [-1, 128, 40, 30]               0\n",
      "           Conv2d-55          [-1, 128, 40, 30]          49,280\n",
      "      BatchNorm2d-56          [-1, 128, 40, 30]             256\n",
      "        LeakyReLU-57          [-1, 128, 40, 30]               0\n",
      "   InceptionBlock-58          [-1, 128, 40, 30]               0\n",
      "          Dropout-59          [-1, 128, 40, 30]               0\n",
      "           Conv2d-60          [-1, 256, 40, 30]          33,024\n",
      "           Conv2d-61          [-1, 256, 40, 30]         590,080\n",
      "           Conv2d-62          [-1, 128, 40, 30]          32,896\n",
      "      BatchNorm2d-63          [-1, 128, 40, 30]             256\n",
      "        LeakyReLU-64          [-1, 128, 40, 30]               0\n",
      "         ResBlock-65          [-1, 128, 40, 30]               0\n",
      "           Conv2d-66          [-1, 256, 40, 30]          33,024\n",
      "           Conv2d-67          [-1, 256, 40, 30]         590,080\n",
      "           Conv2d-68          [-1, 128, 40, 30]          32,896\n",
      "      BatchNorm2d-69          [-1, 128, 40, 30]             256\n",
      "        LeakyReLU-70          [-1, 128, 40, 30]               0\n",
      "         ResBlock-71          [-1, 128, 40, 30]               0\n",
      "           Conv2d-72          [-1, 512, 40, 30]          66,048\n",
      "      BatchNorm2d-73          [-1, 512, 40, 30]           1,024\n",
      "        LeakyReLU-74          [-1, 512, 40, 30]               0\n",
      "        MaxPool2d-75           [-1, 512, 10, 8]               0\n",
      "           Conv2d-76           [-1, 512, 10, 8]         590,336\n",
      "      BatchNorm2d-77           [-1, 512, 10, 8]           1,024\n",
      "        LeakyReLU-78           [-1, 512, 10, 8]               0\n",
      "           Conv2d-79          [-1, 512, 40, 30]          66,048\n",
      "           Conv2d-80          [-1, 2048, 10, 8]       9,439,232\n",
      "           Conv2d-81           [-1, 512, 10, 8]       1,049,088\n",
      "      BatchNorm2d-82           [-1, 512, 10, 8]           1,024\n",
      "        LeakyReLU-83           [-1, 512, 10, 8]               0\n",
      "           Conv2d-84           [-1, 512, 10, 8]         786,944\n",
      "      BatchNorm2d-85           [-1, 512, 10, 8]           1,024\n",
      "        LeakyReLU-86           [-1, 512, 10, 8]               0\n",
      "   InceptionBlock-87           [-1, 512, 10, 8]               0\n",
      "          Dropout-88           [-1, 512, 10, 8]               0\n",
      "          Flatten-89                [-1, 40960]               0\n",
      "          Dropout-90                [-1, 40960]               0\n",
      "           Linear-91                   [-1, 80]       3,276,880\n",
      "      BatchNorm1d-92                   [-1, 80]             160\n",
      "             ReLU-93                   [-1, 80]               0\n",
      "          Dropout-94                   [-1, 80]               0\n",
      "           Linear-95                   [-1, 10]             810\n",
      "================================================================\n",
      "Total params: 17,478,922\n",
      "Trainable params: 17,478,922\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.52\n",
      "Forward/backward pass size (MB): 905.63\n",
      "Params size (MB): 66.68\n",
      "Estimated Total Size (MB): 975.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(cnn_model, input_size = (3,640,480), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-02T10:11:44.332160Z",
     "iopub.status.busy": "2022-07-02T10:11:44.331728Z",
     "iopub.status.idle": "2022-07-02T10:11:44.372913Z",
     "shell.execute_reply": "2022-07-02T10:11:44.371709Z",
     "shell.execute_reply.started": "2022-07-02T10:11:44.332126Z"
    },
    "id": "8y3TKiSETNNY",
    "outputId": "f1a40cb1-7806-476d-e5cb-88a46acc3a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Rearrange-1            [-1, 300, 3072]               0\n",
      "            Linear-2            [-1, 300, 1024]       3,146,752\n",
      "           Dropout-3            [-1, 301, 1024]               0\n",
      "         LayerNorm-4            [-1, 301, 1024]           2,048\n",
      "            Linear-5            [-1, 301, 3840]       3,932,160\n",
      "           Softmax-6         [-1, 10, 301, 301]               0\n",
      "           Dropout-7         [-1, 10, 301, 301]               0\n",
      "            Linear-8            [-1, 301, 1024]       1,311,744\n",
      "           Dropout-9            [-1, 301, 1024]               0\n",
      "        Attention-10            [-1, 301, 1024]               0\n",
      "          PreNorm-11            [-1, 301, 1024]               0\n",
      "        LayerNorm-12            [-1, 301, 1024]           2,048\n",
      "           Linear-13            [-1, 301, 2048]       2,099,200\n",
      "             GELU-14            [-1, 301, 2048]               0\n",
      "          Dropout-15            [-1, 301, 2048]               0\n",
      "           Linear-16            [-1, 301, 1024]       2,098,176\n",
      "          Dropout-17            [-1, 301, 1024]               0\n",
      "      FeedForward-18            [-1, 301, 1024]               0\n",
      "          PreNorm-19            [-1, 301, 1024]               0\n",
      "        LayerNorm-20            [-1, 301, 1024]           2,048\n",
      "           Linear-21            [-1, 301, 3840]       3,932,160\n",
      "          Softmax-22         [-1, 10, 301, 301]               0\n",
      "          Dropout-23         [-1, 10, 301, 301]               0\n",
      "           Linear-24            [-1, 301, 1024]       1,311,744\n",
      "          Dropout-25            [-1, 301, 1024]               0\n",
      "        Attention-26            [-1, 301, 1024]               0\n",
      "          PreNorm-27            [-1, 301, 1024]               0\n",
      "        LayerNorm-28            [-1, 301, 1024]           2,048\n",
      "           Linear-29            [-1, 301, 2048]       2,099,200\n",
      "             GELU-30            [-1, 301, 2048]               0\n",
      "          Dropout-31            [-1, 301, 2048]               0\n",
      "           Linear-32            [-1, 301, 1024]       2,098,176\n",
      "          Dropout-33            [-1, 301, 1024]               0\n",
      "      FeedForward-34            [-1, 301, 1024]               0\n",
      "          PreNorm-35            [-1, 301, 1024]               0\n",
      "        LayerNorm-36            [-1, 301, 1024]           2,048\n",
      "           Linear-37            [-1, 301, 3840]       3,932,160\n",
      "          Softmax-38         [-1, 10, 301, 301]               0\n",
      "          Dropout-39         [-1, 10, 301, 301]               0\n",
      "           Linear-40            [-1, 301, 1024]       1,311,744\n",
      "          Dropout-41            [-1, 301, 1024]               0\n",
      "        Attention-42            [-1, 301, 1024]               0\n",
      "          PreNorm-43            [-1, 301, 1024]               0\n",
      "        LayerNorm-44            [-1, 301, 1024]           2,048\n",
      "           Linear-45            [-1, 301, 2048]       2,099,200\n",
      "             GELU-46            [-1, 301, 2048]               0\n",
      "          Dropout-47            [-1, 301, 2048]               0\n",
      "           Linear-48            [-1, 301, 1024]       2,098,176\n",
      "          Dropout-49            [-1, 301, 1024]               0\n",
      "      FeedForward-50            [-1, 301, 1024]               0\n",
      "          PreNorm-51            [-1, 301, 1024]               0\n",
      "        LayerNorm-52            [-1, 301, 1024]           2,048\n",
      "           Linear-53            [-1, 301, 3840]       3,932,160\n",
      "          Softmax-54         [-1, 10, 301, 301]               0\n",
      "          Dropout-55         [-1, 10, 301, 301]               0\n",
      "           Linear-56            [-1, 301, 1024]       1,311,744\n",
      "          Dropout-57            [-1, 301, 1024]               0\n",
      "        Attention-58            [-1, 301, 1024]               0\n",
      "          PreNorm-59            [-1, 301, 1024]               0\n",
      "        LayerNorm-60            [-1, 301, 1024]           2,048\n",
      "           Linear-61            [-1, 301, 2048]       2,099,200\n",
      "             GELU-62            [-1, 301, 2048]               0\n",
      "          Dropout-63            [-1, 301, 2048]               0\n",
      "           Linear-64            [-1, 301, 1024]       2,098,176\n",
      "          Dropout-65            [-1, 301, 1024]               0\n",
      "      FeedForward-66            [-1, 301, 1024]               0\n",
      "          PreNorm-67            [-1, 301, 1024]               0\n",
      "        LayerNorm-68            [-1, 301, 1024]           2,048\n",
      "           Linear-69            [-1, 301, 3840]       3,932,160\n",
      "          Softmax-70         [-1, 10, 301, 301]               0\n",
      "          Dropout-71         [-1, 10, 301, 301]               0\n",
      "           Linear-72            [-1, 301, 1024]       1,311,744\n",
      "          Dropout-73            [-1, 301, 1024]               0\n",
      "        Attention-74            [-1, 301, 1024]               0\n",
      "          PreNorm-75            [-1, 301, 1024]               0\n",
      "        LayerNorm-76            [-1, 301, 1024]           2,048\n",
      "           Linear-77            [-1, 301, 2048]       2,099,200\n",
      "             GELU-78            [-1, 301, 2048]               0\n",
      "          Dropout-79            [-1, 301, 2048]               0\n",
      "           Linear-80            [-1, 301, 1024]       2,098,176\n",
      "          Dropout-81            [-1, 301, 1024]               0\n",
      "      FeedForward-82            [-1, 301, 1024]               0\n",
      "          PreNorm-83            [-1, 301, 1024]               0\n",
      "      Transformer-84            [-1, 301, 1024]               0\n",
      "         Identity-85                 [-1, 1024]               0\n",
      "        LayerNorm-86                 [-1, 1024]           2,048\n",
      "           Linear-87                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 50,385,930\n",
      "Trainable params: 50,385,930\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.52\n",
      "Forward/backward pass size (MB): 315.43\n",
      "Params size (MB): 192.21\n",
      "Estimated Total Size (MB): 511.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(vit_model, input_size = (3,640,480), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Biunqe5TVsEB",
    "outputId": "4ceba09a-a6e3-4ff2-d2aa-238ede034bb5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Unfold-1           [-1, 3072, 1131]               0\n",
      "         Rearrange-2           [-1, 1131, 3072]               0\n",
      "            Linear-3           [-1, 1131, 1600]       4,916,800\n",
      "           Dropout-4           [-1, 1132, 1600]               0\n",
      "            Linear-5            [-1, 1132, 160]         256,160\n",
      "         Rearrange-6            [-1, 160, 1132]               0\n",
      "            Linear-7            [-1, 160, 1200]       1,359,600\n",
      "         Rearrange-8          [-1, 160, 40, 30]               0\n",
      "         LayerNorm-9          [-1, 160, 40, 30]               0\n",
      "           Conv2d-10          [-1, 640, 40, 30]           5,760\n",
      "           Conv2d-11          [-1, 640, 40, 30]         409,600\n",
      "  DepthWiseConv2d-12          [-1, 640, 40, 30]               0\n",
      "           Conv2d-13         [-1, 1280, 40, 30]          11,520\n",
      "           Conv2d-14         [-1, 1280, 40, 30]       1,638,400\n",
      "  DepthWiseConv2d-15         [-1, 1280, 40, 30]               0\n",
      "          Softmax-16           [-1, 1200, 1200]               0\n",
      "          Dropout-17           [-1, 1200, 1200]               0\n",
      "           Conv2d-18          [-1, 160, 40, 30]         102,560\n",
      "          Dropout-19          [-1, 160, 40, 30]               0\n",
      "        Attention-20          [-1, 160, 40, 30]               0\n",
      "          PreNorm-21          [-1, 160, 40, 30]               0\n",
      "        LayerNorm-22          [-1, 160, 40, 30]               0\n",
      "           Conv2d-23         [-1, 1600, 40, 30]         257,600\n",
      "             GELU-24         [-1, 1600, 40, 30]               0\n",
      "          Dropout-25         [-1, 1600, 40, 30]               0\n",
      "           Conv2d-26          [-1, 160, 40, 30]         256,160\n",
      "          Dropout-27          [-1, 160, 40, 30]               0\n",
      "      FeedForward-28          [-1, 160, 40, 30]               0\n",
      "          PreNorm-29          [-1, 160, 40, 30]               0\n",
      "        LayerNorm-30          [-1, 160, 40, 30]               0\n",
      "           Conv2d-31          [-1, 640, 40, 30]           5,760\n",
      "           Conv2d-32          [-1, 640, 40, 30]         409,600\n",
      "  DepthWiseConv2d-33          [-1, 640, 40, 30]               0\n",
      "           Conv2d-34         [-1, 1280, 40, 30]          11,520\n",
      "           Conv2d-35         [-1, 1280, 40, 30]       1,638,400\n",
      "  DepthWiseConv2d-36         [-1, 1280, 40, 30]               0\n",
      "          Softmax-37           [-1, 1200, 1200]               0\n",
      "          Dropout-38           [-1, 1200, 1200]               0\n",
      "           Conv2d-39          [-1, 160, 40, 30]         102,560\n",
      "          Dropout-40          [-1, 160, 40, 30]               0\n",
      "        Attention-41          [-1, 160, 40, 30]               0\n",
      "          PreNorm-42          [-1, 160, 40, 30]               0\n",
      "        LayerNorm-43          [-1, 160, 40, 30]               0\n",
      "           Conv2d-44         [-1, 1600, 40, 30]         257,600\n",
      "             GELU-45         [-1, 1600, 40, 30]               0\n",
      "          Dropout-46         [-1, 1600, 40, 30]               0\n",
      "           Conv2d-47          [-1, 160, 40, 30]         256,160\n",
      "          Dropout-48          [-1, 160, 40, 30]               0\n",
      "      FeedForward-49          [-1, 160, 40, 30]               0\n",
      "          PreNorm-50          [-1, 160, 40, 30]               0\n",
      "        LayerNorm-51          [-1, 160, 40, 30]               0\n",
      "           Conv2d-52          [-1, 640, 40, 30]           5,760\n",
      "           Conv2d-53          [-1, 640, 40, 30]         409,600\n",
      "  DepthWiseConv2d-54          [-1, 640, 40, 30]               0\n",
      "           Conv2d-55         [-1, 1280, 40, 30]          11,520\n",
      "           Conv2d-56         [-1, 1280, 40, 30]       1,638,400\n",
      "  DepthWiseConv2d-57         [-1, 1280, 40, 30]               0\n",
      "          Softmax-58           [-1, 1200, 1200]               0\n",
      "          Dropout-59           [-1, 1200, 1200]               0\n",
      "           Conv2d-60          [-1, 160, 40, 30]         102,560\n",
      "          Dropout-61          [-1, 160, 40, 30]               0\n",
      "        Attention-62          [-1, 160, 40, 30]               0\n",
      "          PreNorm-63          [-1, 160, 40, 30]               0\n",
      "        LayerNorm-64          [-1, 160, 40, 30]               0\n",
      "           Conv2d-65         [-1, 1600, 40, 30]         257,600\n",
      "             GELU-66         [-1, 1600, 40, 30]               0\n",
      "          Dropout-67         [-1, 1600, 40, 30]               0\n",
      "           Conv2d-68          [-1, 160, 40, 30]         256,160\n",
      "          Dropout-69          [-1, 160, 40, 30]               0\n",
      "      FeedForward-70          [-1, 160, 40, 30]               0\n",
      "          PreNorm-71          [-1, 160, 40, 30]               0\n",
      "      Transformer-72          [-1, 160, 40, 30]               0\n",
      "           Conv2d-73          [-1, 320, 20, 15]           3,200\n",
      "           Conv2d-74          [-1, 320, 20, 15]         102,720\n",
      "  DepthWiseConv2d-75          [-1, 320, 20, 15]               0\n",
      "             Pool-76          [-1, 320, 20, 15]               0\n",
      "        LayerNorm-77          [-1, 320, 20, 15]               0\n",
      "           Conv2d-78          [-1, 640, 20, 15]           5,760\n",
      "           Conv2d-79          [-1, 640, 20, 15]         409,600\n",
      "  DepthWiseConv2d-80          [-1, 640, 20, 15]               0\n",
      "           Conv2d-81         [-1, 1280, 20, 15]          11,520\n",
      "           Conv2d-82         [-1, 1280, 20, 15]       1,638,400\n",
      "  DepthWiseConv2d-83         [-1, 1280, 20, 15]               0\n",
      "          Softmax-84             [-1, 300, 300]               0\n",
      "          Dropout-85             [-1, 300, 300]               0\n",
      "           Conv2d-86          [-1, 320, 20, 15]         205,120\n",
      "          Dropout-87          [-1, 320, 20, 15]               0\n",
      "        Attention-88          [-1, 320, 20, 15]               0\n",
      "          PreNorm-89          [-1, 320, 20, 15]               0\n",
      "        LayerNorm-90          [-1, 320, 20, 15]               0\n",
      "           Conv2d-91         [-1, 1600, 20, 15]         513,600\n",
      "             GELU-92         [-1, 1600, 20, 15]               0\n",
      "          Dropout-93         [-1, 1600, 20, 15]               0\n",
      "           Conv2d-94          [-1, 320, 20, 15]         512,320\n",
      "          Dropout-95          [-1, 320, 20, 15]               0\n",
      "      FeedForward-96          [-1, 320, 20, 15]               0\n",
      "          PreNorm-97          [-1, 320, 20, 15]               0\n",
      "        LayerNorm-98          [-1, 320, 20, 15]               0\n",
      "           Conv2d-99          [-1, 640, 20, 15]           5,760\n",
      "          Conv2d-100          [-1, 640, 20, 15]         409,600\n",
      " DepthWiseConv2d-101          [-1, 640, 20, 15]               0\n",
      "          Conv2d-102         [-1, 1280, 20, 15]          11,520\n",
      "          Conv2d-103         [-1, 1280, 20, 15]       1,638,400\n",
      " DepthWiseConv2d-104         [-1, 1280, 20, 15]               0\n",
      "         Softmax-105             [-1, 300, 300]               0\n",
      "         Dropout-106             [-1, 300, 300]               0\n",
      "          Conv2d-107          [-1, 320, 20, 15]         205,120\n",
      "         Dropout-108          [-1, 320, 20, 15]               0\n",
      "       Attention-109          [-1, 320, 20, 15]               0\n",
      "         PreNorm-110          [-1, 320, 20, 15]               0\n",
      "       LayerNorm-111          [-1, 320, 20, 15]               0\n",
      "          Conv2d-112         [-1, 1600, 20, 15]         513,600\n",
      "            GELU-113         [-1, 1600, 20, 15]               0\n",
      "         Dropout-114         [-1, 1600, 20, 15]               0\n",
      "          Conv2d-115          [-1, 320, 20, 15]         512,320\n",
      "         Dropout-116          [-1, 320, 20, 15]               0\n",
      "     FeedForward-117          [-1, 320, 20, 15]               0\n",
      "         PreNorm-118          [-1, 320, 20, 15]               0\n",
      "       LayerNorm-119          [-1, 320, 20, 15]               0\n",
      "          Conv2d-120          [-1, 640, 20, 15]           5,760\n",
      "          Conv2d-121          [-1, 640, 20, 15]         409,600\n",
      " DepthWiseConv2d-122          [-1, 640, 20, 15]               0\n",
      "          Conv2d-123         [-1, 1280, 20, 15]          11,520\n",
      "          Conv2d-124         [-1, 1280, 20, 15]       1,638,400\n",
      " DepthWiseConv2d-125         [-1, 1280, 20, 15]               0\n",
      "         Softmax-126             [-1, 300, 300]               0\n",
      "         Dropout-127             [-1, 300, 300]               0\n",
      "          Conv2d-128          [-1, 320, 20, 15]         205,120\n",
      "         Dropout-129          [-1, 320, 20, 15]               0\n",
      "       Attention-130          [-1, 320, 20, 15]               0\n",
      "         PreNorm-131          [-1, 320, 20, 15]               0\n",
      "       LayerNorm-132          [-1, 320, 20, 15]               0\n",
      "          Conv2d-133         [-1, 1600, 20, 15]         513,600\n",
      "            GELU-134         [-1, 1600, 20, 15]               0\n",
      "         Dropout-135         [-1, 1600, 20, 15]               0\n",
      "          Conv2d-136          [-1, 320, 20, 15]         512,320\n",
      "         Dropout-137          [-1, 320, 20, 15]               0\n",
      "     FeedForward-138          [-1, 320, 20, 15]               0\n",
      "         PreNorm-139          [-1, 320, 20, 15]               0\n",
      "     Transformer-140          [-1, 320, 20, 15]               0\n",
      "          Conv2d-141           [-1, 640, 10, 8]           6,400\n",
      "          Conv2d-142           [-1, 640, 10, 8]         410,240\n",
      " DepthWiseConv2d-143           [-1, 640, 10, 8]               0\n",
      "            Pool-144           [-1, 640, 10, 8]               0\n",
      "       LayerNorm-145           [-1, 640, 10, 8]               0\n",
      "          Conv2d-146           [-1, 640, 10, 8]           5,760\n",
      "          Conv2d-147           [-1, 640, 10, 8]         409,600\n",
      " DepthWiseConv2d-148           [-1, 640, 10, 8]               0\n",
      "          Conv2d-149          [-1, 1280, 10, 8]          11,520\n",
      "          Conv2d-150          [-1, 1280, 10, 8]       1,638,400\n",
      " DepthWiseConv2d-151          [-1, 1280, 10, 8]               0\n",
      "         Softmax-152               [-1, 80, 80]               0\n",
      "         Dropout-153               [-1, 80, 80]               0\n",
      "          Conv2d-154           [-1, 640, 10, 8]         410,240\n",
      "         Dropout-155           [-1, 640, 10, 8]               0\n",
      "       Attention-156           [-1, 640, 10, 8]               0\n",
      "         PreNorm-157           [-1, 640, 10, 8]               0\n",
      "       LayerNorm-158           [-1, 640, 10, 8]               0\n",
      "          Conv2d-159          [-1, 1600, 10, 8]       1,025,600\n",
      "            GELU-160          [-1, 1600, 10, 8]               0\n",
      "         Dropout-161          [-1, 1600, 10, 8]               0\n",
      "          Conv2d-162           [-1, 640, 10, 8]       1,024,640\n",
      "         Dropout-163           [-1, 640, 10, 8]               0\n",
      "     FeedForward-164           [-1, 640, 10, 8]               0\n",
      "         PreNorm-165           [-1, 640, 10, 8]               0\n",
      "       LayerNorm-166           [-1, 640, 10, 8]               0\n",
      "          Conv2d-167           [-1, 640, 10, 8]           5,760\n",
      "          Conv2d-168           [-1, 640, 10, 8]         409,600\n",
      " DepthWiseConv2d-169           [-1, 640, 10, 8]               0\n",
      "          Conv2d-170          [-1, 1280, 10, 8]          11,520\n",
      "          Conv2d-171          [-1, 1280, 10, 8]       1,638,400\n",
      " DepthWiseConv2d-172          [-1, 1280, 10, 8]               0\n",
      "         Softmax-173               [-1, 80, 80]               0\n",
      "         Dropout-174               [-1, 80, 80]               0\n",
      "          Conv2d-175           [-1, 640, 10, 8]         410,240\n",
      "         Dropout-176           [-1, 640, 10, 8]               0\n",
      "       Attention-177           [-1, 640, 10, 8]               0\n",
      "         PreNorm-178           [-1, 640, 10, 8]               0\n",
      "       LayerNorm-179           [-1, 640, 10, 8]               0\n",
      "          Conv2d-180          [-1, 1600, 10, 8]       1,025,600\n",
      "            GELU-181          [-1, 1600, 10, 8]               0\n",
      "         Dropout-182          [-1, 1600, 10, 8]               0\n",
      "          Conv2d-183           [-1, 640, 10, 8]       1,024,640\n",
      "         Dropout-184           [-1, 640, 10, 8]               0\n",
      "     FeedForward-185           [-1, 640, 10, 8]               0\n",
      "         PreNorm-186           [-1, 640, 10, 8]               0\n",
      "       LayerNorm-187           [-1, 640, 10, 8]               0\n",
      "          Conv2d-188           [-1, 640, 10, 8]           5,760\n",
      "          Conv2d-189           [-1, 640, 10, 8]         409,600\n",
      " DepthWiseConv2d-190           [-1, 640, 10, 8]               0\n",
      "          Conv2d-191          [-1, 1280, 10, 8]          11,520\n",
      "          Conv2d-192          [-1, 1280, 10, 8]       1,638,400\n",
      " DepthWiseConv2d-193          [-1, 1280, 10, 8]               0\n",
      "         Softmax-194               [-1, 80, 80]               0\n",
      "         Dropout-195               [-1, 80, 80]               0\n",
      "          Conv2d-196           [-1, 640, 10, 8]         410,240\n",
      "         Dropout-197           [-1, 640, 10, 8]               0\n",
      "       Attention-198           [-1, 640, 10, 8]               0\n",
      "         PreNorm-199           [-1, 640, 10, 8]               0\n",
      "       LayerNorm-200           [-1, 640, 10, 8]               0\n",
      "          Conv2d-201          [-1, 1600, 10, 8]       1,025,600\n",
      "            GELU-202          [-1, 1600, 10, 8]               0\n",
      "         Dropout-203          [-1, 1600, 10, 8]               0\n",
      "          Conv2d-204           [-1, 640, 10, 8]       1,024,640\n",
      "         Dropout-205           [-1, 640, 10, 8]               0\n",
      "     FeedForward-206           [-1, 640, 10, 8]               0\n",
      "         PreNorm-207           [-1, 640, 10, 8]               0\n",
      "     Transformer-208           [-1, 640, 10, 8]               0\n",
      "       Rearrange-209                [-1, 51200]               0\n",
      "          Linear-210                   [-1, 10]         512,010\n",
      "================================================================\n",
      "Total params: 39,078,170\n",
      "Trainable params: 39,078,170\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.52\n",
      "Forward/backward pass size (MB): 623.66\n",
      "Params size (MB): 149.07\n",
      "Estimated Total Size (MB): 776.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(pcvit_model, input_size = (3,640,480), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T11:55:41.274903Z",
     "iopub.status.busy": "2022-07-04T11:55:41.274523Z",
     "iopub.status.idle": "2022-07-04T11:55:41.295459Z",
     "shell.execute_reply": "2022-07-04T11:55:41.294546Z",
     "shell.execute_reply.started": "2022-07-04T11:55:41.274871Z"
    },
    "id": "QyMgQFUBTNNZ"
   },
   "outputs": [],
   "source": [
    "def dataset_split(dataset, val_split=0.2, random_state=42):\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        list(range(len(dataset))), \n",
    "        test_size=val_split, \n",
    "        stratify=dataset.targets, \n",
    "        random_state=random_state)\n",
    "    datasets = {}\n",
    "    datasets['train'] = torch.utils.data.Subset(dataset, train_idx)\n",
    "    datasets['test'] = torch.utils.data.Subset(dataset, val_idx)\n",
    "    return datasets, (train_idx, val_idx)\n",
    "\n",
    "## splitting training and testing sets\n",
    "train_data, split_indx = dataset_split(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T05:22:53.808659Z",
     "iopub.status.busy": "2022-07-02T05:22:53.808109Z",
     "iopub.status.idle": "2022-07-02T05:22:53.814108Z",
     "shell.execute_reply": "2022-07-02T05:22:53.813151Z",
     "shell.execute_reply.started": "2022-07-02T05:22:53.808623Z"
    },
    "id": "l06zQUyVTNNZ"
   },
   "outputs": [],
   "source": [
    "print(len(train_data['train']))\n",
    "print(len(train_data['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T11:55:44.731544Z",
     "iopub.status.busy": "2022-07-04T11:55:44.730995Z",
     "iopub.status.idle": "2022-07-04T11:57:41.049878Z",
     "shell.execute_reply": "2022-07-04T11:57:41.048919Z",
     "shell.execute_reply.started": "2022-07-04T11:55:44.731505Z"
    },
    "id": "saAOLFMSTNNa"
   },
   "outputs": [],
   "source": [
    "def dataset_split(dataset, val_split=0.1, random_state=42):\n",
    "    y = [dataset[x][1] for x in range(len(dataset))]\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        list(range(len(dataset))), \n",
    "        test_size=val_split, \n",
    "        stratify=y, \n",
    "        random_state=random_state)\n",
    "    datasets = {}\n",
    "    datasets['train'] = torch.utils.data.Subset(dataset, train_idx)\n",
    "    datasets['val'] = torch.utils.data.Subset(dataset, val_idx)\n",
    "    return datasets\n",
    "\n",
    "## splitting validation set in training set\n",
    "train_ds = train_data['train']\n",
    "train_ds = dataset_split(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-02T05:24:01.444190Z",
     "iopub.status.busy": "2022-07-02T05:24:01.443794Z",
     "iopub.status.idle": "2022-07-02T05:24:01.449663Z",
     "shell.execute_reply": "2022-07-02T05:24:01.448621Z",
     "shell.execute_reply.started": "2022-07-02T05:24:01.444153Z"
    },
    "id": "Ddo7UBkiTNNa",
    "outputId": "4c6a41ef-178d-4cc8-bddc-b64a221b90c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7492\n",
      "833\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds['train']))\n",
    "print(len(train_ds['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T11:57:41.052354Z",
     "iopub.status.busy": "2022-07-04T11:57:41.052017Z",
     "iopub.status.idle": "2022-07-04T11:57:45.973939Z",
     "shell.execute_reply": "2022-07-04T11:57:45.972854Z",
     "shell.execute_reply.started": "2022-07-04T11:57:41.052321Z"
    },
    "id": "s468z6jgTNNa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class TrainingProcessor:\n",
    "    def __init__(self, train_data, model, epochs, batch_size=8, learning_rate=0.0001, scheduler=True, class_weights=None):\n",
    "        super(TrainingProcessor, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.batch_size = batch_size\n",
    "        self.traindataloader = DataLoader(self.train_data['train'], batch_size = self.batch_size, shuffle=True)\n",
    "        self.valdataloader = DataLoader(self.train_data['val'], batch_size = self.batch_size, shuffle=True)\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = self.learning_rate)\n",
    "        \n",
    "        if scheduler == True:\n",
    "            self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, mode='min', factor=0.5, patience=3, min_lr=5e-6\n",
    "            )\n",
    "        if class_weights != None:\n",
    "            self.class_weights = class_weights\n",
    "            \n",
    "    def loss(self, y_pred, y_true):\n",
    "        weights = torch.tensor(self.class_weights).cuda()\n",
    "        weighted_ce_loss = nn.CrossEntropyLoss(weight = weights)(y_pred, y_true)\n",
    "        return weighted_ce_loss\n",
    "    \n",
    "    def get_metrics(self, y_pred_tags, y_true_tags):\n",
    "        correct_pred = (y_pred_tags == y_true_tags).float()\n",
    "        accuracy = correct_pred.sum() / len(correct_pred)\n",
    "        y_pred_tags, y_true_tags = y_pred_tags.cpu().numpy(), y_true_tags.cpu().numpy()\n",
    "        precision = precision_score(y_pred_tags, y_true_tags, average=None)\n",
    "        recall = recall_score(y_pred_tags, y_true_tags, average=None)\n",
    "        F1 = f1_score(y_pred_tags, y_true_tags, average=None)\n",
    "        return accuracy.item(), np.mean(precision), np.mean(recall), np.mean(F1)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            evaluated_metrics = []\n",
    "            evaluated_loss = []\n",
    "            for i, (batch_x, batch_y) in enumerate(self.valdataloader):\n",
    "                ## iteration training\n",
    "                batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "                out = self.model(batch_x)\n",
    "                _, out_tags = torch.max(torch.log_softmax(out, dim = 1), dim = 1)\n",
    "                out_loss = self.loss(out, batch_y)\n",
    "                evaluated_loss.append(out_loss.item())\n",
    "                ## get metrics\n",
    "                accuracy, precision, recall, F1 = self.get_metrics(out_tags, batch_y)\n",
    "                evaluated_metrics.append([accuracy, precision, recall, F1])\n",
    "        return evaluated_loss, evaluated_metrics\n",
    "        \n",
    "    def train(self, start_epoch=0):\n",
    "        for epoch in range(start_epoch, self.epochs + start_epoch):\n",
    "            ## initialization\n",
    "            self.model.train()\n",
    "            metrics = []\n",
    "            for i, (batch_x, batch_y) in enumerate(self.traindataloader):\n",
    "                ## iteration training\n",
    "                batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(batch_x)\n",
    "                _, out_tags = torch.max(torch.log_softmax(out, dim = 1), dim = 1)\n",
    "                out_loss = self.loss(out, batch_y)\n",
    "                out_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                ## get metrics\n",
    "                accuracy, precision, recall, F1 = self.get_metrics(out_tags, batch_y)\n",
    "                metrics.append([accuracy, precision, recall, F1])\n",
    "            \n",
    "            val_loss, val_metrics = self.evaluate()\n",
    "            val_loss = np.mean(val_loss)\n",
    "            self.scheduler.step(val_loss)\n",
    "            val_accuracy, val_precision, val_recall, val_F1 = \\\n",
    "                np.mean([x[0] for x in val_metrics]), \\\n",
    "                np.mean([x[1] for x in val_metrics]), \\\n",
    "                np.mean([x[2] for x in val_metrics]), \\\n",
    "                np.mean([x[3] for x in val_metrics])\n",
    "            \n",
    "            train_loss = out_loss.item()\n",
    "            train_accuracy, train_precision, train_recall, train_F1 = \\\n",
    "                np.mean([x[0] for x in metrics]), \\\n",
    "                np.mean([x[1] for x in metrics]), \\\n",
    "                np.mean([x[2] for x in metrics]), \\\n",
    "                np.mean([x[3] for x in metrics])\n",
    "            \n",
    "            print(\"Epoch \" + str(epoch+1) + \" || \" + \\\n",
    "                  \"train_loss: {:.4f} val_loss: {:.4f} | \".format(train_loss, val_loss) + \\\n",
    "                  \"train_acc: {:.4f} val_acc: {:.4f} | \".format(train_accuracy, val_accuracy) + \\\n",
    "                  \"train_p: {:.4f} val_p: {:.4f} | \".format(train_precision, val_precision) + \\\n",
    "                  \"train_r: {:.4f} val_r: {:.4f} | \".format(train_recall, val_recall) + \\\n",
    "                  \"train_F1: {:.4f} val_F1: {:.4f} | \".format(train_F1, val_F1)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rW0S4uSoJtTW"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9dk98nKZsEdV"
   },
   "outputs": [],
   "source": [
    "cnn_dag = TrainingProcessor(train_data=train_ds, \n",
    "                            model=cnn_model, \n",
    "                            epochs=25, \n",
    "                            batch_size=16, \n",
    "                            learning_rate=1e-5, \n",
    "                            scheduler=True, \n",
    "                            class_weights=class_weights_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCgBCrNssEk-",
    "outputId": "8c1758f5-f552-4e6b-ce09-f05a8c4539e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || train_loss: 2.4609 val_loss: 4.9846 | train_acc: 0.1975 val_acc: 0.1639 | train_p: 0.1655 val_p: 0.1262 | train_r: 0.1491 val_r: 0.0294 | train_F1: 0.1346 val_F1: 0.0426 | \n",
      "Epoch 2 || train_loss: 2.3819 val_loss: 5.8422 | train_acc: 0.3386 val_acc: 0.1639 | train_p: 0.2840 val_p: 0.1277 | train_r: 0.2821 val_r: 0.0229 | train_F1: 0.2517 val_F1: 0.0372 | \n",
      "Epoch 3 || train_loss: 2.3030 val_loss: 5.4597 | train_acc: 0.4360 val_acc: 0.1816 | train_p: 0.3721 val_p: 0.1499 | train_r: 0.3822 val_r: 0.0441 | train_F1: 0.3406 val_F1: 0.0589 | \n",
      "Epoch 4 || train_loss: 1.9688 val_loss: 5.2524 | train_acc: 0.5181 val_acc: 0.1675 | train_p: 0.4479 val_p: 0.1372 | train_r: 0.4647 val_r: 0.0322 | train_F1: 0.4221 val_F1: 0.0463 | \n",
      "Epoch 5 || train_loss: 1.5794 val_loss: 5.3371 | train_acc: 0.5809 val_acc: 0.1816 | train_p: 0.5211 val_p: 0.1472 | train_r: 0.5341 val_r: 0.0447 | train_F1: 0.4913 val_F1: 0.0590 | \n",
      "Epoch 6 || train_loss: 1.4161 val_loss: 5.0423 | train_acc: 0.6366 val_acc: 0.1639 | train_p: 0.5673 val_p: 0.1253 | train_r: 0.5932 val_r: 0.0242 | train_F1: 0.5477 val_F1: 0.0387 | \n",
      "Epoch 7 || train_loss: 2.2559 val_loss: 5.0050 | train_acc: 0.6599 val_acc: 0.1639 | train_p: 0.5898 val_p: 0.1301 | train_r: 0.6160 val_r: 0.0255 | train_F1: 0.5697 val_F1: 0.0405 | \n",
      "Epoch 8 || train_loss: 1.7214 val_loss: 4.6084 | train_acc: 0.6839 val_acc: 0.1675 | train_p: 0.6114 val_p: 0.1344 | train_r: 0.6357 val_r: 0.0325 | train_F1: 0.5914 val_F1: 0.0464 | \n",
      "Epoch 9 || train_loss: 1.6537 val_loss: 4.3821 | train_acc: 0.7059 val_acc: 0.1710 | train_p: 0.6365 val_p: 0.1379 | train_r: 0.6614 val_r: 0.0420 | train_F1: 0.6192 val_F1: 0.0503 | \n",
      "Epoch 10 || train_loss: 2.0306 val_loss: 3.5746 | train_acc: 0.7336 val_acc: 0.1958 | train_p: 0.6659 val_p: 0.1587 | train_r: 0.6898 val_r: 0.0771 | train_F1: 0.6501 val_F1: 0.0774 | \n",
      "Epoch 11 || train_loss: 1.5289 val_loss: 3.7203 | train_acc: 0.7440 val_acc: 0.1792 | train_p: 0.6750 val_p: 0.1437 | train_r: 0.6979 val_r: 0.0588 | train_F1: 0.6596 val_F1: 0.0632 | \n",
      "Epoch 12 || train_loss: 0.6720 val_loss: 3.7142 | train_acc: 0.7712 val_acc: 0.1745 | train_p: 0.7097 val_p: 0.1399 | train_r: 0.7305 val_r: 0.0440 | train_F1: 0.6964 val_F1: 0.0523 | \n",
      "Epoch 13 || train_loss: 1.2812 val_loss: 3.3453 | train_acc: 0.7884 val_acc: 0.2087 | train_p: 0.7327 val_p: 0.1634 | train_r: 0.7508 val_r: 0.0954 | train_F1: 0.7176 val_F1: 0.0894 | \n",
      "Epoch 14 || train_loss: 1.1086 val_loss: 3.5336 | train_acc: 0.8053 val_acc: 0.1946 | train_p: 0.7471 val_p: 0.1509 | train_r: 0.7633 val_r: 0.0780 | train_F1: 0.7339 val_F1: 0.0743 | \n",
      "Epoch 15 || train_loss: 2.2989 val_loss: 3.4456 | train_acc: 0.8177 val_acc: 0.2241 | train_p: 0.7611 val_p: 0.1891 | train_r: 0.7761 val_r: 0.0945 | train_F1: 0.7483 val_F1: 0.1033 | \n",
      "Epoch 16 || train_loss: 1.2629 val_loss: 3.3307 | train_acc: 0.8309 val_acc: 0.2488 | train_p: 0.7785 val_p: 0.1945 | train_r: 0.7903 val_r: 0.1284 | train_F1: 0.7646 val_F1: 0.1247 | \n",
      "Epoch 17 || train_loss: 1.9414 val_loss: 3.4848 | train_acc: 0.8376 val_acc: 0.2099 | train_p: 0.7865 val_p: 0.1764 | train_r: 0.7968 val_r: 0.0896 | train_F1: 0.7729 val_F1: 0.0918 | \n",
      "Epoch 18 || train_loss: 1.1900 val_loss: 3.5234 | train_acc: 0.8617 val_acc: 0.2406 | train_p: 0.8156 val_p: 0.1992 | train_r: 0.8255 val_r: 0.1034 | train_F1: 0.8045 val_F1: 0.1147 | \n",
      "Epoch 19 || train_loss: 1.2301 val_loss: 3.1411 | train_acc: 0.8637 val_acc: 0.2465 | train_p: 0.8201 val_p: 0.1970 | train_r: 0.8308 val_r: 0.1335 | train_F1: 0.8086 val_F1: 0.1215 | \n",
      "Epoch 20 || train_loss: 0.6740 val_loss: 3.3341 | train_acc: 0.8717 val_acc: 0.1946 | train_p: 0.8220 val_p: 0.1535 | train_r: 0.8321 val_r: 0.0723 | train_F1: 0.8121 val_F1: 0.0701 | \n",
      "Epoch 21 || train_loss: 2.1905 val_loss: 3.3310 | train_acc: 0.8883 val_acc: 0.2264 | train_p: 0.8472 val_p: 0.1937 | train_r: 0.8566 val_r: 0.1029 | train_F1: 0.8386 val_F1: 0.1051 | \n",
      "Epoch 22 || train_loss: 1.0729 val_loss: 3.1994 | train_acc: 0.8890 val_acc: 0.1922 | train_p: 0.8524 val_p: 0.1549 | train_r: 0.8611 val_r: 0.0790 | train_F1: 0.8432 val_F1: 0.0770 | \n",
      "Epoch 23 || train_loss: 0.9962 val_loss: 3.1514 | train_acc: 0.8966 val_acc: 0.2064 | train_p: 0.8576 val_p: 0.1746 | train_r: 0.8678 val_r: 0.1005 | train_F1: 0.8503 val_F1: 0.0926 | \n",
      "Epoch 24 || train_loss: 0.8836 val_loss: 3.3027 | train_acc: 0.9006 val_acc: 0.2300 | train_p: 0.8581 val_p: 0.1869 | train_r: 0.8689 val_r: 0.1003 | train_F1: 0.8515 val_F1: 0.1045 | \n",
      "Epoch 25 || train_loss: 0.8916 val_loss: 3.3879 | train_acc: 0.9083 val_acc: 0.2052 | train_p: 0.8780 val_p: 0.1596 | train_r: 0.8851 val_r: 0.0688 | train_F1: 0.8699 val_F1: 0.0772 | \n"
     ]
    }
   ],
   "source": [
    "cnn_dag.train(start_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T05:27:03.009704Z",
     "iopub.status.idle": "2022-07-03T05:27:03.010458Z",
     "shell.execute_reply": "2022-07-03T05:27:03.010236Z",
     "shell.execute_reply.started": "2022-07-03T05:27:03.010210Z"
    },
    "id": "mdHg223gTNNb"
   },
   "outputs": [],
   "source": [
    "vit_dag = TrainingProcessor(train_data=train_ds, \n",
    "                            model=vit_model, \n",
    "                            epochs=50, \n",
    "                            batch_size=16, \n",
    "                            learning_rate=1e-4, \n",
    "                            scheduler=True, \n",
    "                            class_weights=class_weights_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-02T14:28:29.558777Z",
     "iopub.status.busy": "2022-07-02T14:28:29.558097Z",
     "iopub.status.idle": "2022-07-02T17:43:07.687488Z",
     "shell.execute_reply": "2022-07-02T17:43:07.683727Z",
     "shell.execute_reply.started": "2022-07-02T14:28:29.558737Z"
    },
    "id": "8ent8j9STNNb",
    "outputId": "d621a167-4425-45ed-df65-203e8c2dd063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || train_loss: 1.5637 val_loss: 1.8645 | train_acc: 0.2775 val_acc: 0.3715 | train_p: 0.2443 val_p: 0.3227 | train_r: 0.2138 val_r: 0.3019 | train_F1: 0.1975 val_F1 0.2757 | \n",
      "Epoch 2 || train_loss: 1.5533 val_loss: 1.7967 | train_acc: 0.3483 val_acc: 0.3314 | train_p: 0.2978 val_p: 0.2971 | train_r: 0.2890 val_r: 0.2530 | train_F1: 0.2598 val_F1 0.2425 | \n",
      "Epoch 3 || train_loss: 1.0114 val_loss: 1.6843 | train_acc: 0.4084 val_acc: 0.4009 | train_p: 0.3536 val_p: 0.3695 | train_r: 0.3456 val_r: 0.3446 | train_F1: 0.3152 val_F1 0.3190 | \n",
      "Epoch 4 || train_loss: 1.3637 val_loss: 1.6213 | train_acc: 0.4498 val_acc: 0.4882 | train_p: 0.3946 val_p: 0.4269 | train_r: 0.3900 val_r: 0.4126 | train_F1: 0.3561 val_F1 0.3871 | \n",
      "Epoch 5 || train_loss: 2.2374 val_loss: 1.4902 | train_acc: 0.4936 val_acc: 0.4988 | train_p: 0.4338 val_p: 0.4259 | train_r: 0.4293 val_r: 0.4304 | train_F1: 0.3956 val_F1 0.3988 | \n",
      "Epoch 6 || train_loss: 1.3471 val_loss: 1.4339 | train_acc: 0.5281 val_acc: 0.4965 | train_p: 0.4710 val_p: 0.4400 | train_r: 0.4736 val_r: 0.4536 | train_F1: 0.4366 val_F1 0.4123 | \n",
      "Epoch 7 || train_loss: 0.8688 val_loss: 1.5751 | train_acc: 0.5605 val_acc: 0.4705 | train_p: 0.5041 val_p: 0.4317 | train_r: 0.5036 val_r: 0.4183 | train_F1: 0.4687 val_F1 0.3895 | \n",
      "Epoch 8 || train_loss: 0.6636 val_loss: 1.2434 | train_acc: 0.6011 val_acc: 0.5884 | train_p: 0.5448 val_p: 0.5230 | train_r: 0.5477 val_r: 0.5273 | train_F1: 0.5116 val_F1 0.4949 | \n",
      "Epoch 9 || train_loss: 0.9354 val_loss: 1.2352 | train_acc: 0.6345 val_acc: 0.5566 | train_p: 0.5773 val_p: 0.4972 | train_r: 0.5885 val_r: 0.4993 | train_F1: 0.5477 val_F1 0.4644 | \n",
      "Epoch 10 || train_loss: 0.1590 val_loss: 1.2120 | train_acc: 0.6612 val_acc: 0.6085 | train_p: 0.6039 val_p: 0.5640 | train_r: 0.6091 val_r: 0.5654 | train_F1: 0.5748 val_F1 0.5319 | \n",
      "Epoch 11 || train_loss: 0.1388 val_loss: 1.2342 | train_acc: 0.6891 val_acc: 0.5755 | train_p: 0.6345 val_p: 0.5037 | train_r: 0.6412 val_r: 0.5215 | train_F1: 0.6074 val_F1 0.4777 | \n",
      "Epoch 12 || train_loss: 0.6348 val_loss: 1.2579 | train_acc: 0.7066 val_acc: 0.6333 | train_p: 0.6572 val_p: 0.5619 | train_r: 0.6621 val_r: 0.5640 | train_F1: 0.6292 val_F1 0.5311 | \n",
      "Epoch 13 || train_loss: 0.1698 val_loss: 1.1297 | train_acc: 0.7193 val_acc: 0.6285 | train_p: 0.6653 val_p: 0.5557 | train_r: 0.6717 val_r: 0.5607 | train_F1: 0.6394 val_F1 0.5250 | \n",
      "Epoch 14 || train_loss: 0.9212 val_loss: 1.0740 | train_acc: 0.7403 val_acc: 0.6651 | train_p: 0.6945 val_p: 0.6044 | train_r: 0.6992 val_r: 0.6208 | train_F1: 0.6682 val_F1 0.5831 | \n",
      "Epoch 15 || train_loss: 0.4883 val_loss: 1.2720 | train_acc: 0.7785 val_acc: 0.6380 | train_p: 0.7312 val_p: 0.5872 | train_r: 0.7363 val_r: 0.5943 | train_F1: 0.7076 val_F1 0.5560 | \n",
      "Epoch 16 || train_loss: 0.8448 val_loss: 1.1156 | train_acc: 0.7861 val_acc: 0.6321 | train_p: 0.7423 val_p: 0.5794 | train_r: 0.7462 val_r: 0.5859 | train_F1: 0.7198 val_F1 0.5448 | \n",
      "Epoch 17 || train_loss: 0.3331 val_loss: 1.0839 | train_acc: 0.8136 val_acc: 0.7123 | train_p: 0.7740 val_p: 0.6545 | train_r: 0.7770 val_r: 0.6527 | train_F1: 0.7536 val_F1 0.6314 | \n",
      "Epoch 18 || train_loss: 0.3589 val_loss: 1.0693 | train_acc: 0.8197 val_acc: 0.6946 | train_p: 0.7811 val_p: 0.6249 | train_r: 0.7820 val_r: 0.6228 | train_F1: 0.7597 val_F1 0.5961 | \n",
      "Epoch 19 || train_loss: 0.1300 val_loss: 0.9707 | train_acc: 0.8273 val_acc: 0.7288 | train_p: 0.7838 val_p: 0.6650 | train_r: 0.7916 val_r: 0.6604 | train_F1: 0.7670 val_F1 0.6359 | \n",
      "Epoch 20 || train_loss: 0.2384 val_loss: 0.9347 | train_acc: 0.8314 val_acc: 0.7453 | train_p: 0.7922 val_p: 0.6763 | train_r: 0.7956 val_r: 0.6720 | train_F1: 0.7729 val_F1 0.6513 | \n",
      "Epoch 21 || train_loss: 0.1081 val_loss: 0.9423 | train_acc: 0.8601 val_acc: 0.7571 | train_p: 0.8296 val_p: 0.6926 | train_r: 0.8319 val_r: 0.6979 | train_F1: 0.8127 val_F1 0.6684 | \n",
      "Epoch 22 || train_loss: 0.8697 val_loss: 1.2195 | train_acc: 0.8594 val_acc: 0.6580 | train_p: 0.8276 val_p: 0.5816 | train_r: 0.8323 val_r: 0.5923 | train_F1: 0.8131 val_F1 0.5557 | \n",
      "Epoch 23 || train_loss: 0.1466 val_loss: 0.9608 | train_acc: 0.8563 val_acc: 0.7429 | train_p: 0.8286 val_p: 0.6696 | train_r: 0.8297 val_r: 0.6722 | train_F1: 0.8104 val_F1 0.6482 | \n",
      "Epoch 24 || train_loss: 0.3842 val_loss: 1.0124 | train_acc: 0.8793 val_acc: 0.7618 | train_p: 0.8478 val_p: 0.7091 | train_r: 0.8534 val_r: 0.7005 | train_F1: 0.8357 val_F1 0.6807 | \n",
      "Epoch 25 || train_loss: 0.0401 val_loss: 0.9516 | train_acc: 0.9347 val_acc: 0.7995 | train_p: 0.9155 val_p: 0.7161 | train_r: 0.9169 val_r: 0.7187 | train_F1: 0.9078 val_F1 0.6977 | \n",
      "Epoch 26 || train_loss: 0.0036 val_loss: 0.9712 | train_acc: 0.9583 val_acc: 0.8054 | train_p: 0.9472 val_p: 0.7448 | train_r: 0.9496 val_r: 0.7470 | train_F1: 0.9425 val_F1 0.7227 | \n",
      "Epoch 27 || train_loss: 0.0023 val_loss: 1.0458 | train_acc: 0.9659 val_acc: 0.7854 | train_p: 0.9565 val_p: 0.7110 | train_r: 0.9586 val_r: 0.7178 | train_F1: 0.9527 val_F1 0.6934 | \n",
      "Epoch 28 || train_loss: 0.0046 val_loss: 1.0862 | train_acc: 0.9719 val_acc: 0.7606 | train_p: 0.9672 val_p: 0.6877 | train_r: 0.9683 val_r: 0.6854 | train_F1: 0.9635 val_F1 0.6622 | \n",
      "Epoch 29 || train_loss: 0.0008 val_loss: 1.0282 | train_acc: 0.9815 val_acc: 0.8125 | train_p: 0.9772 val_p: 0.7599 | train_r: 0.9783 val_r: 0.7563 | train_F1: 0.9749 val_F1 0.7387 | \n",
      "Epoch 30 || train_loss: 0.1002 val_loss: 1.0694 | train_acc: 0.9895 val_acc: 0.8066 | train_p: 0.9862 val_p: 0.7721 | train_r: 0.9869 val_r: 0.7526 | train_F1: 0.9851 val_F1 0.7433 | \n",
      "Epoch 31 || train_loss: 0.0096 val_loss: 1.0366 | train_acc: 0.9920 val_acc: 0.8149 | train_p: 0.9906 val_p: 0.7685 | train_r: 0.9911 val_r: 0.7569 | train_F1: 0.9897 val_F1 0.7420 | \n",
      "Epoch 32 || train_loss: 0.0014 val_loss: 1.0884 | train_acc: 0.9905 val_acc: 0.8019 | train_p: 0.9886 val_p: 0.7281 | train_r: 0.9891 val_r: 0.7416 | train_F1: 0.9875 val_F1 0.7116 | \n",
      "Epoch 33 || train_loss: 0.0001 val_loss: 1.0580 | train_acc: 0.9932 val_acc: 0.8137 | train_p: 0.9921 val_p: 0.7629 | train_r: 0.9921 val_r: 0.7656 | train_F1: 0.9911 val_F1 0.7431 | \n",
      "Epoch 34 || train_loss: 0.0023 val_loss: 1.0138 | train_acc: 0.9967 val_acc: 0.8219 | train_p: 0.9966 val_p: 0.7724 | train_r: 0.9966 val_r: 0.7657 | train_F1: 0.9961 val_F1 0.7488 | \n",
      "Epoch 35 || train_loss: 0.0011 val_loss: 1.0577 | train_acc: 0.9951 val_acc: 0.8208 | train_p: 0.9959 val_p: 0.7455 | train_r: 0.9950 val_r: 0.7491 | train_F1: 0.9946 val_F1 0.7303 | \n",
      "Epoch 36 || train_loss: 0.0009 val_loss: 1.1078 | train_acc: 0.9967 val_acc: 0.8078 | train_p: 0.9957 val_p: 0.7625 | train_r: 0.9959 val_r: 0.7646 | train_F1: 0.9953 val_F1 0.7435 | \n",
      "Epoch 37 || train_loss: 0.0021 val_loss: 1.2105 | train_acc: 0.9960 val_acc: 0.8031 | train_p: 0.9942 val_p: 0.7561 | train_r: 0.9944 val_r: 0.7508 | train_F1: 0.9938 val_F1 0.7334 | \n",
      "Epoch 38 || train_loss: 0.0338 val_loss: 1.0735 | train_acc: 0.9981 val_acc: 0.8196 | train_p: 0.9969 val_p: 0.7726 | train_r: 0.9972 val_r: 0.7709 | train_F1: 0.9968 val_F1 0.7514 | \n",
      "Epoch 39 || train_loss: 0.0016 val_loss: 1.3362 | train_acc: 0.9969 val_acc: 0.7925 | train_p: 0.9963 val_p: 0.7270 | train_r: 0.9965 val_r: 0.7197 | train_F1: 0.9960 val_F1 0.7028 | \n",
      "Epoch 40 || train_loss: 0.0006 val_loss: 1.1171 | train_acc: 0.9973 val_acc: 0.8054 | train_p: 0.9971 val_p: 0.7211 | train_r: 0.9971 val_r: 0.7301 | train_F1: 0.9967 val_F1 0.7092 | \n",
      "Epoch 41 || train_loss: 0.0015 val_loss: 1.0955 | train_acc: 0.9988 val_acc: 0.8243 | train_p: 0.9981 val_p: 0.7557 | train_r: 0.9980 val_r: 0.7523 | train_F1: 0.9979 val_F1 0.7365 | \n",
      "Epoch 42 || train_loss: 0.0068 val_loss: 1.1342 | train_acc: 0.9984 val_acc: 0.8231 | train_p: 0.9977 val_p: 0.7690 | train_r: 0.9979 val_r: 0.7643 | train_F1: 0.9976 val_F1 0.7464 | \n",
      "Epoch 43 || train_loss: 0.0001 val_loss: 1.1499 | train_acc: 0.9985 val_acc: 0.8184 | train_p: 0.9977 val_p: 0.7588 | train_r: 0.9981 val_r: 0.7576 | train_F1: 0.9976 val_F1 0.7405 | \n",
      "Epoch 44 || train_loss: 0.0007 val_loss: 1.1758 | train_acc: 0.9983 val_acc: 0.8101 | train_p: 0.9967 val_p: 0.7512 | train_r: 0.9968 val_r: 0.7563 | train_F1: 0.9966 val_F1 0.7332 | \n",
      "Epoch 45 || train_loss: 0.0005 val_loss: 1.0973 | train_acc: 0.9993 val_acc: 0.8231 | train_p: 0.9992 val_p: 0.7660 | train_r: 0.9992 val_r: 0.7697 | train_F1: 0.9991 val_F1 0.7478 | \n",
      "Epoch 46 || train_loss: 0.0002 val_loss: 1.1561 | train_acc: 0.9988 val_acc: 0.8219 | train_p: 0.9985 val_p: 0.7739 | train_r: 0.9986 val_r: 0.7657 | train_F1: 0.9984 val_F1 0.7480 | \n",
      "Epoch 47 || train_loss: 0.0021 val_loss: 1.1616 | train_acc: 0.9984 val_acc: 0.8113 | train_p: 0.9982 val_p: 0.7606 | train_r: 0.9983 val_r: 0.7679 | train_F1: 0.9980 val_F1 0.7443 | \n",
      "Epoch 48 || train_loss: 0.0001 val_loss: 1.1252 | train_acc: 0.9993 val_acc: 0.8184 | train_p: 0.9992 val_p: 0.7730 | train_r: 0.9993 val_r: 0.7724 | train_F1: 0.9992 val_F1 0.7545 | \n",
      "Epoch 49 || train_loss: 0.0009 val_loss: 1.1401 | train_acc: 0.9993 val_acc: 0.8196 | train_p: 0.9992 val_p: 0.7634 | train_r: 0.9991 val_r: 0.7721 | train_F1: 0.9991 val_F1 0.7493 | \n",
      "Epoch 50 || train_loss: 0.0001 val_loss: 1.3842 | train_acc: 0.9996 val_acc: 0.8007 | train_p: 0.9997 val_p: 0.7367 | train_r: 0.9997 val_r: 0.7190 | train_F1: 0.9996 val_F1 0.7081 | \n"
     ]
    }
   ],
   "source": [
    "vit_dag.train(start_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ByjUYg-CViN"
   },
   "outputs": [],
   "source": [
    "pcvit_dag = TrainingProcessor(train_data=train_ds, \n",
    "                              model=pcvit_model, \n",
    "                              epochs=25, \n",
    "                              batch_size=16, \n",
    "                              learning_rate=5e-5, \n",
    "                              scheduler=True, \n",
    "                              class_weights=class_weights_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYqcFClELdKE",
    "outputId": "7a07337b-1fbd-4ee6-9514-814c47e6c70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || train_loss: 2.1893 val_loss: 1.8701 | train_acc: 0.2195 val_acc: 0.3538 | train_p: 0.1925 val_p: 0.3081 | train_r: 0.1499 val_r: 0.3020 | train_F1: 0.1404 val_F1: 0.2768 | \n",
      "Epoch 2 || train_loss: 1.1201 val_loss: 1.4013 | train_acc: 0.4495 val_acc: 0.5413 | train_p: 0.3874 val_p: 0.4939 | train_r: 0.3883 val_r: 0.4951 | train_F1: 0.3546 val_F1: 0.4648 | \n",
      "Epoch 3 || train_loss: 2.2696 val_loss: 1.2309 | train_acc: 0.6269 val_acc: 0.6344 | train_p: 0.5621 val_p: 0.5598 | train_r: 0.5711 val_r: 0.5531 | train_F1: 0.5339 val_F1: 0.5302 | \n",
      "Epoch 4 || train_loss: 0.2315 val_loss: 1.1673 | train_acc: 0.7777 val_acc: 0.6675 | train_p: 0.7290 val_p: 0.6174 | train_r: 0.7339 val_r: 0.6208 | train_F1: 0.7069 val_F1: 0.5866 | \n",
      "Epoch 5 || train_loss: 0.2780 val_loss: 1.2280 | train_acc: 0.8645 val_acc: 0.6804 | train_p: 0.8335 val_p: 0.6139 | train_r: 0.8381 val_r: 0.6195 | train_F1: 0.8188 val_F1: 0.5950 | \n",
      "Epoch 6 || train_loss: 0.0353 val_loss: 1.1273 | train_acc: 0.9259 val_acc: 0.7335 | train_p: 0.9077 val_p: 0.6593 | train_r: 0.9095 val_r: 0.6712 | train_F1: 0.8988 val_F1: 0.6386 | \n",
      "Epoch 7 || train_loss: 1.2128 val_loss: 1.4199 | train_acc: 0.9446 val_acc: 0.6769 | train_p: 0.9284 val_p: 0.6110 | train_r: 0.9275 val_r: 0.6277 | train_F1: 0.9205 val_F1: 0.5936 | \n",
      "Epoch 8 || train_loss: 0.0130 val_loss: 1.4264 | train_acc: 0.9208 val_acc: 0.7099 | train_p: 0.8963 val_p: 0.6318 | train_r: 0.8992 val_r: 0.6228 | train_F1: 0.8865 val_F1: 0.6042 | \n",
      "Epoch 9 || train_loss: 0.0015 val_loss: 1.4914 | train_acc: 0.9519 val_acc: 0.7182 | train_p: 0.9335 val_p: 0.6765 | train_r: 0.9364 val_r: 0.6798 | train_F1: 0.9287 val_F1: 0.6496 | \n",
      "Epoch 10 || train_loss: 0.0037 val_loss: 1.6960 | train_acc: 0.9733 val_acc: 0.7288 | train_p: 0.9634 val_p: 0.6676 | train_r: 0.9642 val_r: 0.6688 | train_F1: 0.9600 val_F1: 0.6436 | \n",
      "Epoch 11 || train_loss: 0.0003 val_loss: 1.5540 | train_acc: 0.9892 val_acc: 0.7394 | train_p: 0.9875 val_p: 0.6800 | train_r: 0.9869 val_r: 0.6816 | train_F1: 0.9855 val_F1: 0.6564 | \n",
      "Epoch 12 || train_loss: 0.0002 val_loss: 1.5363 | train_acc: 0.9972 val_acc: 0.7500 | train_p: 0.9957 val_p: 0.6973 | train_r: 0.9959 val_r: 0.6950 | train_F1: 0.9953 val_F1: 0.6714 | \n",
      "Epoch 13 || train_loss: 0.0003 val_loss: 1.5531 | train_acc: 0.9989 val_acc: 0.7465 | train_p: 0.9987 val_p: 0.6887 | train_r: 0.9988 val_r: 0.6826 | train_F1: 0.9986 val_F1: 0.6601 | \n",
      "Epoch 14 || train_loss: 0.0008 val_loss: 1.5628 | train_acc: 0.9995 val_acc: 0.7347 | train_p: 0.9992 val_p: 0.6600 | train_r: 0.9992 val_r: 0.6527 | train_F1: 0.9991 val_F1: 0.6337 | \n",
      "Epoch 15 || train_loss: 0.0001 val_loss: 1.6878 | train_acc: 0.9993 val_acc: 0.7370 | train_p: 0.9985 val_p: 0.6780 | train_r: 0.9985 val_r: 0.6714 | train_F1: 0.9984 val_F1: 0.6502 | \n",
      "Epoch 16 || train_loss: 0.0000 val_loss: 1.6733 | train_acc: 0.9997 val_acc: 0.7417 | train_p: 0.9994 val_p: 0.6751 | train_r: 0.9993 val_r: 0.6818 | train_F1: 0.9993 val_F1: 0.6546 | \n",
      "Epoch 17 || train_loss: 0.0012 val_loss: 1.6310 | train_acc: 0.9999 val_acc: 0.7300 | train_p: 0.9999 val_p: 0.6703 | train_r: 0.9999 val_r: 0.6642 | train_F1: 0.9999 val_F1: 0.6405 | \n",
      "Epoch 18 || train_loss: 0.0044 val_loss: 1.5799 | train_acc: 0.9999 val_acc: 0.7630 | train_p: 0.9998 val_p: 0.6988 | train_r: 0.9999 val_r: 0.7003 | train_F1: 0.9998 val_F1: 0.6760 | \n",
      "Epoch 19 || train_loss: 0.0011 val_loss: 1.5515 | train_acc: 0.9997 val_acc: 0.7618 | train_p: 0.9996 val_p: 0.7039 | train_r: 0.9995 val_r: 0.7049 | train_F1: 0.9995 val_F1: 0.6803 | \n",
      "Epoch 20 || train_loss: 0.0007 val_loss: 1.5578 | train_acc: 0.9999 val_acc: 0.7618 | train_p: 0.9999 val_p: 0.7156 | train_r: 0.9999 val_r: 0.7067 | train_F1: 0.9999 val_F1: 0.6884 | \n",
      "Epoch 21 || train_loss: 0.0231 val_loss: 1.6031 | train_acc: 0.9999 val_acc: 0.7630 | train_p: 0.9999 val_p: 0.7050 | train_r: 0.9999 val_r: 0.6997 | train_F1: 0.9999 val_F1: 0.6758 | \n",
      "Epoch 22 || train_loss: 0.0002 val_loss: 1.6501 | train_acc: 1.0000 val_acc: 0.7618 | train_p: 1.0000 val_p: 0.6926 | train_r: 1.0000 val_r: 0.6959 | train_F1: 1.0000 val_F1: 0.6684 | \n",
      "Epoch 23 || train_loss: 0.0000 val_loss: 1.6205 | train_acc: 1.0000 val_acc: 0.7630 | train_p: 1.0000 val_p: 0.6935 | train_r: 1.0000 val_r: 0.6985 | train_F1: 1.0000 val_F1: 0.6736 | \n",
      "Epoch 24 || train_loss: 0.0013 val_loss: 1.7183 | train_acc: 0.9999 val_acc: 0.7406 | train_p: 0.9999 val_p: 0.6809 | train_r: 1.0000 val_r: 0.6809 | train_F1: 0.9999 val_F1: 0.6539 | \n",
      "Epoch 25 || train_loss: 0.0000 val_loss: 1.6016 | train_acc: 0.9999 val_acc: 0.7642 | train_p: 0.9996 val_p: 0.6950 | train_r: 0.9997 val_r: 0.7008 | train_F1: 0.9996 val_F1: 0.6747 | \n"
     ]
    }
   ],
   "source": [
    "pcvit_dag.train(start_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BSXjc8jtxPrl"
   },
   "outputs": [],
   "source": [
    "## prediction on test dataset\n",
    "from sklearn.metrics import classification_report\n",
    "test_ds = train_data['test']\n",
    "testdataloader = DataLoader(test_ds, batch_size = 16, shuffle=True)\n",
    "traindataloader = DataLoader(train_data['train'], batch_size = 16, shuffle=True)\n",
    "\n",
    "def get_tags(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        true_tags = []\n",
    "        pred_tags = []\n",
    "        for i, (batch_x, batch_y) in enumerate(dataloader):\n",
    "            ## iteration training\n",
    "            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "            out = model(batch_x)\n",
    "            _, out_tags = torch.max(torch.log_softmax(out, dim = 1), dim = 1)\n",
    "            true_tags.append(batch_y.cpu().numpy())\n",
    "            pred_tags.append(out_tags.cpu().numpy())\n",
    "    return true_tags, pred_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YLbCVaHMlzUb"
   },
   "outputs": [],
   "source": [
    "cnn_eval_tags = get_tags(cnn_model, testdataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7CvgPVLSgZE"
   },
   "outputs": [],
   "source": [
    "vit_eval_tags = get_tags(vit_model, testdataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1X4zkKi6lq1"
   },
   "outputs": [],
   "source": [
    "pcvit_eval_tags = get_tags(pcvit_model, testdataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__lyFnqxipUO",
    "outputId": "3936ea52-a055-4576-d11e-cbfb4be3a018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        96\n",
      "           1       0.00      0.00      0.00        76\n",
      "           2       0.00      0.00      0.00        67\n",
      "           3       0.17      0.98      0.30       348\n",
      "           4       0.00      0.00      0.00       193\n",
      "           5       0.50      0.21      0.29       288\n",
      "           6       0.00      0.00      0.00       124\n",
      "           7       0.00      0.00      0.00       319\n",
      "           8       0.00      0.00      0.00       353\n",
      "           9       0.00      0.00      0.00       218\n",
      "\n",
      "    accuracy                           0.19      2082\n",
      "   macro avg       0.07      0.12      0.06      2082\n",
      "weighted avg       0.10      0.19      0.09      2082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Inception ResNet results on testing set\n",
    "print(classification_report([y for x in cnn_eval_tags[0] for y in x], [y for x in cnn_eval_tags[1] for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mN4z-fFh-OX0",
    "outputId": "90cd313c-3713-495f-97ef-ad3a6edfaaf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.66        96\n",
      "           1       0.86      0.78      0.81        76\n",
      "           2       0.75      0.75      0.75        67\n",
      "           3       0.84      0.80      0.82       348\n",
      "           4       0.81      0.75      0.78       193\n",
      "           5       0.89      0.89      0.89       288\n",
      "           6       0.76      0.76      0.76       124\n",
      "           7       0.81      0.82      0.81       319\n",
      "           8       0.81      0.87      0.84       353\n",
      "           9       0.78      0.89      0.83       218\n",
      "\n",
      "    accuracy                           0.82      2082\n",
      "   macro avg       0.81      0.79      0.80      2082\n",
      "weighted avg       0.82      0.82      0.82      2082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Vision Transformer results on testing set\n",
    "print(classification_report([y for x in vit_eval_tags[0] for y in x], [y for x in vit_eval_tags[1] for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Br3tHL0HbLnq",
    "outputId": "37063108-8a3b-40dd-97df-c4679c66527d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.45      0.49        96\n",
      "           1       0.86      0.78      0.81        76\n",
      "           2       0.77      0.64      0.70        67\n",
      "           3       0.80      0.75      0.77       348\n",
      "           4       0.71      0.67      0.69       193\n",
      "           5       0.80      0.80      0.80       288\n",
      "           6       0.80      0.75      0.77       124\n",
      "           7       0.73      0.77      0.75       319\n",
      "           8       0.77      0.82      0.80       353\n",
      "           9       0.69      0.80      0.74       218\n",
      "\n",
      "    accuracy                           0.75      2082\n",
      "   macro avg       0.75      0.72      0.73      2082\n",
      "weighted avg       0.75      0.75      0.75      2082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Convolution-based Vision Transformer results on testing set\n",
    "print(classification_report([y for x in pcvit_eval_tags[0] for y in x], [y for x in pcvit_eval_tags[1] for y in x]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Agricultural Crop (Paddy) Disease Classfication.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
