{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text summarization on BBC News.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbmh-B7PyFnA"
      },
      "source": [
        "#### Text Summarization for BBC News - Seq2Seq with Attention using Bi-LSTM and/or Transformer BERT Embeddings\n",
        "<br>\n",
        "<br>\n",
        "This coding project would aim at demonstrating the experiences of doing one of the most common natural language processing (NLP) task, Text Summarization (TS), on the well-recognized public dataset sourced from 2,225 pieces of BBC News (availabel on Kaggle: <a href=\"https://www.kaggle.com/pariza/bbc-news-summary\">https://www.kaggle.com/pariza/bbc-news-summary</a>) These news are usually within around 300 to 500 words, depending on the topics (e.g. shorter for business or entertainment news, while longer for political texts). The following three approaches were attempted respectively: <br>\n",
        "<ul>\n",
        "<li>Seq2Seq with Bidirectional-LSTM embeddings and Luong Attention</li>\n",
        "<li>Seq2Seq with Transformer (positional embeddings + multi-head attention)</li>\n",
        "<li>Seq2Seq with pre-trained BERT models for preprocessing and encoding\n",
        "    <ul><li>Preprocessor:  A Lite BERT (ALBERT)</li>\n",
        "        <li>Encoder:  BERT with Talking-Heads Attention and Gated GELU</li>\n",
        "    </ul>\n",
        "</li>\n",
        "</ul>\n",
        "<br>\n",
        "There are two approaches on doing text summarization: Extractive Text Summarization (ETS) and Abstractive Text Sumarization (ATS). <br>\n",
        " <br>\n",
        "The extractive approach would be easier on the perspective of implementations, as the abstractive approach normally requires a huge number of training epochs and abundant samples to achieve results that are qualitatively satisfactory compared to human written summaries, and this would cost considerably large expenses on cloud resource acquisitions, which would be hardly affordable in small scale tasks. Moreover, as the summary texts in this dataset are basically extracting a portion of crucial sentences from the original full texts and reordering them. The unit of tokenization would be sentences in this scenario. Therefore, the notebook presents the follows conducting the extractive approach.  <br>\n",
        " <br>\n",
        "For the evaluation metrics, 1) accuracy represents whether the model could extract the correct key sentences and match the order of the delivered texts; 2) precision represents the propotion of all predicted sentences that are correctly extracted, i.e. the ability of the model in selecting the key contents; 3) recall represents the propotion of all sentences appeared in the summary that are also included in the predicted texts, i.e. the ability of the model in capturing or covering what should actually be present; 4) BLEU score borrowed from machine translation which indicates how well the generated summary could be compared to the actual summary after exlusion of the position tags marked padding, unknown, begin and end of sentences, and it could be treated as a modified score of precision.<br>\n",
        " <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "    <thead>\n",
        "        <tr>\n",
        "          <th>News Topics</th>\n",
        "          <th colspan=\"4\">BiLSTM Embedding + Luong Attention</th>\n",
        "          <th colspan=\"4\">BERT Embedding + Luong Attention</th>\n",
        "          <th colspan=\"4\">Transformer Encoding + Self-Attention</th>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <th></th>\n",
        "          <th>Mean Accuracy</th>\n",
        "          <th>Mean Precision</th>\n",
        "          <th>Mean Recall</th>\n",
        "          <th>Mean BLEU</th>\n",
        "          <th>Mean Accuracy</th>\n",
        "          <th>Mean Precision</th>\n",
        "          <th>Mean Recall</th>\n",
        "          <th>Mean BLEU</th>\n",
        "          <th>Mean Accuracy</th>\n",
        "          <th>Mean Precision</th>\n",
        "          <th>Mean Recall</th>\n",
        "          <th>Mean BLEU</th>\n",
        "        </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "      <tr>\n",
        "        <td>Business</td>\n",
        "        <td>0.3217</td>\t\n",
        "        <td>0.3718</td>\t\n",
        "        <td>0.2072</td>\t\n",
        "        <td>0.4628</td>\t\n",
        "        <td>0.3971</td>\t\n",
        "        <td>0.7884</td>\t\n",
        "        <td>0.4582</td>\t\n",
        "        <td>0.5418</td>\t\n",
        "        <td>0.3654</td>\t\n",
        "        <td>0.3630</td>\t\n",
        "        <td>0.6087</td>\t\n",
        "        <td>0.4963</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td>Entertainment</td>\n",
        "        <td>0.0612</td>\t\n",
        "        <td>0.2890</td>\t\n",
        "        <td>0.6172</td>\t\n",
        "        <td>0.4894</td>\t\n",
        "        <td>0.0939</td>\t\n",
        "        <td>0.6401</td>\t\n",
        "        <td>0.5576</td>\t\n",
        "        <td>0.4933</td>\t\n",
        "        <td>0.0776</td>\n",
        "        <td>0.3446</td>\t\n",
        "        <td>0.5730</td>\t\n",
        "        <td>0.4895</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td>Politics</td>\n",
        "        <td>0.0569</td>\t\n",
        "        <td>0.3220</td>\t\n",
        "        <td>0.7384</td>\t\n",
        "        <td>0.4530</td>\t\n",
        "        <td>0.0668</td>\t\n",
        "        <td>0.5675</td>\t\n",
        "        <td>0.6667</td>\t\n",
        "        <td>0.4923</td>\t\n",
        "        <td>0.0875</td>\t\n",
        "        <td>0.4047</td>\t\n",
        "        <td>0.7103</td>\t\n",
        "        <td>0.4945</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td>Sports</td>\n",
        "        <td>0.0583</td>\t\n",
        "        <td>0.3120</td>\t\n",
        "        <td>0.4673</td>\t\n",
        "        <td>0.4674</td>\t\n",
        "        <td>0.1902</td>\t\n",
        "        <td>0.4850</td>\t\n",
        "        <td>0.4583</td>\t\n",
        "        <td>0.4777</td>\t\n",
        "        <td>0.2375</td>\t\n",
        "        <td>0.3132</td>\t\n",
        "        <td>0.8737</td>\t\n",
        "        <td>0.4897</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td>Technology</td>\n",
        "        <td>0.0801</td>\t\n",
        "        <td>0.3266</td>\t\n",
        "        <td>0.3471</td>\t\n",
        "        <td>0.4107</td>\t\n",
        "        <td>0.1856</td>\t\n",
        "        <td>0.7495</td>\t\n",
        "        <td>0.3611</td>\t\n",
        "        <td>0.4504</td>\t\n",
        "        <td>0.1091</td>\t\n",
        "        <td>0.3617</td>\t\n",
        "        <td>0.7109</td>\t\n",
        "        <td>0.4278</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td><b>Overall</b></td>\n",
        "      <td><b>0.1156</b></td>\t\n",
        "      <td><b>0.3243</b></td>\t\n",
        "      <td><b>0.4754</b></td>\t\n",
        "      <td><b>0.4567</b></td>\t\n",
        "      <td><b>0.1867</b></td>\t\n",
        "      <td><b>0.6461</b></td>\t\n",
        "      <td><b>0.5004</b></td>\t\n",
        "      <td><b>0.4911</b></td>\t\n",
        "      <td><b>0.1754</b></td>\t\n",
        "      <td><b>0.3574</b></td>\t\n",
        "      <td><b>0.6953</b></td>\t\n",
        "      <td><b>0.4796</b></td>\n",
        "      </tr>\n",
        "    </tbody>\n",
        "</table>"
      ],
      "metadata": {
        "id": "_8IlF0cbuunl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "From above table gathering all results of different models fitted in this notebook, it could be found that using Transformer-based encoding methods involving positional embeddings, no matter tailored to customized training or calling the pre-trained BERT models from Tensorflow hub, had outweighed the Bidirectional LSTM encoded embeddings, in all accuracy, precision and recall metrics. In general, the BLEU score for all analyses reached 0.4 or above, which was generally an acceptable level. <br>\n",
        "<br>\n",
        "Comparing the customized training using Bi-LSTM embeddings and Transformer positional embeddings, the latter one had generally slight increases on the average precision, but also greatly boosted the average recall for Business, Sports and Technology news from the range of 0.2 - 0.4 to 0.6 - 0.8 (overall from 0.475 to 0.695) while the accuracy of Sports achieved the highest level with the customized Transformer model. <br>\n",
        "<br>\n",
        "The pre-trained BERT model with talking-heads attention and gated GELU called from the Tensorflow hub had projected each sentence to a (1 x 128 x 768) dimension array, based on the training results from the developer. This embeddings was passed as the encoder outputs directly to the decoder model with Luong Attention. The results deviated from the custom models in a greater extent, such that the average precision of the predicted summaries was enhanced to over 0.64 from 0.35, but the average recall dropped compared to the customized Transformer models. It gave a scenario that the precision was more emphasized than recall, which might mean the models with pre-trained BERT embeddings could be more conservative to capture correctly the key contents at its guess, while having a weaker coverage against all needed sentences."
      ],
      "metadata": {
        "id": "aGfmeYSjZpox"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiQsqRRXD4eQ"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Colab Notebooks/NLP/bbc_news_archive.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4AFHtlCOd5t"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMBeyqgvDJaD"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import codecs\n",
        "\n",
        "summary_dir = sorted(os.listdir(\"./BBC News Summary/Summaries\"))\n",
        "text_dir = sorted(os.listdir(\"./BBC News Summary/News Articles\"))\n",
        "\n",
        "summary = dict()\n",
        "raw = dict()\n",
        "\n",
        "for i in summary_dir:\n",
        "    summary[i] = list()\n",
        "    data = os.listdir(\"./BBC News Summary/Summaries/\" + i)\n",
        "    for j in data:\n",
        "      try:\n",
        "        f = open(\"./BBC News Summary/Summaries/\" + i + '/' + j, 'r').read()\n",
        "      except:\n",
        "        f = codecs.open(\"./BBC News Summary/Summaries/\" + i + '/' + j, 'rb').read().decode(errors='replace')\n",
        "      f = f.replace('\\n', ' ')\n",
        "      summary[i].append(f)\n",
        "\n",
        "for i in text_dir:\n",
        "    raw[i] = list()\n",
        "    data = os.listdir(\"./BBC News Summary/News Articles/\" + i)\n",
        "    for j in data:\n",
        "      try:\n",
        "        f = open(\"./BBC News Summary/News Articles/\" + i + '/' + j, 'r').read()\n",
        "      except:\n",
        "        f = codecs.open(\"./BBC News Summary/News Articles/\" + i + '/' + j, 'rb').read().decode(errors='replace')\n",
        "      f = f.replace('\\n', ' ')\n",
        "      raw[i].append(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuVyh4FLCE0r"
      },
      "source": [
        "from random import sample, seed, random, randint\n",
        "seed(42)\n",
        "txt_idx = [len(summary[x]) for x in summary]\n",
        "train_idx = [sample(range(0, x), int(x*0.95)) for x in txt_idx]\n",
        "test_idx = [[x for x in range(0, txt_idx[y]) if x not in train_idx[y]] for y in range(len(train_idx))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwAtN3AxHNJz"
      },
      "source": [
        "train_summary = [[summary[list(summary.keys())[x]][tr] for tr in train_idx[x]] for x in range(len(summary))]\n",
        "train_raw = [[raw[list(raw.keys())[x]][tr] for tr in train_idx[x]] for x in range(len(raw))]\n",
        "test_summary = [[summary[list(summary.keys())[x]][ts] for ts in test_idx[x]] for x in range(len(summary))]\n",
        "test_raw = [[raw[list(raw.keys())[x]][ts] for ts in test_idx[x]] for x in range(len(raw))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOjIph4K80O0",
        "outputId": "f87db328-c523-41fa-e58a-27195b94536d"
      },
      "source": [
        "text_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['business', 'entertainment', 'politics', 'sport', 'tech']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY3VOXfV83-l",
        "outputId": "57a4c20c-d3b0-4538-f3e9-98c014355e20"
      },
      "source": [
        "summary_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['business', 'entertainment', 'politics', 'sport', 'tech']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMY7vjSM6VXs",
        "outputId": "04c7f5c5-a1aa-4fa2-dc44-c991e6138d4f"
      },
      "source": [
        "list(raw.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['business', 'entertainment', 'politics', 'sport', 'tech']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raVRheMo6c7n",
        "outputId": "616b54a5-d4c1-4e67-ec0d-880bbbb4f508"
      },
      "source": [
        "list(summary.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['business', 'entertainment', 'politics', 'sport', 'tech']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeOQBLRO2ZJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d413143-d101-444b-c722-b31614ee1482"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.util import ngrams\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5KWf653oNR"
      },
      "source": [
        "## Word tokenization\n",
        "\"\"\"\n",
        "def word_tokenization(doc):\n",
        "    doc = doc.lower()\n",
        "    doc = re.sub('<br/>', ' ', doc)\n",
        "    doc = re.sub('<br />', ' ', doc)\n",
        "    doc = re.sub(\"'s|'m|'re|'ve|'ll|'d|n't\", ' ', doc)\n",
        "    doc = re.sub(r'\"', ' ', doc)\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]\\W+|\\d+|[!?@#%^&*\\[\\]\\\\(){}<>]|[.]|[/]|[$]|[-;:,`~=_+]', ' ', doc)\n",
        "    doc = doc.strip()\n",
        "    tokens = word_tokenize(doc)\n",
        "    tokens = [x for x in tokens if x not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "train_raw_token_categorized = list()\n",
        "train_summary_token_categorized = list()\n",
        "for i in range(len(train_summary)):\n",
        "  train_raw_token_categorized.append([word_tokenization(x) for x in train_raw[i]])\n",
        "  train_summary_token_categorized.append([word_tokenization(x) for x in train_summary[i]])\n",
        "\n",
        "test_raw_token_categorized = list()\n",
        "test_summary_token_categorized = list()\n",
        "for i in range(len(test_summary)):\n",
        "  test_raw_token_categorized.append([word_tokenization(x) for x in test_raw[i]])\n",
        "  test_summary_token_categorized.append([word_tokenization(x) for x in test_summary[i]])\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dye6tqFp3TTW"
      },
      "source": [
        "## Trigram tokenization\n",
        "\"\"\"\n",
        "def ngram_tokenization(doc, n):\n",
        "    doc = doc.lower()\n",
        "    doc = re.sub('<br/>', ' ', doc)\n",
        "    doc = re.sub('<br />', ' ', doc)\n",
        "    doc = re.sub(\"'s|'m|'re|'ve|'ll|'d|n't\", ' ', doc)\n",
        "    doc = re.sub(r'\"', ' ', doc)\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]\\W+|\\d+|[!?@#%^&*\\[\\]\\\\(){}<>]|[.]|[/]|[$]|[-;:,`~=_+]', ' ', doc)\n",
        "    doc = doc.strip()\n",
        "    tokens = ngrams(doc.split(), n)\n",
        "    return tokens\n",
        "\n",
        "train_raw_token_categorized = list()\n",
        "train_summary_token_categorized = list()\n",
        "for i in range(len(train_summary)):\n",
        "  train_raw_token_categorized.append([ngram_tokenization(x, 3) for x in train_raw[i]])\n",
        "  train_summary_token_categorized.append([ngram_tokenization(x, 3) for x in train_summary[i]])\n",
        "\n",
        "test_raw_token_categorized = list()\n",
        "test_summary_token_categorized = list()\n",
        "for i in range(len(test_summary)):\n",
        "  test_raw_token_categorized.append([ngram_tokenization(x, 3) for x in test_raw[i]])\n",
        "  test_summary_token_categorized.append([ngram_tokenization(x, 3) for x in test_summary[i]])\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3t2NbF9z6ut"
      },
      "source": [
        "## Sentence tokenization\n",
        "def summary_sentence_tokenization(doc):\n",
        "    doc = re.sub('<br/>', ' ', doc)\n",
        "    doc = re.sub('<br />', ' ', doc)\n",
        "    tokens = re.split(r'([\\.|!|?][A-Z\\\"])', doc)\n",
        "    re_tokens = []\n",
        "    if len(tokens) > 1:\n",
        "        re_tokens.append(tokens[0] + tokens[1][0])\n",
        "        reserve_letter = tokens[1][1]\n",
        "        for n in range(2, len(tokens), 2):\n",
        "            if n + 1 < len(tokens):\n",
        "                re_tokens.append(reserve_letter + tokens[n] + tokens[n+1][0])\n",
        "            else:\n",
        "                re_tokens.append(reserve_letter + tokens[n])\n",
        "            try:\n",
        "                reserve_letter = tokens[n+1][1]\n",
        "            except:\n",
        "                continue\n",
        "        re_tokens = \" \".join(re_tokens)\n",
        "        tokens = sent_tokenize(re_tokens)\n",
        "    tokens = [x.strip() for x in tokens if len(x.strip()) > 0]\n",
        "    tokens = [x.lower() for x in tokens]\n",
        "    return tokens\n",
        "\n",
        "def raw_sentence_tokenization(doc):\n",
        "    doc = doc.lower()\n",
        "    doc = re.sub('<br/>', ' ', doc)\n",
        "    doc = re.sub('<br />', ' ', doc)\n",
        "    tokens = sent_tokenize(doc)\n",
        "    tokens = [z for y in [x.split(\"  \") for x in tokens] for z in y]\n",
        "    tokens = [x.strip() for x in tokens if len(x.strip()) > 0]\n",
        "    return tokens\n",
        "\n",
        "train_raw_token_categorized = list()\n",
        "train_summary_token_categorized = list()\n",
        "for i in range(len(train_summary)):\n",
        "  train_raw_token_categorized.append([raw_sentence_tokenization(x) for x in train_raw[i]])\n",
        "  train_summary_token_categorized.append([summary_sentence_tokenization(x) for x in train_summary[i]])\n",
        "\n",
        "test_raw_token_categorized = list()\n",
        "test_summary_token_categorized = list()\n",
        "for i in range(len(test_summary)):\n",
        "  test_raw_token_categorized.append([raw_sentence_tokenization(x) for x in test_raw[i]])\n",
        "  test_summary_token_categorized.append([summary_sentence_tokenization(x) for x in test_summary[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGYgICT_8NNm"
      },
      "source": [
        "## gather tokens of all topics\n",
        "train_raw_token = [y for x in train_raw_token_categorized for y in x]\n",
        "train_summary_token = [y for x in train_summary_token_categorized for y in x]\n",
        "test_raw_token = [y for x in test_raw_token_categorized for y in x]\n",
        "test_summary_token = [y for x in test_summary_token_categorized for y in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6GXVASJeiY4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ-xPm_ku2cU"
      },
      "source": [
        "## convert encoder dictionary\n",
        "def process_seq2seq_train_encoder_input(encoder):\n",
        "    reserved = {'<PAD>': 0, '<UNK>': 1}\n",
        "    enc_list = [w for i in encoder for w in i]\n",
        "    enc_dict = {e:i+2 for i,e in enumerate(set(enc_list))}\n",
        "    enc_dict = {**reserved, **enc_dict}\n",
        "    enc_seq = []\n",
        "    ## reserved key-index for padding sequence length, out-of-dictionary words\n",
        "    for e in range(len(encoder)):\n",
        "        enc_sub_seq = []\n",
        "        for se in encoder[e]:\n",
        "            enc_sub_seq.append(enc_dict.get(se))\n",
        "        enc_seq.append(enc_sub_seq)\n",
        "    return enc_dict, enc_seq\n",
        "    \n",
        "## convert decoder dictionary\n",
        "def process_seq2seq_train_decoder_input(decoder):\n",
        "    reserved = {'<PAD>': 0, '<UNK>': 1, '<BOS>':2, '<EOS>':3}\n",
        "    dec_list = [w for i in decoder for w in i]\n",
        "    dec_dict = {e:i+4 for i,e in enumerate(set(dec_list))}\n",
        "    dec_dict = {**reserved, **dec_dict}\n",
        "    dec_seq= []\n",
        "    ## pad <BOS> and <EOS> at the beginning and ending of decoder inputs as indicator for teacher forcing in 3-D outputs\n",
        "    for f in range(len(decoder)):\n",
        "        dec_sub_seq = []\n",
        "        dec_sub_seq.append(dec_dict.get('<BOS>'))\n",
        "        for sf in decoder[f]:\n",
        "            dec_sub_seq.append(dec_dict.get(sf))\n",
        "        dec_sub_seq.append(dec_dict.get('<EOS>'))\n",
        "        dec_seq.append(dec_sub_seq)\n",
        "    return dec_dict, dec_seq\n",
        "\n",
        "## create an one-hot encoded vector for each position of the sequence length\n",
        "def process_seq2seq_train_decoder_y(decoder_text, decoder_dict):\n",
        "    # define length\n",
        "    max_length_de = max([len(x) for x in decoder_text])\n",
        "    len_de = len(decoder_dict)\n",
        "    # initialize matrix\n",
        "    decoder_output_label = np.zeros((len(decoder_text), max_length_de, len_de), dtype=\"float32\")\n",
        "    ## decoder output data would be ahead of decoder input data by one timestep\n",
        "    for i, s1 in enumerate(decoder_text):\n",
        "      for j, s2 in enumerate(s1):\n",
        "        if j > 0:\n",
        "          decoder_output_label[i][j-1][s2] = 1\n",
        "    return decoder_output_label\n",
        "\n",
        "\"\"\"  Setting a maximum limit on available decoding units. \"\"\"\n",
        "def process_seq2seq_train_decoder_y_modified(encoder_text, decoder_text, max_length_de=None, max_length_de_cat=None):\n",
        "\n",
        "    if max_length_de == None:\n",
        "        max_length_de = max([len(x) for x in encoder_text]) + 2\n",
        "    if max_length_de_cat == None:\n",
        "        max_length_de_cat = max_length_de + 2\n",
        "\n",
        "    decoder_output_label = np.zeros((len(decoder_text), max_length_de, max_length_de_cat), dtype=\"float32\")\n",
        "    decoder_n = 0\n",
        "    \n",
        "    for d,e in zip(decoder_text, encoder_text):\n",
        "        reserved = {'<PAD>': 0, '<UNK>': 1, '<BOS>':2, '<EOS>':3 }\n",
        "        enc_list = [w for w in e]\n",
        "        enc_dict = {j:i+4 for i,j in enumerate(set(enc_list))}\n",
        "        enc_dict = {**reserved, **enc_dict}\n",
        "        for n in range(len(d)):\n",
        "            if d[n] in enc_dict.keys():\n",
        "                ind = enc_dict.get(d[n])\n",
        "            else:\n",
        "                ind = enc_dict.get('<PAD>')\n",
        "            decoder_output_label[decoder_n, n + 1, ind] = 1\n",
        "        decoder_n += 1\n",
        "\n",
        "    for k in range(len(decoder_text)):\n",
        "        decoder_output_label[k, 0, 2] = 1\n",
        "        decoder_output_label[k, max_length_de - 1, 3] = 1\n",
        "            \n",
        "    return decoder_output_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJccnQPOLMMk"
      },
      "source": [
        "def get_encoder_decoder_inputs(raw_set, summary_set):\n",
        "  raw_dict, raw_seq = process_seq2seq_train_encoder_input(raw_set)\n",
        "  summary_dict, summary_seq = process_seq2seq_train_decoder_input(summary_set)\n",
        "  # summary_seq_y = process_seq2seq_train_decoder_y(summary_seq, summary_dict)\n",
        "  summary_seq_y = process_seq2seq_train_decoder_y_modified(raw_set, summary_set)\n",
        "  return raw_dict, raw_seq, summary_dict, summary_seq, summary_seq_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42CoKmIZyx2Z"
      },
      "source": [
        "## \"Business\" topic news:\n",
        "## generate encoder and decoder sequence\n",
        "raw_dict, raw_seq = process_seq2seq_train_encoder_input(train_raw_token_categorized[0])\n",
        "summary_dict, summary_seq = process_seq2seq_train_decoder_input(train_summary_token_categorized[0])\n",
        "## pad encoder and decoder sequence\n",
        "raw_seq = pad_sequences(raw_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "# summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in summary_seq]), padding='post')\n",
        "summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in raw_seq]) + 2, padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "# y = process_seq2seq_train_decoder_y(summary_seq, summary_dict)\n",
        "y = process_seq2seq_train_decoder_y_modified(train_raw_token_categorized[0], train_summary_token_categorized[0])\n",
        "## texts for inputs into bert\n",
        "bert_inputs = train_raw_token_categorized[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHXcsLcakn_H"
      },
      "source": [
        "## \"Entertainment\" topic news:\n",
        "## generate encoder and decoder sequence\n",
        "raw_dict, raw_seq = process_seq2seq_train_encoder_input(train_raw_token_categorized[1])\n",
        "summary_dict, summary_seq = process_seq2seq_train_decoder_input(train_summary_token_categorized[1])\n",
        "## pad encoder and decoder sequence\n",
        "raw_seq = pad_sequences(raw_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "# summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in summary_seq]), padding='post')\n",
        "summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in raw_seq]) + 2, padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "# y = process_seq2seq_train_decoder_y(summary_seq, summary_dict)\n",
        "y = process_seq2seq_train_decoder_y_modified(train_raw_token_categorized[1], train_summary_token_categorized[1])\n",
        "## texts for inputs into bert\n",
        "bert_inputs = train_raw_token_categorized[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6tJMcIZolty"
      },
      "source": [
        "## \"Politics\" topic news:\n",
        "## generate encoder and decoder sequence\n",
        "raw_dict, raw_seq = process_seq2seq_train_encoder_input(train_raw_token_categorized[2])\n",
        "summary_dict, summary_seq = process_seq2seq_train_decoder_input(train_summary_token_categorized[2])\n",
        "## pad encoder and decoder sequence\n",
        "raw_seq = pad_sequences(raw_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "# summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in summary_seq]), padding='post')\n",
        "summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in raw_seq]) + 2, padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "# y = process_seq2seq_train_decoder_y(summary_seq, summary_dict)\n",
        "y = process_seq2seq_train_decoder_y_modified(train_raw_token_categorized[2], train_summary_token_categorized[2])\n",
        "## texts for inputs into bert\n",
        "bert_inputs = train_raw_token_categorized[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwqx8f-hN7Lr"
      },
      "source": [
        "## \"Sports\" topic news:\n",
        "## generate encoder and decoder sequence\n",
        "raw_dict, raw_seq = process_seq2seq_train_encoder_input(train_raw_token_categorized[3])\n",
        "summary_dict, summary_seq = process_seq2seq_train_decoder_input(train_summary_token_categorized[3])\n",
        "## pad encoder and decoder sequence\n",
        "raw_seq = pad_sequences(raw_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "# summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in summary_seq]), padding='post')\n",
        "summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in raw_seq]) + 2, padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "# y = process_seq2seq_train_decoder_y(summary_seq, summary_dict)\n",
        "y = process_seq2seq_train_decoder_y_modified(train_raw_token_categorized[3], train_summary_token_categorized[3])\n",
        "## texts for inputs into bert\n",
        "bert_inputs = train_raw_token_categorized[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBWSg9Ca9P7_"
      },
      "source": [
        "## \"Tech\" topic news:\n",
        "## generate encoder and decoder sequence\n",
        "raw_dict, raw_seq = process_seq2seq_train_encoder_input(train_raw_token_categorized[4])\n",
        "summary_dict, summary_seq = process_seq2seq_train_decoder_input(train_summary_token_categorized[4])\n",
        "## pad encoder and decoder sequence\n",
        "raw_seq = pad_sequences(raw_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "# summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in summary_seq]), padding='post')\n",
        "summary_seq = pad_sequences(summary_seq, maxlen = max([len(x) for x in raw_seq]) + 2, padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "# y = process_seq2seq_train_decoder_y(summary_seq, summary_dict)\n",
        "y = process_seq2seq_train_decoder_y_modified(train_raw_token_categorized[4], train_summary_token_categorized[4])\n",
        "## texts for inputs into bert\n",
        "bert_inputs = train_raw_token_categorized[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE27E-o2Ej4-"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Bidirectional, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, Dropout, Activation, Concatenate, Dot\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRR32Y4qiN2p"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "## fitting with 5 bootstrap samples\n",
        "random_state = [42, 101, 111, 123, 999]\n",
        "\n",
        "def bootstrap_samples(num_training_samples, self_defined_random_state, \n",
        "                      encoder_training_samples, \n",
        "                      decoder_training_samples, decoder_training_samples_output):\n",
        "  \n",
        "  sample_index = list(range(0, num_training_samples))\n",
        "  boot = resample(sample_index, replace=False, \n",
        "                  n_samples = int(num_training_samples*0.9), \n",
        "                  random_state = self_defined_random_state)\n",
        "  \n",
        "  enc_train = [encoder_training_samples[ref] for ref in boot]\n",
        "  enc_val = [encoder_training_samples[ref] for ref in range(0, len(encoder_training_samples)) if ref not in boot]\n",
        "  \n",
        "  dec_train_in = [decoder_training_samples[ref] for ref in boot]\n",
        "  dec_val_in = [decoder_training_samples[ref] for ref in range(0, len(decoder_training_samples)) if ref not in boot]\n",
        "  \n",
        "  dec_train_out = [decoder_training_samples_output[ref] for ref in boot]\n",
        "  dec_val_out = [decoder_training_samples_output[ref] for ref in range(0, len(decoder_training_samples_output)) if ref not in boot]\n",
        "  \n",
        "  enc_train = np.array(enc_train)\n",
        "  enc_val = np.array(enc_val)\n",
        "  dec_train_in = np.array(dec_train_in)\n",
        "  dec_val_in = np.array(dec_val_in)\n",
        "  dec_train_out = np.array(dec_train_out)\n",
        "  dec_val_out = np.array(dec_val_out)\n",
        "  \n",
        "  return enc_train, enc_val, dec_train_in, dec_val_in, dec_train_out, dec_val_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "7kdufVYhfeli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQlQMLfeE2yD"
      },
      "source": [
        "def seq2seq_bilstm_luong(encoder_dict, decoder_dict, encoder, decoder):\n",
        "\n",
        "    len_en = len(encoder_dict)\n",
        "    len_de = len(decoder_dict)\n",
        "    max_length_en = max([len(x) for x in encoder])\n",
        "    max_length_de = max([len(x) for x in decoder])\n",
        "\n",
        "    ## Encoder structure with Bi-LSTM\n",
        "    encoder_inputs = Input(shape=(None, ))\n",
        "    encoder_embed = Embedding(input_dim=len_en, output_dim=500)(encoder_inputs)\n",
        "    encoder_LSTM = Bidirectional(LSTM(250, return_state=True, return_sequences=True))\n",
        "    encoder_hidden_vec, forward_last_h, forward_last_c, backward_last_h, backward_last_c = encoder_LSTM(encoder_embed)\n",
        "    enc_state_last_h = Concatenate()([forward_last_h, backward_last_h])\n",
        "    enc_state_last_c = Concatenate()([forward_last_c, backward_last_c])\n",
        "    encoder_states = [enc_state_last_h, enc_state_last_c]\n",
        "\n",
        "    ## Decoder structure with 2-layer stacked LSTM\n",
        "    decoder_inputs = Input(shape=(None, ))\n",
        "    decoder_embed = Embedding(input_dim=len_de, output_dim=1000)(decoder_inputs)\n",
        "    decoder_LSTM = LSTM(units=500, return_state=True, return_sequences=True)\n",
        "    decoder_LSTM_layer = decoder_LSTM(decoder_embed, initial_state = encoder_states)\n",
        "    decoder_LSTM2 = LSTM(units=500, return_state=True, return_sequences=True)\n",
        "    decoder_hidden_vec, dec_state_last_h, dec_state_last_c = decoder_LSTM2(decoder_LSTM_layer)\n",
        "        \n",
        "    ## Attention mechanism\n",
        "    attention_score = Dot([2,2])([decoder_hidden_vec, encoder_hidden_vec])\n",
        "    attention_weight = Activation('softmax')(attention_score)\n",
        "    context = Dot([2,1])([attention_weight, encoder_hidden_vec])\n",
        "    decoder_outputs_combined_context = Concatenate()([context, decoder_hidden_vec])\n",
        "\n",
        "    hidden_state_outputs = TimeDistributed(Dense((max_length_de + 2) * 2, activation='tanh'))(decoder_outputs_combined_context)\n",
        "    outputs = TimeDistributed(Dense(max_length_de + 2, activation='softmax'))(hidden_state_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_seq2seq_bilstm_luong(lr, epoch, batch):\n",
        "\n",
        "    optimizer_learning_rate = lr\n",
        "    num_epochs = epoch\n",
        "    num_batch = batch\n",
        "\n",
        "    model = seq2seq_bilstm_luong(raw_dict, summary_dict, raw_seq, y)\n",
        "    model.compile(optimizer=Adam(learning_rate = optimizer_learning_rate), loss='categorical_crossentropy', metrics=['acc'])    \n",
        "\n",
        "    for b in range(len(random_state)):\n",
        "        enc_train, enc_val, dec_train_in, dec_val_in, dec_train_out, dec_val_out = \\\n",
        "          bootstrap_samples(len(raw_seq), random_state[b], raw_seq, summary_seq, y)\n",
        "        # training the main model\n",
        "        model.fit([enc_train, dec_train_in], dec_train_out, \n",
        "                  batch_size = num_batch, epochs = num_epochs, validation_data=([enc_val, dec_val_in], dec_val_out))\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "VEVYpJz0lHss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Business\n",
        "busi_model = training_seq2seq_bilstm_luong(0.0001, 10, 8)"
      ],
      "metadata": {
        "id": "guGCtKJVplhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Entertainment\n",
        "entt_model = training_seq2seq_bilstm_luong(0.0001, 40, 8)"
      ],
      "metadata": {
        "id": "SvWfGcXJ7pPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Politics\n",
        "polit_model = training_seq2seq_bilstm_luong(0.0001, 40, 8)"
      ],
      "metadata": {
        "id": "0L2T06knu0fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sports\n",
        "sport_model = training_seq2seq_bilstm_luong(0.0001, 20, 8)"
      ],
      "metadata": {
        "id": "XTmH8L5KjRtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd5YcwbQrS0P"
      },
      "source": [
        "## Tech\n",
        "tech_model = training_seq2seq_bilstm_luong(0.0001, 30, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxoEZqp2ewCM"
      },
      "source": [
        "## Business\n",
        "## generate encoder and decoder sequence\n",
        "test_dict, test_seq = process_seq2seq_train_encoder_input(test_raw_token_categorized[0])\n",
        "test_summary_dict, test_summary_seq = process_seq2seq_train_decoder_input(test_summary_token_categorized[0])\n",
        "## pad encoder and decoder sequence\n",
        "test_raw_seq = pad_sequences(test_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "test_summary_seq = pad_sequences(test_summary_seq, maxlen = max([len(x) for x in y]), padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "# y = process_seq2seq_train_decoder_y(summary_seq, summary_dict)\n",
        "test_y = process_seq2seq_train_decoder_y_modified(test_raw_token_categorized[0], test_summary_token_categorized[0],\n",
        "                                                  max_length_de = y.shape[1], max_length_de_cat = y.shape[2])\n",
        "## bert inputs\n",
        "bert_inputs_test = test_raw_token_categorized[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hWknjQwueyK"
      },
      "source": [
        "## Entertainment\n",
        "## generate encoder and decoder sequence\n",
        "test_dict, test_seq = process_seq2seq_train_encoder_input(test_raw_token_categorized[1])\n",
        "test_summary_dict, test_summary_seq = process_seq2seq_train_decoder_input(test_summary_token_categorized[1])\n",
        "## pad encoder and decoder sequence\n",
        "test_raw_seq = pad_sequences(test_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "test_summary_seq = pad_sequences(test_summary_seq, maxlen = max([len(x) for x in y]), padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "test_y = process_seq2seq_train_decoder_y_modified(test_raw_token_categorized[1], test_summary_token_categorized[1],\n",
        "                                                  max_length_de = y.shape[1], max_length_de_cat = y.shape[2])\n",
        "## bert inputs\n",
        "bert_inputs_test = test_raw_token_categorized[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SjUE83395Wq"
      },
      "source": [
        "## Politics\n",
        "## generate encoder and decoder sequence\n",
        "test_dict, test_seq = process_seq2seq_train_encoder_input(test_raw_token_categorized[2])\n",
        "test_summary_dict, test_summary_seq = process_seq2seq_train_decoder_input(test_summary_token_categorized[2])\n",
        "## pad encoder and decoder sequence\n",
        "test_raw_seq = pad_sequences(test_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "test_summary_seq = pad_sequences(test_summary_seq, maxlen = max([len(x) for x in y]), padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "test_y = process_seq2seq_train_decoder_y_modified(test_raw_token_categorized[2], test_summary_token_categorized[2],\n",
        "                                                  max_length_de = y.shape[1], max_length_de_cat = y.shape[2])\n",
        "## bert inputs\n",
        "bert_inputs_test = test_raw_token_categorized[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvUxoUklOdOA"
      },
      "source": [
        "## Sports\n",
        "## generate encoder and decoder sequence\n",
        "test_dict, test_seq = process_seq2seq_train_encoder_input(test_raw_token_categorized[3])\n",
        "test_summary_dict, test_summary_seq = process_seq2seq_train_decoder_input(test_summary_token_categorized[3])\n",
        "## pad encoder and decoder sequence\n",
        "test_raw_seq = pad_sequences(test_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "test_summary_seq = pad_sequences(test_summary_seq, maxlen = max([len(x) for x in y]), padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "test_y = process_seq2seq_train_decoder_y_modified(test_raw_token_categorized[3], test_summary_token_categorized[3],\n",
        "                                                  max_length_de = y.shape[1], max_length_de_cat = y.shape[2])\n",
        "## bert inputs\n",
        "bert_inputs_test = test_raw_token_categorized[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WULMPnw4Ak8"
      },
      "source": [
        "## Tech\n",
        "## generate encoder and decoder sequence\n",
        "test_dict, test_seq = process_seq2seq_train_encoder_input(test_raw_token_categorized[4])\n",
        "test_summary_dict, test_summary_seq = process_seq2seq_train_decoder_input(test_summary_token_categorized[4])\n",
        "## pad encoder and decoder sequence\n",
        "test_raw_seq = pad_sequences(test_seq, maxlen = max([len(x) for x in raw_seq]), padding='post')\n",
        "test_summary_seq = pad_sequences(test_summary_seq, maxlen = max([len(x) for x in y]), padding='post')\n",
        "## dictionary for each document, list of positional sequence, 3d-array one-hot matrix\n",
        "test_y = process_seq2seq_train_decoder_y_modified(test_raw_token_categorized[4], test_summary_token_categorized[4],\n",
        "                                                  max_length_de = y.shape[1], max_length_de_cat = y.shape[2])\n",
        "## bert inputs\n",
        "bert_inputs_test = test_raw_token_categorized[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sequence_embedding(model, input_encoder_seq, n_steps_in_seq):\n",
        "    # initialization\n",
        "    dec_input = np.zeros((1, n_steps_in_seq))\n",
        "    # populate the <BOS> tag of the targeted generated sequence\n",
        "    dec_input[0, 0] = 2\n",
        "    # decoding the sequence\n",
        "    output = []\n",
        "    for t in range(n_steps_in_seq):\n",
        "        dec_output = model.predict([input_encoder_seq, dec_input])\n",
        "        output.append(dec_output[0,t,:])\n",
        "        activated_index = np.argmax(dec_output[0,t,:])\n",
        "        if t + 1 < n_steps_in_seq:\n",
        "            dec_input[0, t + 1] = activated_index\n",
        "    \n",
        "    return np.array(output)"
      ],
      "metadata": {
        "id": "C78MHfJDhAUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_sequence_batch(n_steps, decoder_model, encoder_text_samples, bert=False, bert_inputs=None):\n",
        "\n",
        "    # make predictions using the inference models\n",
        "    n_steps_in_seq = n_steps\n",
        "    inference_seq = []\n",
        "    for t in range(len(test_raw_seq)):\n",
        "        if bert == False:\n",
        "            y_estimated = predict_sequence_embedding(decoder_model, test_raw_seq[t].reshape(1, test_raw_seq[t].shape[0]), n_steps_in_seq)\n",
        "        else:\n",
        "            y_estimated = predict_sequence_embedding(decoder_model, bert_inputs[t], n_steps_in_seq)\n",
        "        inference_seq.append(y_estimated)\n",
        "    \n",
        "    ## initialize metric lists\n",
        "    predicted_seq = []\n",
        "    validated_seq = []\n",
        "    bleu = []\n",
        "    bleu_sample = []\n",
        "    avg_acc = []\n",
        "    accuracy_per_run = []\n",
        "    avg_precision = []\n",
        "    precision_per_run = []\n",
        "    avg_recall = []\n",
        "    recall_per_run = []\n",
        "\n",
        "    for samples in range(len(inference_seq)):\n",
        "        pred = []\n",
        "        actual = []\n",
        "\n",
        "        if bert == False:\n",
        "            reserved = {'<PAD>': 0, '<UNK>': 1, '<BOS>':2, '<EOS>':3 }\n",
        "        else:\n",
        "            reserved = {'pad': 0, 'UNK': 1, 'BOS':2, 'EOS':3 }\n",
        "            \n",
        "        enc_list = [w for w in encoder_text_samples[samples]]\n",
        "        enc_dict = {j:i+4 for i,j in enumerate(set(enc_list))}\n",
        "        enc_dict = {**reserved, **enc_dict}\n",
        "\n",
        "        ## get evaluations\n",
        "        acc_score = 0\n",
        "        total = 0\n",
        "        prec_score = 0\n",
        "        recall_score = 0\n",
        "        \n",
        "        for p in range(len(inference_seq[samples])):\n",
        "            total += 1\n",
        "            try:\n",
        "                predicted_token_index = np.argmax(inference_seq[samples][p])\n",
        "                predicted_token = list(enc_dict.keys())[list(enc_dict.values()).index(predicted_token_index)]\n",
        "            except:\n",
        "                predicted_token_index = 1\n",
        "                predicted_token = list(enc_dict.keys())[list(enc_dict.values()).index(predicted_token_index)]\n",
        "            try:\n",
        "                validated_token_index = np.argmax(test_y[samples][p])\n",
        "                validated_token = list(enc_dict.keys())[list(enc_dict.values()).index(validated_token_index)]\n",
        "            except:\n",
        "                validated_token_index = 1\n",
        "                validated_token = list(enc_dict.keys())[list(enc_dict.values()).index(validated_token_index)]\n",
        "\n",
        "            if predicted_token_index == validated_token_index:\n",
        "                acc_score += 1\n",
        "            pred.append(predicted_token)\n",
        "            actual.append(validated_token)\n",
        "\n",
        "        predicted_seq.append(pred)\n",
        "        validated_seq.append(actual)\n",
        "        bleu_sample.append(sentence_bleu(\", \".join([x for x in list(set(pred)) if x not in ['<EOS>', '<BOS>','<PAD>']]), \n",
        "                                         \", \".join([x for x in list(set(actual)) if x not in ['<EOS>', '<BOS>','<PAD>']])))\n",
        "        accuracy = acc_score / total\n",
        "        accuracy_per_run.append(accuracy)\n",
        "        if len([x for x in list(set(pred)) if x not in ['<EOS>', '<BOS>','<PAD>']]) != 0:\n",
        "            precision = len(list(set([x for x in list(set(pred)) if x not in ['<EOS>', '<BOS>','<PAD>']]) & \n",
        "                                set([x for x in list(set(actual)) if x not in ['<EOS>', '<BOS>','<PAD>']]))) / len([x for x in list(set(pred)) if x not in ['<EOS>', '<BOS>','<PAD>']])\n",
        "        else:\n",
        "            precision = 0\n",
        "        precision_per_run.append(precision)\n",
        "        if len([x for x in list(set(actual)) if x not in ['<EOS>', '<BOS>','<PAD>']]) != 0:\n",
        "            recall = len(list(set([x for x in list(set(pred)) if x not in ['<EOS>', '<BOS>','<PAD>']]) & \n",
        "                              set([x for x in list(set(actual)) if x not in ['<EOS>', '<BOS>','<PAD>']]))) / len([x for x in list(set(actual)) if x not in ['<EOS>', '<BOS>','<PAD>']])\n",
        "        else:\n",
        "            recall = 0\n",
        "        recall_per_run.append(recall)\n",
        "      \n",
        "    avg_acc.append(np.mean(np.array(accuracy_per_run)))\n",
        "    avg_precision.append(np.mean(np.array(precision_per_run)))\n",
        "    avg_recall.append(np.mean(np.array(recall_per_run)))\n",
        "    bleu.append(np.mean(np.array(bleu_sample)))\n",
        "\n",
        "    return avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq"
      ],
      "metadata": {
        "id": "McOQiQIHNTQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIdkJlC3OF0q"
      },
      "source": [
        "**Business:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QGoRS8d30jt"
      },
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), busi_model, test_raw_token_categorized[0]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyL5jXNdjzk0",
        "outputId": "23b41401-bfe2-41e0-9bcf-7bd600d8bcca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.3217\n",
            "Test Result: Mean Precision per Token Position for each document = 0.3718\n",
            "Test Result: Mean Recall per Token Position for each document = 0.2072\n",
            "Test Result: BLEU score = 0.4628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## print an example inference\n",
        "n = randint(0,len(inference_seq)-1)\n",
        "print(\"### Encoder inputs:\")\n",
        "print(\"\\n\".join(test_raw_token_categorized[0][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Decoder outputs:\")\n",
        "print(\"\\n\".join(test_summary_token_categorized[0][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Predicted decoder:\")\n",
        "print(\"\\n\".join([x for x in list(set(predicted_seq[n])) if x not in ['<EOS>', '<BOS>','<PAD>']]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfykxd9DxCOr",
        "outputId": "33d2241f-83d9-4b8d-b282-094464e33fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Encoder inputs:\n",
            "mystery surrounds new yukos owner\n",
            "the fate of russia's yuganskneftegas - the oil firm sold to a little-known buyer on sunday - is the subject of frantic speculation in moscow.\n",
            "baikal finance group emerged as the auction winner, agreeing to pay 260.75bn roubles (4.8bn; $9.4bn).\n",
            "russia's newspapers claimed that baikal was a front for gas monopoly gazprom, which had been expected to win.\n",
            "the sale has destroyed yukos, once the owner of yuganskneftegas, said founder mikhail khodorkovsky.\n",
            "\"yuganskneftegas has been sold in the best traditions of the 90s.\n",
            "the authorities have made themselves a wonderful christmas present - russia's most efficient oil company has been destroyed,\" the interfax news agency quoted mr khodorkovsky as saying via his lawyers.\n",
            "gazprom had been expected to win the auction but is thought to have failed to get finance for the deal after a us court injunction barred it from taking part.\n",
            "last week, yukos filed for chapter 11 bankruptcy protection in the us in a last-ditch attempt to hang on to yuganskneftegas, which accounts for 60% of its output.\n",
            "a us judge banned gazprom from taking part in the auction and barred international banks from providing the firm with cash.\n",
            "\"they screwed up the financing,\" said ronald smith, an analyst at renaissance capital in moscow.\n",
            "\"and gazprom doesn't have this sort of money lying around.\"\n",
            "gazprom has denied that it is behind the purchase.\n",
            "\"it is a front for somebody but not necessarily for gazprom,\" said oleg maximov, an analyst at troika dialog in moscow.\n",
            "\"we don't know if this company is linked 100% to gazprom.\n",
            "\"we tried to find it, but we couldn't and as far as i know, the papers had the same result.\"\n",
            "the sale has however bought time for gazprom to raise the money needed for the purchase, analysts said.\n",
            "one scenario is that baikal will not pay when it is supposed to in two weeks time, putting yuganskneftegas back in the hands of bailiffs and back within the reach of gazprom.\n",
            "yukos is not planning on letting go of its unit without a fight and has threatened legal action against any buyer.\n",
            "menatep, yukos main shareholders' group, has also threatened legal action.\n",
            "yukos claims that it is being punished for the political ambitions of its founder, mikhail khodorkovsky, who is now in jail facing separate fraud charges.\n",
            "it has been hit with more than $27bn in taxes and fines and many observers now say that the break up of the firm that accounts for 20% of russia's oil output is inevitable.\n",
            "\n",
            "\n",
            "### Decoder outputs:\n",
            "the sale has however bought time for gazprom to raise the money needed for the purchase, analysts said.\n",
            "the sale has destroyed yukos, once the owner of yuganskneftegas, said founder mikhail khodorkovsky.\n",
            "gazprom has denied that it is behind the purchase.\n",
            "\"it is a front for somebody but not necessarily for gazprom,\" said oleg maximov, an analyst at troika dialog in moscow.\n",
            "\"we don't know if this company is linked 100% to gazprom.\n",
            "\"yuganskneftegas has been sold in the best traditions of the 90s.\n",
            "russia's newspapers claimed that baikal was a front for gas monopoly gazprom, which had been expected to win.\n",
            "gazprom had been expected to win the auction but is thought to have failed to get finance for the deal after a us court injunction barred it from taking part.\n",
            "it has been hit with more than $27bn in taxes and fines and many observers now say that the break up of the firm that accounts for 20% of russia's oil output is inevitable.\n",
            "\n",
            "\n",
            "### Predicted decoder:\n",
            "baikal finance group emerged as the auction winner, agreeing to pay 260.75bn roubles (4.8bn; $9.4bn).\n",
            "a us judge banned gazprom from taking part in the auction and barred international banks from providing the firm with cash.\n",
            "gazprom has denied that it is behind the purchase.\n",
            "the authorities have made themselves a wonderful christmas present - russia's most efficient oil company has been destroyed,\" the interfax news agency quoted mr khodorkovsky as saying via his lawyers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT3k6wmxcWvo"
      },
      "source": [
        "**Entertainment:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), entt_model, test_raw_token_categorized[1]\n",
        ")"
      ],
      "metadata": {
        "id": "nzfj-ek8JHjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW75LCP2n4oc",
        "outputId": "cf919977-6ab8-4456-bf03-9d40bf121db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.0612\n",
            "Test Result: Mean Precision per Token Position for each document = 0.289\n",
            "Test Result: Mean Recall per Token Position for each document = 0.6172\n",
            "Test Result: BLEU score = 0.4894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8doPozOabgS",
        "outputId": "a2acda1a-4e16-4630-9ed9-095a426ba442"
      },
      "source": [
        "## print an example inference\n",
        "n = randint(0,len(inference_seq)-1)\n",
        "print(\"### Encoder inputs:\")\n",
        "print(\"\\n\".join(test_raw_token_categorized[1][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Decoder outputs:\")\n",
        "print(\"\\n\".join(test_summary_token_categorized[1][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Predicted decoder:\")\n",
        "print(\"\\n\".join([x for x in list(set(predicted_seq[n])) if x not in ['<EOS>', '<BOS>','<PAD>']]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Encoder inputs:\n",
            "ray dvd beats box office takings\n",
            "oscar-nominated film biopic ray has surpassed its us box office takings with a combined tally of $80m (43m) from dvd and video sales and rentals.\n",
            "ray's success on dvd outstripped its $74m (40m) us box office total, earning more than $40m (22m) on the first day of the dvd's release alone.\n",
            "ray has been nominated in six oscar categories including best film and best actor for jamie foxx.\n",
            "the film recounts the life of blues singer ray charles, who died in 2004. in its first week on home entertainment release the film was the number one selling dvd, with the limited edition version coming in at number 11. sony horror film the grudge, starring michelle gellar, was the us' second best-selling dvd, with jennifer lopez and richard gere's romantic comedy shall we dance?\n",
            "at number three.\n",
            "foxx's critically acclaimed performance as ray has already earned him a screen actors guild award for best actor, as well as a prestigious golden globe.\n",
            "ray director taylor hackford, responsible for the classic 1982 film an officer and a gentleman, has also received an oscar nomination in the best director category.\n",
            "the film's three other oscar nominations are for costume, film editing and sound mixing.\n",
            "\n",
            "\n",
            "### Decoder outputs:\n",
            "ray has been nominated in six oscar categories including best film and best actor for jamie foxx.\n",
            "oscar-nominated film biopic ray has surpassed its us box office takings with a combined tally of $80m (43m) from dvd and video sales and rentals.\n",
            "ray director taylor hackford, responsible for the classic 1982 film an officer and a gentleman, has also received an oscar nomination in the best director category.\n",
            "in its first week on home entertainment release the film was the number one selling dvd, with the limited edition version coming in at number 11.\n",
            "\n",
            "\n",
            "### Predicted decoder:\n",
            "<UNK>\n",
            "ray dvd beats box office takings\n",
            "the film's three other oscar nominations are for costume, film editing and sound mixing.\n",
            "oscar-nominated film biopic ray has surpassed its us box office takings with a combined tally of $80m (43m) from dvd and video sales and rentals.\n",
            "ray's success on dvd outstripped its $74m (40m) us box office total, earning more than $40m (22m) on the first day of the dvd's release alone.\n",
            "ray has been nominated in six oscar categories including best film and best actor for jamie foxx.\n",
            "the film recounts the life of blues singer ray charles, who died in 2004. in its first week on home entertainment release the film was the number one selling dvd, with the limited edition version coming in at number 11. sony horror film the grudge, starring michelle gellar, was the us' second best-selling dvd, with jennifer lopez and richard gere's romantic comedy shall we dance?\n",
            "at number three.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep7k9GcU6xz4"
      },
      "source": [
        "**Politics:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), polit_model, test_raw_token_categorized[2]\n",
        ")"
      ],
      "metadata": {
        "id": "XVkvA4mp5ZCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIthb5uJ5hex",
        "outputId": "7775df27-ce23-49d7-bbd9-d33deb743868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.0569\n",
            "Test Result: Mean Precision per Token Position for each document = 0.322\n",
            "Test Result: Mean Recall per Token Position for each document = 0.7384\n",
            "Test Result: BLEU score = 0.453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNUaJESTkvzu",
        "outputId": "5e0c6c52-75b5-4c98-e558-3969afdff54e"
      },
      "source": [
        "## print an example inference\n",
        "n = randint(0,len(inference_seq)-1)\n",
        "print(\"### Encoder inputs:\")\n",
        "print(\"\\n\".join(test_raw_token_categorized[2][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Decoder outputs:\")\n",
        "print(\"\\n\".join(test_summary_token_categorized[2][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Predicted decoder:\")\n",
        "print(\"\\n\".join([x for x in list(set(predicted_seq[n])) if x not in ['<EOS>', '<BOS>','<PAD>']]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Encoder inputs:\n",
            "anti-terror plan faces first test\n",
            "plans to allow home secretary charles clarke to place terror suspects under house arrest without trial are set for their first real test in parliament.\n",
            "tories, lib dems and some labour mps are poised to vote against the plans.\n",
            "mr clarke says the powers are needed to counter terror threats.\n",
            "opponents say only judges, not politicians, should be able to order detention of uk citizens.\n",
            "the government is expected to win wednesday's vote in the commons, but faces a battle in the house of lords.\n",
            "the prevention of terrorism bill was published on tuesday.\n",
            "it proposes \"control orders\", which would mean house arrest in the most serious cases, and curfews, electronic tagging and limits on telephone and internet access for other suspects.\n",
            "the two opposition parties are particularly worried that the control orders would initially be imposed on the say-so of the home secretary, rather than a judge.\n",
            "tory shadow home secretary david davis warned of the potential for miscarriages of justice, like the guildford four - for which tony blair recently apologised - as a result of the pressure on politicians to lock up terror suspects.\n",
            "\"those pressures would be much more for a politician than they would on a judge and that's why we have serious concerns abut that approach,\" he told bbc radio 4's today programme.\n",
            "mr clarke says he does not intend to use the house arrest powers now - even for the 11 current terror detainees.\n",
            "he also said that any decision he made would be reviewed by a judge within seven days.\n",
            "the foreign terror suspects currently detained are mostly held at london's belmarsh prison.\n",
            "they are held under laws which the law lords have ruled break human rights rules - and which are due to expire on 14 march.\n",
            "the new powers, designed to replace the existing laws and meet the law lords' concerns, would apply to british as well as foreign terror suspects.\n",
            "critics say that giving politicians the power to deprive uk citizens of their freedom is the biggest attack on civil liberties for 300 years.\n",
            "opposition mps are also angry they will have only two days - wednesday and next monday - to debate the new plans before they pass to the house of lords.\n",
            "but the government says the existing powers run out soon so must be replaced urgently.\n",
            "in a rare move, the tories and lib dems have jointly tabled a motion opposing the new bill, saying the house arrest plans are \"excessive\".\n",
            "it argues decisions should be taken on a higher standard of proof and the plan \"wrongly infringes the right to liberty\" by failing to bring terrorists to trial where there is evidence.\n",
            "mr davis told today: \"it gives a minister, for the first time in modern history, the right to detain without trial, without showing the evidence and indeed, in some respects, almost the allegation against the individual concerned.\"\n",
            "he questioned why there was \"such a rush\" to introduce the legislation when mr clarke had indicated he was not planning to use the house arrest powers straight away.\n",
            "liberal democrat home affairs spokesman mark oaten said: \"we believe it should be the judge that takes decisions, not politicians.\"\n",
            "mr clarke said the security services and police backed his measures and it would be \"rash and negligent\" to ignore their advice.\n",
            "nobody should doubt that terrorists at home and abroad wanted to attack the uk and its interests, he argued.\n",
            "\n",
            "\n",
            "### Decoder outputs:\n",
            "mr clarke says he does not intend to use the house arrest powers now - even for the 11 current terror detainees.\n",
            "plans to allow home secretary charles clarke to place terror suspects under house arrest without trial are set for their first real test in parliament.\n",
            "mr clarke says the powers are needed to counter terror threats.\n",
            "he questioned why there was \"such a rush\" to introduce the legislation when mr clarke had indicated he was not planning to use the house arrest powers straight away.\n",
            "the new powers, designed to replace the existing laws and meet the law lords' concerns, would apply to british as well as foreign terror suspects.\n",
            "in a rare move, the tories and lib dems have jointly tabled a motion opposing the new bill, saying the house arrest plans are \"excessive\".\n",
            "the two opposition parties are particularly worried that the control orders would initially be imposed on the say-so of the home secretary, rather than a judge.\n",
            "it proposes \"control orders\", which would mean house arrest in the most serious cases, and curfews, electronic tagging and limits on telephone and internet access for other suspects.\n",
            "opposition mps are also angry they will have only two days - wednesday and next monday - to debate the new plans before they pass to the house of lords.\n",
            "mr clarke said the security services and police backed his measures and it would be \"rash and negligent\" to ignore their advice.\n",
            "\n",
            "\n",
            "### Predicted decoder:\n",
            "it proposes \"control orders\", which would mean house arrest in the most serious cases, and curfews, electronic tagging and limits on telephone and internet access for other suspects.\n",
            "tories, lib dems and some labour mps are poised to vote against the plans.\n",
            "in a rare move, the tories and lib dems have jointly tabled a motion opposing the new bill, saying the house arrest plans are \"excessive\".\n",
            "anti-terror plan faces first test\n",
            "the prevention of terrorism bill was published on tuesday.\n",
            "it argues decisions should be taken on a higher standard of proof and the plan \"wrongly infringes the right to liberty\" by failing to bring terrorists to trial where there is evidence.\n",
            "but the government says the existing powers run out soon so must be replaced urgently.\n",
            "<UNK>\n",
            "the new powers, designed to replace the existing laws and meet the law lords' concerns, would apply to british as well as foreign terror suspects.\n",
            "tory shadow home secretary david davis warned of the potential for miscarriages of justice, like the guildford four - for which tony blair recently apologised - as a result of the pressure on politicians to lock up terror suspects.\n",
            "liberal democrat home affairs spokesman mark oaten said: \"we believe it should be the judge that takes decisions, not politicians.\"\n",
            "nobody should doubt that terrorists at home and abroad wanted to attack the uk and its interests, he argued.\n",
            "mr clarke said the security services and police backed his measures and it would be \"rash and negligent\" to ignore their advice.\n",
            "mr clarke says he does not intend to use the house arrest powers now - even for the 11 current terror detainees.\n",
            "mr clarke says the powers are needed to counter terror threats.\n",
            "opponents say only judges, not politicians, should be able to order detention of uk citizens.\n",
            "he also said that any decision he made would be reviewed by a judge within seven days.\n",
            "the foreign terror suspects currently detained are mostly held at london's belmarsh prison.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bquTp90z6ntz"
      },
      "source": [
        "**Sports:** "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), sport_model, test_raw_token_categorized[3]\n",
        ")"
      ],
      "metadata": {
        "id": "qu2JrD-S0l7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lykf_QxXNW4i",
        "outputId": "acb0dc6d-7381-4289-ecc8-b014e2fe07b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.0583\n",
            "Test Result: Mean Precision per Token Position for each document = 0.312\n",
            "Test Result: Mean Recall per Token Position for each document = 0.4673\n",
            "Test Result: BLEU score = 0.4674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EZW2sng30UR",
        "outputId": "0c39e30d-dd56-4671-d984-27ddfc11d87e"
      },
      "source": [
        "## print an example inference\n",
        "n = randint(0,len(inference_seq)-1)\n",
        "print(\"### Encoder inputs:\")\n",
        "print(\"\\n\".join(test_raw_token_categorized[3][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Decoder outputs:\")\n",
        "print(\"\\n\".join(test_summary_token_categorized[3][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Predicted decoder:\")\n",
        "print(\"\\n\".join([x for x in list(set(predicted_seq[n])) if x not in ['<EOS>', '<BOS>','<PAD>']]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Encoder inputs:\n",
            "britain boosted by holmes double\n",
            "athletics fans endured a year of mixed emotions in 2004 as stunning victories went hand-in-hand with disappointing defeats and more drugs scandals.\n",
            "kelly holmes finally fulfilled her potential by storming to double gold on the track at the olympic games.\n",
            "holmes helped erase the gloom hanging over team gb after their biggest medal hope, paula radcliffe, dropped out of the marathon and then the 10,000m.\n",
            "britain's men's 4x100m relay team also did their bit by taking a shock gold.\n",
            "holmes had started the year in disappointing style, falling over in the final of 1500m at the world indoor championships where she was favourite.\n",
            "her olympic build-up was clouded by self doubt but that proved unfounded as she overhauled rival maria mutola to win the 800m - her first global title.\n",
            "just five days later, the 34-year-old made it double gold in the 1500m.\n",
            "it was the first time in 84 years a briton has achieved the olympic middle-distance double.\n",
            "while holmes left athens as the star of team gb, it was radcliffe who carried expectations before the august games.\n",
            "the 30-year-old marathon world record holder went into the athens event as favourite but an exhausted radcliffe dropped out after 23 miles in tears.\n",
            "her decision to enter the 10,000m five days later also backfired as she again pulled out with eight laps remaining.\n",
            "but radcliffe helped put her olympic trauma behind her with a thrilling win in november's new york marathon.\n",
            "the 4x100m team grabbed some last-gasp glory for the british men's olympic squad after a poor start to the games.\n",
            "it seemed as though athens would be the first games where the men would fail to win a medal with michael east the only individual track finalist in the 1500m.\n",
            "but darren campell, jason gardener, marlon devonish and mark lewis-francis made amends in the sprint relay.\n",
            "the quartet held off favourites the usa to win britain's first relay medal since 1912 in 38.07 seconds.\n",
            "gardener added the olympic relay crown to his world indoor title over 60m and, just like holmes, finally lived up to his promise in 2004. kelly sotherton completed team gb's athletics medal haul in athens with a surprise bronze in the heptathlon.\n",
            "the 28-year-old won her first championship medal since becoming a full-time athlete in 2003.\n",
            "but it was a different story for britain's defending champion denise lewis, who withdrew on day two of the competition after some poor results.\n",
            "lewis, who was troubled by injury, has ruled out retiring while sotherton is tipped to build on her success.\n",
            "the athens olympics proved to be a landmark occasion for steve backley, who retired from competition after finishing fourth in the javelin.\n",
            "the battling 35-year-old leaves the sport with a vast medal haul including two silvers and one olympic bronze.\n",
            "and backley's departure was balanced by the return of injury-hit decathlete dean macey, who came fourth in athens.\n",
            "the continued improvement of sprinter abi oyepitan and long jumper chris tomlinson also boosted team gb.\n",
            "sadly, the 2004 olympics did not escape the problems of drugs misuse.\n",
            "on the eve of the games, greek sprinters kostas kenteris and katerina thanou missed a drugs test and claimed to have been involved in a road crash.\n",
            "kenteris, the 200m champion in 2000, and thanou have since been charged by the greek authorities and await trial.\n",
            "at the games, adrian annus (hammer), robert fazelas (discus) and irina korzhanenko (shot) were all stripped of their titles because of doping issues.\n",
            "hungarian compatriots annus and fazelas both refused to give urine samples while russian korzhanenko tested positive for the steroid stanozolol.\n",
            "the fallout from the thg scandal, which rocked the sport in 2003, continued to impact in olympic year.\n",
            "britain's 4x100m team took gold without the services of dwain chambers, who was handed a two-year ban in february after testing positive for steroid thg.\n",
            "american kelli white was suspended and stripped of her world 100m and 200m titles after failing a drugs test.\n",
            "and world 400m champion jerome young landed a life ban from us chiefs after a second doping offence.\n",
            "russian pole vaulter yelena isinbayeva provided some light relief by smashing the world record seven times on her way to the world indoor and olympic titles.\n",
            "her rivalry with compatriot svetlana feofanova livened up the field events.\n",
            "morocco's hicham el guerrouj also delighted fans by racing to a historic olympic double in the 1500m and 5,000m.\n",
            "and though there was no paula radcliffe in the london marathon, there was plenty of drama as kenyans evans rutto and margaret okayo took the titles.\n",
            "rutto held on to win despite slipping on some cobblestones and tumbling into a barrier.\n",
            "okayo also had to battle back after mistiming her tactics but clinched victory on her debut.\n",
            "\n",
            "\n",
            "### Decoder outputs:\n",
            "while holmes left athens as the star of team gb, it was radcliffe who carried expectations before the august games.\n",
            "it was the first time in 84 years a briton has achieved the olympic middle-distance double.\n",
            "kelly holmes finally fulfilled her potential by storming to double gold on the track at the olympic games.\n",
            "gardener added the olympic relay crown to his world indoor title over 60m and, just like holmes, finally lived up to his promise in 2004.\n",
            "her olympic build-up was clouded by self doubt but that proved unfounded as she overhauled rival maria mutola to win the 800m - her first global title.\n",
            "holmes had started the year in disappointing style, falling over in the final of 1500m at the world indoor championships where she was favourite.\n",
            "the quartet held off favourites the usa to win britain's first relay medal since 1912 in 38.07 seconds.\n",
            "american kelli white was suspended and stripped of her world 100m and 200m titles after failing a drugs test.\n",
            "britain's 4x100m team took gold without the services of dwain chambers, who was handed a two-year ban in february after testing positive for steroid thg.\n",
            "britain's men's 4x100m relay team also did their bit by taking a shock gold.\n",
            "and though there was no paula radcliffe in the london marathon, there was plenty of drama as kenyans evans rutto and margaret okayo took the titles.\n",
            "holmes helped erase the gloom hanging over team gb after their biggest medal hope, paula radcliffe, dropped out of the marathon and then the 10,000m.\n",
            "the 4x100m team grabbed some last-gasp glory for the british men's olympic squad after a poor start to the games.\n",
            "the 30-year-old marathon world record holder went into the athens event as favourite but an exhausted radcliffe dropped out after 23 miles in tears.\n",
            "it seemed as though athens would be the first games where the men would fail to win a medal with michael east the only individual track finalist in the 1500m.\n",
            "kelly sotherton completed team gb's athletics medal haul in athens with a surprise bronze in the heptathlon.\n",
            "\n",
            "\n",
            "### Predicted decoder:\n",
            "on the eve of the games, greek sprinters kostas kenteris and katerina thanou missed a drugs test and claimed to have been involved in a road crash.\n",
            "holmes had started the year in disappointing style, falling over in the final of 1500m at the world indoor championships where she was favourite.\n",
            "russian pole vaulter yelena isinbayeva provided some light relief by smashing the world record seven times on her way to the world indoor and olympic titles.\n",
            "but radcliffe helped put her olympic trauma behind her with a thrilling win in november's new york marathon.\n",
            "but it was a different story for britain's defending champion denise lewis, who withdrew on day two of the competition after some poor results.\n",
            "kenteris, the 200m champion in 2000, and thanou have since been charged by the greek authorities and await trial.\n",
            "kelly holmes finally fulfilled her potential by storming to double gold on the track at the olympic games.\n",
            "her decision to enter the 10,000m five days later also backfired as she again pulled out with eight laps remaining.\n",
            "her rivalry with compatriot svetlana feofanova livened up the field events.\n",
            "hungarian compatriots annus and fazelas both refused to give urine samples while russian korzhanenko tested positive for the steroid stanozolol.\n",
            "and though there was no paula radcliffe in the london marathon, there was plenty of drama as kenyans evans rutto and margaret okayo took the titles.\n",
            "britain's men's 4x100m relay team also did their bit by taking a shock gold.\n",
            "lewis, who was troubled by injury, has ruled out retiring while sotherton is tipped to build on her success.\n",
            "and backley's departure was balanced by the return of injury-hit decathlete dean macey, who came fourth in athens.\n",
            "the continued improvement of sprinter abi oyepitan and long jumper chris tomlinson also boosted team gb.\n",
            "sadly, the 2004 olympics did not escape the problems of drugs misuse.\n",
            "holmes helped erase the gloom hanging over team gb after their biggest medal hope, paula radcliffe, dropped out of the marathon and then the 10,000m.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSRuhahm5a7w"
      },
      "source": [
        "**Technology:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), tech_model, test_raw_token_categorized[4]\n",
        ")"
      ],
      "metadata": {
        "id": "lDwgDR2WVIPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4HajDuiyFMX",
        "outputId": "6e4b9e6d-fe50-4082-c816-fe64de760bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.0801\n",
            "Test Result: Mean Precision per Token Position for each document = 0.3266\n",
            "Test Result: Mean Recall per Token Position for each document = 0.3471\n",
            "Test Result: BLEU score = 0.4107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgAo359w5fwa",
        "outputId": "8cad0c2d-f80e-4c3c-c786-be272f45777b"
      },
      "source": [
        "## print an example inference\n",
        "n = randint(0,len(inference_seq)-1)\n",
        "print(\"### Encoder inputs:\")\n",
        "print(\"\\n\".join(test_raw_token_categorized[4][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Decoder outputs:\")\n",
        "print(\"\\n\".join(test_summary_token_categorized[4][n]))\n",
        "print(\"\\n\")\n",
        "print(\"### Predicted decoder:\")\n",
        "print(\"\\n\".join([x for x in list(set(predicted_seq[n])) if x not in ['<EOS>', '<BOS>','<PAD>']]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Encoder inputs:\n",
            "'no re-draft' for eu patent law\n",
            "a proposed european law on software patents will not be re-drafted by the european commission (ec) despite requests by meps.\n",
            "the law is proving controversial and has been in limbo for a year.\n",
            "some major tech firms say it is needed to protect inventions, while others fear it will hurt smaller tech firms the ec says the council of ministers will adopt a draft version that was agreed upon last may but said it would review \"all aspects of the directive\".\n",
            "the directive is intended to offer patent protection to inventions that use software to achieve their effect, in other words, \"computer implemented invention\".\n",
            "in a letter, ec president jos&#233; manuel barroso told the president of the european parliament, josep borrell, that the commission \"did not intend to refer a new proposal to the parliament and the council (of ministers)\" as it had supported the agreement reached by ministers in may 2004.\n",
            "if the european council agrees on the draft directive it will then return for a second reading at the european parliament.\n",
            "but that will not guarantee that the directive will become law - instead it will probably mean further delays and controversy over the directive.\n",
            "most eu legislation now needs the approval of both parliament and the council of ministers before it becomes law.\n",
            "french green mep alain lipietz warned two weeks ago that if the commission ignored the parliament's request it would be an \"insult\" to the assembly.\n",
            "he said that the parliament would then reject the council's version of the legislation as part of the final or conciliation stage of the decision procedure.\n",
            "in the us, the patenting of computer programs and internet business methods is permitted.\n",
            "this means that the us-based amazon.com holds a patent for its \"one-click shopping\" service, for example.\n",
            "critics are concerned that the directive could lead to a similar model happening in europe.\n",
            "this, they fear, could hurt small software developers because they do not have the legal and financial might of larger companies if they had to fight patent legal action in court.\n",
            "supporters say current laws are inefficient and it would serve to even up a playing field without bringing eu laws in line with the us.\n",
            "\n",
            "\n",
            "### Decoder outputs:\n",
            "a proposed european law on software patents will not be re-drafted by the european commission (ec) despite requests by meps.\n",
            "but that will not guarantee that the directive will become law - instead it will probably mean further delays and controversy over the directive.\n",
            "supporters say current laws are inefficient and it would serve to even up a playing field without bringing eu laws in line with the us.\n",
            "if the european council agrees on the draft directive it will then return for a second reading at the european parliament.\n",
            "most eu legislation now needs the approval of both parliament and the council of ministers before it becomes law.\n",
            "some major tech firms say it is needed to protect inventions, while others fear it will hurt smaller tech firms the ec says the council of ministers will adopt a draft version that was agreed upon last may but said it would review \"all aspects of the directive\".\n",
            "\n",
            "\n",
            "### Predicted decoder:\n",
            "most eu legislation now needs the approval of both parliament and the council of ministers before it becomes law.\n",
            "this means that the us-based amazon.com holds a patent for its \"one-click shopping\" service, for example.\n",
            "french green mep alain lipietz warned two weeks ago that if the commission ignored the parliament's request it would be an \"insult\" to the assembly.\n",
            "he said that the parliament would then reject the council's version of the legislation as part of the final or conciliation stage of the decision procedure.\n",
            "a proposed european law on software patents will not be re-drafted by the european commission (ec) despite requests by meps.\n",
            "in a letter, ec president jos&#233; manuel barroso told the president of the european parliament, josep borrell, that the commission \"did not intend to refer a new proposal to the parliament and the council (of ministers)\" as it had supported the agreement reached by ministers in may 2004.\n",
            "this, they fear, could hurt small software developers because they do not have the legal and financial might of larger companies if they had to fight patent legal action in court.\n",
            "supporters say current laws are inefficient and it would serve to even up a playing field without bringing eu laws in line with the us.\n",
            "but that will not guarantee that the directive will become law - instead it will probably mean further delays and controversy over the directive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L5nIJ4PNp1R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TmFY84nMIZt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "c4x9YtG0pHAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "qczWupYZ_g0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seq_with_bert:\n",
        "\n",
        "    def __init__(self, encoder_text, max_length_en, decoder_dict, decoder_vector, seq_length):\n",
        "        self.decoder_dict = decoder_dict\n",
        "        self.decoder_vector =  decoder_vector\n",
        "        self.seq_length = seq_length\n",
        "        self.len_de = len(decoder_dict)\n",
        "        self.max_length_de = max([len(x) for x in decoder_vector])\n",
        "        self.encoder_text = encoder_text\n",
        "        self.max_length_en = max_length_en\n",
        "\n",
        "    def get_bert_preprocessor_outputs(self):\n",
        "        ## loaded model\n",
        "        tfhub_albert_preprocess = \"https://tfhub.dev/tensorflow/albert_en_preprocess/3\"\n",
        "        albert_preprocess = hub.load(tfhub_albert_preprocess)\n",
        "        ## padding the texts to same length\n",
        "        len_en = [self.max_length_en - len(d) for d in self.encoder_text]\n",
        "        pad_encoder_text = [[\" \".join(self.encoder_text[x] + ['pad'] * len_en[x])] for x in range(len(self.encoder_text))]\n",
        "        ## get outputs preprocessed\n",
        "        preprocess_encoder_text = [albert_preprocess(x) for x in pad_encoder_text]\n",
        "        return preprocess_encoder_text\n",
        "\n",
        "    def get_bert_encoder_embeddings(self, preprocess_encoder_text):\n",
        "        ## loaded model\n",
        "        tfhub_bert_encoder = \"https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/2\"\n",
        "        ggelu_bert_encoder = hub.load(tfhub_bert_encoder)\n",
        "        bert_encoder_outputs = [ggelu_bert_encoder(x)['sequence_output'] for x in preprocess_encoder_text]\n",
        "        return bert_encoder_outputs\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        ## BERT encoder\n",
        "        bert_inputs = Input(shape=(None, 768))\n",
        "\n",
        "        ## Decoder 2-layer stacked LSTM\n",
        "        decoder_inputs = Input(shape=(None, ))\n",
        "        decoder_embed = Embedding(input_dim = self.len_de, output_dim = 768)(decoder_inputs)\n",
        "        decoder_LSTM = LSTM(units=768, return_state=True, return_sequences=True)\n",
        "        decoder_LSTM_layer = decoder_LSTM(decoder_embed)\n",
        "        decoder_LSTM2 = LSTM(units=768, return_state=True, return_sequences=True)\n",
        "        decoder_hidden_vec, dec_state_last_h, dec_state_last_c = decoder_LSTM2(decoder_LSTM_layer)\n",
        "        \n",
        "        ## Attention mechanism\n",
        "        attention_score = Dot([2,2])([decoder_hidden_vec, bert_inputs])\n",
        "        attention_weight = Activation('softmax')(attention_score)\n",
        "        context = Dot([2,1])([attention_weight, bert_inputs])\n",
        "        decoder_outputs_combined_context = Concatenate()([context, decoder_hidden_vec])\n",
        "        hidden_state_outputs = TimeDistributed(Dense((self.max_length_de + 2) * 2, activation='tanh'))(decoder_outputs_combined_context)\n",
        "        outputs = TimeDistributed(Dense(self.max_length_de + 2, activation='softmax'))(hidden_state_outputs)\n",
        "\n",
        "        model = tf.keras.Model([bert_inputs, decoder_inputs], outputs)\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "MjmdvnWTpOZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_seq2seq_with_bert(lr, epoch, batch):\n",
        "\n",
        "    optimizer_learning_rate = lr\n",
        "    num_epochs = epoch\n",
        "    num_batch = batch\n",
        "\n",
        "    bert = seq2seq_with_bert(bert_inputs, len(raw_seq[0]), summary_dict, y, 128)\n",
        "    bert_preprocessed = bert.get_bert_preprocessor_outputs()\n",
        "    bert_encoded = bert.get_bert_encoder_embeddings(bert_preprocessed)\n",
        "    bert_seq2seq = bert.build_model()\n",
        "    bert_seq2seq.compile(optimizer=Adam(learning_rate = optimizer_learning_rate), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "    for b in range(len(random_state)):\n",
        "        enc_train, enc_val, dec_train_in, dec_val_in, dec_train_out, dec_val_out = \\\n",
        "          bootstrap_samples(len(bert_encoded), random_state[b], \n",
        "                            [tf.reshape(x, [128,768]) for x in bert_encoded], summary_seq, y)\n",
        "        # training the main model\n",
        "        bert_seq2seq.fit([enc_train, dec_train_in], dec_train_out, \n",
        "                         batch_size = num_batch, epochs = num_epochs, validation_data=([enc_val, dec_val_in], dec_val_out))\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return bert_seq2seq"
      ],
      "metadata": {
        "id": "jNz-UUb3qObv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Business\n",
        "business_bert_seq2seq = training_seq2seq_with_bert(0.00001, 20, 2)"
      ],
      "metadata": {
        "id": "qtB_wEpIJjEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Entertainment\n",
        "entertain_bert_seq2seq = training_seq2seq_with_bert(0.00001, 40, 2)"
      ],
      "metadata": {
        "id": "WS1DZGLDxlJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Politics\n",
        "politics_bert_seq2seq = training_seq2seq_with_bert(0.00001, 40, 2)"
      ],
      "metadata": {
        "id": "jvNilP7fCpO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sports\n",
        "sports_bert_seq2seq = training_seq2seq_with_bert(0.00001, 20, 2)"
      ],
      "metadata": {
        "id": "oaIv8-_CHkxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tech\n",
        "tech_bert_seq2seq = training_seq2seq_with_bert(0.00001, 30, 2)"
      ],
      "metadata": {
        "id": "4GvRCH3uNmgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Business\n",
        "## Encoding vectors for the testing set\n",
        "business_bert_test = seq2seq_with_bert(bert_inputs_busi_test, len(test_raw_seq[0]), test_summary_dict, test_y, 128)\n",
        "business_bert_preprocessed_test = business_bert_test.get_bert_preprocessor_outputs()\n",
        "business_bert_encoded_test = business_bert_test.get_bert_encoder_embeddings(business_bert_preprocessed_test)"
      ],
      "metadata": {
        "id": "aK9SJt96_Y7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), business_bert_seq2seq, test_raw_token_categorized[0], \n",
        "    bert=True, bert_inputs=[x for x in business_bert_encoded_test]\n",
        ")"
      ],
      "metadata": {
        "id": "_YUARPsjP4pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Q2SUQ5NqlJ",
        "outputId": "8aefd61a-a97c-4f95-edb8-ec363f5aa53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.3971\n",
            "Test Result: Mean Precision per Token Position for each document = 0.7884\n",
            "Test Result: Mean Recall per Token Position for each document = 0.4582\n",
            "Test Result: BLEU score = 0.5418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Entertainment\n",
        "## Encoding vectors for the testing set\n",
        "entertain_bert_test = seq2seq_with_bert(bert_inputs_entt_test, len(test_raw_seq[0]), test_summary_dict, test_y, 128)\n",
        "entertain_bert_preprocessed_test = entertain_bert_test.get_bert_preprocessor_outputs()\n",
        "entertain_bert_encoded_test = entertain_bert_test.get_bert_encoder_embeddings(entertain_bert_preprocessed_test)"
      ],
      "metadata": {
        "id": "Nbrbj62781SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), entertain_bert_seq2seq, test_raw_token_categorized[1], \n",
        "    bert=True, bert_inputs=[x for x in entertain_bert_encoded_test]\n",
        ")"
      ],
      "metadata": {
        "id": "Az-Wi6Wv9GPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfjS4ch2HWov",
        "outputId": "2c8dd6c4-b760-48b0-d616-bb796515b45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.0939\n",
            "Test Result: Mean Precision per Token Position for each document = 0.6401\n",
            "Test Result: Mean Recall per Token Position for each document = 0.5576\n",
            "Test Result: BLEU score = 0.4933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Politics\n",
        "## Encoding vectors for the testing set\n",
        "politics_bert_test = seq2seq_with_bert(bert_inputs_polit_test, len(test_raw_seq[0]), test_summary_dict, test_y, 128)\n",
        "politics_bert_preprocessed_test = politics_bert_test.get_bert_preprocessor_outputs()\n",
        "politics_bert_encoded_test = politics_bert_test.get_bert_encoder_embeddings(politics_bert_preprocessed_test)"
      ],
      "metadata": {
        "id": "oYfguPRkFSe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), politics_bert_seq2seq, test_raw_token_categorized[2], \n",
        "    bert=True, bert_inputs=[x for x in politics_bert_encoded_test]\n",
        ")"
      ],
      "metadata": {
        "id": "hGi-SiRKFSfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "id": "3hW8TC7jpOfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c2c89c-a30a-4d66-98b6-9f12e9d4657a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.0668\n",
            "Test Result: Mean Precision per Token Position for each document = 0.5675\n",
            "Test Result: Mean Recall per Token Position for each document = 0.6667\n",
            "Test Result: BLEU score = 0.4923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Sports\n",
        "## Encoding vectors for the testing set\n",
        "sports_bert_test = seq2seq_with_bert(bert_inputs_sport_test, len(test_raw_seq[0]), test_summary_dict, test_y, 128)\n",
        "sports_bert_preprocessed_test = sports_bert_test.get_bert_preprocessor_outputs()\n",
        "sports_bert_encoded_test = sports_bert_test.get_bert_encoder_embeddings(sports_bert_preprocessed_test)"
      ],
      "metadata": {
        "id": "jM_xFF3vLyX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), sports_bert_seq2seq, test_raw_token_categorized[3], \n",
        "    bert=True, bert_inputs=[x for x in sports_bert_encoded_test]\n",
        ")"
      ],
      "metadata": {
        "id": "Q46rtf9HLyYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aboPQtck_Hi0",
        "outputId": "d915ef49-ee47-4874-f19a-c18f49691a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.1902\n",
            "Test Result: Mean Precision per Token Position for each document = 0.485\n",
            "Test Result: Mean Recall per Token Position for each document = 0.4583\n",
            "Test Result: BLEU score = 0.4777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tech\n",
        "## Encoding vectors for the testing set\n",
        "tech_bert_test = seq2seq_with_bert(bert_inputs_tech_test, len(test_raw_seq[0]), test_summary_dict, test_y, 128)\n",
        "tech_bert_preprocessed_test = tech_bert_test.get_bert_preprocessor_outputs()\n",
        "tech_bert_encoded_test = tech_bert_test.get_bert_encoder_embeddings(tech_bert_preprocessed_test)"
      ],
      "metadata": {
        "id": "fq1PQBWkTZeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), tech_bert_seq2seq, test_raw_token_categorized[4], \n",
        "    bert=True, bert_inputs=[x for x in tech_bert_encoded_test]\n",
        ")"
      ],
      "metadata": {
        "id": "NEWUyXTxTZeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVh-lN6SvUMf",
        "outputId": "0b8ed135-551f-49ef-ef8b-3f2ab234d01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.1856\n",
            "Test Result: Mean Precision per Token Position for each document = 0.7495\n",
            "Test Result: Mean Recall per Token Position for each document = 0.3611\n",
            "Test Result: BLEU score = 0.4504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bO8gG-PkU-wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VXmmhMAord1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"), \n",
        "             tf.keras.layers.Dense(embed_dim)]\n",
        "        )\n",
        "        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n",
        "        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "\n",
        "        attention_output = self.attention(query=inputs, value=inputs, key=inputs)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "\n",
        "        return self.layernorm_2(proj_input + proj_output)"
      ],
      "metadata": {
        "id": "_bkSZPTUA6GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  \n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.token_embeddings = tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = embed_dim)\n",
        "        self.position_embeddings = tf.keras.layers.Embedding(input_dim = sequence_length, output_dim = embed_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)"
      ],
      "metadata": {
        "id": "lAUnxP9J_o_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.attention_1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(latent_dim, activation=\"relu\"), \n",
        "             tf.keras.layers.Dense(embed_dim)]\n",
        "        )\n",
        "        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n",
        "        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n",
        "        self.layernorm_3 = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "\n",
        "        attention_output_1 = self.attention_1(query=inputs, value=inputs, key=inputs)\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(query=out_1, value=encoder_outputs, key=encoder_outputs)\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)"
      ],
      "metadata": {
        "id": "XS3UAscr_w3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Transformer_Model():\n",
        "\n",
        "    vocab_size_encoder = len(raw_dict)\n",
        "    vocab_size_decoder = len(summary_dict)\n",
        "    sequence_length_encoder = raw_seq.shape[1]\n",
        "    sequence_length_decoder = summary_seq.shape[1]\n",
        "    embed_dim = round(vocab_size_encoder // 20, -1)\n",
        "    latent_dim = round(vocab_size_encoder // 2, -3)\n",
        "    num_heads = 8\n",
        "\n",
        "    encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "    encoder_x = PositionalEmbedding(sequence_length_encoder, vocab_size_encoder , embed_dim)(encoder_inputs)\n",
        "    encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(encoder_x)\n",
        "\n",
        "    decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "    decoder_x = PositionalEmbedding(sequence_length_decoder, vocab_size_decoder, embed_dim)(decoder_inputs)\n",
        "    decoder_x = TransformerDecoder(embed_dim, latent_dim, num_heads)(decoder_x, encoder_outputs)\n",
        "    decoder_outputs = tf.keras.layers.Dense((sequence_length_decoder + 2) * 2, activation=\"relu\")(decoder_x)\n",
        "    decoder_outputs = tf.keras.layers.Dense(sequence_length_decoder + 2, activation=\"softmax\")(decoder_outputs)\n",
        "\n",
        "    transformer = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")\n",
        "\n",
        "    return transformer"
      ],
      "metadata": {
        "id": "NX8_5ub8A683"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_Transformer(lr, epoch, batch):\n",
        "\n",
        "    optimizer_learning_rate = lr\n",
        "    num_epochs = epoch\n",
        "    num_batch = batch\n",
        "\n",
        "    tfm = Transformer_Model()\n",
        "    tfm.compile(optimizer=Adam(learning_rate = optimizer_learning_rate), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "    for b in range(len(random_state)):\n",
        "        enc_train, enc_val, dec_train_in, dec_val_in, dec_train_out, dec_val_out = \\\n",
        "          bootstrap_samples(len(raw_seq), random_state[b], raw_seq, summary_seq, y)\n",
        "        # training the main model\n",
        "        tfm.fit([enc_train, dec_train_in], dec_train_out, \n",
        "                batch_size = num_batch, epochs = num_epochs, validation_data=([enc_val, dec_val_in], dec_val_out))\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return tfm"
      ],
      "metadata": {
        "id": "q-3iUgW4y01Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Business\n",
        "busi_tfm = training_Transformer(0.00001, 10, 4)"
      ],
      "metadata": {
        "id": "SYkYhFpSAzZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Entertainment\n",
        "entt_tfm = training_Transformer(0.00001, 10, 4)"
      ],
      "metadata": {
        "id": "1pwgnai9HTvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Politics\n",
        "polit_tfm = training_Transformer(0.00001, 10, 4)"
      ],
      "metadata": {
        "id": "yZDfGs1pRCL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sports\n",
        "sport_tfm = training_Transformer(0.00001, 10, 4)"
      ],
      "metadata": {
        "id": "vRY59ChCRWVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tech\n",
        "tech_tfm = training_Transformer(0.00001, 10, 4)"
      ],
      "metadata": {
        "id": "WCHZni2CRCRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Business\n",
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), busi_tfm, test_raw_token_categorized[0]\n",
        ")"
      ],
      "metadata": {
        "id": "NMrivEnLz_bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYXc875FE97g",
        "outputId": "6c20b3eb-0472-4ea8-e9fa-c8bd6ab7df7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.3654\n",
            "Test Result: Mean Precision per Token Position for each document = 0.363\n",
            "Test Result: Mean Recall per Token Position for each document = 0.6087\n",
            "Test Result: BLEU score = 0.4963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Entertainment\n",
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), entt_tfm, test_raw_token_categorized[1]\n",
        ")"
      ],
      "metadata": {
        "id": "UHOh9ywFG2dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUkfSU-oKvrK",
        "outputId": "a42d93bd-e122-4d53-c900-0963c840d83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.0776\n",
            "Test Result: Mean Precision per Token Position for each document = 0.3446\n",
            "Test Result: Mean Recall per Token Position for each document = 0.573\n",
            "Test Result: BLEU score = 0.4895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Politics\n",
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), polit_tfm, test_raw_token_categorized[2]\n",
        ")"
      ],
      "metadata": {
        "id": "3AIRkWwSYBdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhWSm9zKUrS1",
        "outputId": "2a463c47-3028-4a23-c018-d5d97831c8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.0875\n",
            "Test Result: Mean Precision per Token Position for each document = 0.4047\n",
            "Test Result: Mean Recall per Token Position for each document = 0.7103\n",
            "Test Result: BLEU score = 0.4945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Sports\n",
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), polit_tfm, test_raw_token_categorized[3]\n",
        ")"
      ],
      "metadata": {
        "id": "bu-YR1Rjcvf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYz77tGndzuB",
        "outputId": "590c88eb-e878-4adf-b3e9-784db551a801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.2375\n",
            "Test Result: Mean Precision per Token Position for each document = 0.3132\n",
            "Test Result: Mean Recall per Token Position for each document = 0.8737\n",
            "Test Result: BLEU score = 0.4897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tech\n",
        "avg_acc, avg_precision, avg_recall, bleu, inference_seq, predicted_seq = evaluate_sequence_batch(\n",
        "    len(summary_seq[0]), polit_tfm, test_raw_token_categorized[4]\n",
        ")"
      ],
      "metadata": {
        "id": "huR4LKz3YPG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Result: Mean Accuracy per Token Position for each document = \" + str(round(avg_acc[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Precision per Token Position for each document = \" + str(round(avg_precision[0], ndigits=4)))\n",
        "print(\"Test Result: Mean Recall per Token Position for each document = \" + str(round(avg_recall[0], ndigits=4)))\n",
        "print(\"Test Result: BLEU score = \" + str(round(bleu[0], ndigits=4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3_Y5og5UrYS",
        "outputId": "1c2b3f26-7fe8-4d0c-a5a6-6d401ba381df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: Mean Accuracy per Token Position for each document = 0.1091\n",
            "Test Result: Mean Precision per Token Position for each document = 0.3617\n",
            "Test Result: Mean Recall per Token Position for each document = 0.7109\n",
            "Test Result: BLEU score = 0.4278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZP3Ytb-mns3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LOZvLVsrzWOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}