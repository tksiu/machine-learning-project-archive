{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Short text NLP inference (keyword extraction & abbreviation detection & Seq2Seq) on allocation problem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5SjjRrQmV0I",
        "colab_type": "text"
      },
      "source": [
        "## **Text-based inference on a production allocation problem (keyword extraction, abbreviation detection, seq2seq encoder-decoder)**\n",
        "\n",
        "Information Extraction (IE) is one of the most active research topics in natural languag processing (NLP) domain, comprising of a number of sophisticated tasks to go through prior to being able to make human-like inference digesting on the input texts. Tokenization, POS tagging, anguage models, entity recognition, text summarizations, neural machine translations, etc. are bunch of work analysts might play with to get the unstructured form of strings to be analyzable and predictable to complete targets on custom contexts.\n",
        "\n",
        "\n",
        "In a highly dynamic and uncertian business operation of a supply chain or production environment, how many resources were to be allocated to specific parties may sometimes not be easily clear-cut. External factors like the development lead time, availability of raw materials and warehouse capacity constraints could change the rules frequently. \n",
        "\n",
        "\n",
        "For a problem trying to automatically deduce the rules based on some short texts of instructions, with as minimal supervised efforts and prior expertise as possible, these short texts consisted of short forms of named parties, implicit or explicit numerical expressions, and even some latent contextual meanings, e.g. when it was meant to be equally shared, the machine needs to consider the number of parties involved and simply dividing 100% by it. But it would be extremely inefficient to write if-else condition programme to define actions to take, and also difficult to pin-point the short forms to the special nouns which were specific in my context that no pre-trained corpa of named entities could help.\n",
        "\n",
        "\n",
        "To complete such challenge using NLP techniques, my idea included extracting keywords from the instruction texts by building a classifier, converting the short forms by a self-defined matching function, and constructing an encoder-decoder structure of seq2seq model to learn the rules between named parties and their percentages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EooHxaOCm7-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ql5hnbYLQ17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6yv05IqLaDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('NLP information extraction and allocation action.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FXd8w4WXr8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Extract vendor name and vendor class entities\n",
        "## Tokenize the short texts of allocation rules\n",
        "\n",
        "identity = []\n",
        "combined_text = []\n",
        "tokenized_text = []\n",
        "word_list = []\n",
        "\n",
        "n = 0\n",
        "k = 1\n",
        "for i in range(1, len(df)):\n",
        "  if df['5-digit Item Number'][i]!=df['5-digit Item Number'][i-1]:\n",
        "    k += 1\n",
        "\n",
        "for j in range(k):\n",
        "  while (not identity) or (df['5-digit Item Number'][n]==df['5-digit Item Number'][n-1]):\n",
        "    identity.append(df[['Vendor Name', 'Vendor Class']].iloc[n].apply(lambda x: ''.join(x)).values)\n",
        "    n += 1\n",
        "    if n >= len(df):\n",
        "      break\n",
        "\n",
        "  series = list(np.array(identity).flatten())\n",
        "  series = [x.lower() for x in series]\n",
        "  series = [x.strip() for x in series]\n",
        "\n",
        "  combined_text.append(series)\n",
        "  identity = []\n",
        "\n",
        "  processed_text = df['Allocation rules'][n-1]\n",
        "  processed_text = processed_text.lower()\n",
        "  processed_text = processed_text.strip()\n",
        "  processed_text = re.findall(r'\\d+\\.?\\d+?%|\\d+?%|\\d+/\\d+/\\d+|\\w+', processed_text)\n",
        "  tokenized_text.append(processed_text)\n",
        "  \n",
        "  ## Make tokens of vendor names consistent before word2vec; \n",
        "  ## handling cases like of mis-spelling / missing space in-between the names\n",
        "  \n",
        "  for v in range(0, len(combined_text[j]), 2):\n",
        "    if len(combined_text[j][v].split()) > 1:\n",
        "      w = 0\n",
        "      while w < len(tokenized_text[j]):\n",
        "        if tokenized_text[j][w]==combined_text[j][v].split()[0]:\n",
        "          m = 0\n",
        "          while tokenized_text[j][w+m]==combined_text[j][v].split()[m]:\n",
        "            m += 1\n",
        "            if m >= len(combined_text[j][v].split()) or w + 1 >= len(tokenized_text[j]):\n",
        "              break\n",
        "          if m > 1 or len(combined_text[j][v].split()) > 1:\n",
        "            tokenized_text[j][w:w+m] = []\n",
        "            tokenized_text[j].insert(w, combined_text[j][v])\n",
        "        w += 1\n",
        "        if w + 1 > len(tokenized_text[j]):\n",
        "          break\n",
        "          \n",
        "  word_list.append(combined_text[j] + tokenized_text[j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYK_V4-SAXzj",
        "colab_type": "text"
      },
      "source": [
        "### Word representations:\n",
        "\n",
        "The above operations tokenized the raw strings, and read the entities (factory name and factory category) into respective lists. For processing information from text data, Word2Vec is a common technique to obtain neural representations of the texts. It can be used as features in the keyword classification task. I tested to query the top relevant words for the abbreviation tokens, and the fitted word2vec model successfully returned the desired token as the most similar word for some of them, e.g. \"fs\" matched with \"funskool\". Though \"mp\" also found \"micro plastics\" in the 6th position, it showed that the word2vec model was still not robust enough to detect correctly the referred word of each abbreviation in the corpus.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WyyOsMnlANW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import word2vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m2WNcrPM1zW",
        "colab_type": "code",
        "outputId": "f4d059b0-50ca-414e-d27d-a47f45f0ade6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## use Word2Vec to find nearest neighbouring expressions for mining abbreviations related to name entities\n",
        "w2v = word2vec.Word2Vec(word_list, size=1000, window=3, min_count=1, seed=42)\n",
        "w2v.train(word_list, total_examples=len(word_list), epochs=500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(827568, 1942500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMdehSjog_Vc",
        "colab_type": "code",
        "outputId": "a805fe6d-fe21-4654-b79c-aae1a4fc5fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "## load the trained word2vec model\n",
        "w2v = word2vec.Word2Vec.load(\"allocation word vectors\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN_qts6bz7xE",
        "colab_type": "code",
        "outputId": "6e8dfa46-56e8-4613-c7a0-341a6ae6b131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v.wv.most_similar('mp')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('check', 0.5507981777191162),\n",
              " ('gsp', 0.46539390087127686),\n",
              " ('growth master', 0.460766464471817),\n",
              " ('allocation', 0.41754984855651855),\n",
              " ('gm', 0.41087865829467773),\n",
              " ('micro plastics', 0.37347841262817383),\n",
              " ('kh', 0.3706154227256775),\n",
              " ('40%', 0.3654845356941223),\n",
              " ('60%', 0.3639428913593292),\n",
              " ('45%', 0.34594470262527466)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbyIkrpz3pmH",
        "colab_type": "code",
        "outputId": "6cfff8aa-110b-440d-eba3-e6c5b86eaf9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v.wv.most_similar('fs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('funskool', 0.8913756608963013),\n",
              " ('90%', 0.7004472613334656),\n",
              " ('item', 0.6796683073043823),\n",
              " ('growth master', 0.6771235466003418),\n",
              " ('wt', 0.6760456562042236),\n",
              " ('under', 0.6524773240089417),\n",
              " ('gm', 0.6307111382484436),\n",
              " ('35%', 0.602761447429657),\n",
              " ('ex', 0.6009894609451294),\n",
              " ('2.1%', 0.5619425773620605)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0WWCQuz1909",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## save vocab list\n",
        "vocab = w2v.wv.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riNZH_xDOeSx",
        "colab_type": "text"
      },
      "source": [
        "### Transforming tokens into dataframe for manual annotations & Classification problem to tag keyowrds:\n",
        "\n",
        "For each short text being of different lengths, I re-construct a dataframe format to present each token in a row, allowing easy creations of fields for tagging of  keywords and abbreviations. Here, I load the tagged dataset, map the word2vec features and import them for training a Gradient Boosting classifier on the binary indicator of keywords. Overall, 92% of balanced-class accuracy and 93% of F1 score have been achieved. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0KuD6pngng4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Construct a dataframe of vocab\n",
        "vocab_item = []\n",
        "vocab_df = []\n",
        "\n",
        "k = 1\n",
        "for i in range(1, len(df)):\n",
        "  if not vocab_item:\n",
        "    vocab_item.append(df['5-digit Item Number'][0])\n",
        "  if df['5-digit Item Number'][i]!=df['5-digit Item Number'][i-1]:\n",
        "    k += 1\n",
        "    vocab_item.append(df['5-digit Item Number'][i])\n",
        "\n",
        "for j in range(k):\n",
        "  vocab_df.append(pd.concat([pd.Series([vocab_item[j]]*len(tokenized_text[j])), \n",
        "                             pd.Series(np.array(tokenized_text[j]).reshape(len(tokenized_text[j]), ))], \n",
        "                            axis=1))\n",
        "  \n",
        "vocab_df = pd.concat(vocab_df, axis=0)\n",
        "vocab_df.columns = ['Item', 'Token']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhKoTsPaFMul",
        "colab_type": "code",
        "outputId": "2f6dcdfa-e21f-4769-cd75-65b18e114e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "## manually tagged dataset\n",
        "vocab_df = pd.read_csv('keyword_encode_2.csv')\n",
        "vocab_df.iloc[0:5,1:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Critical Word Indicator</th>\n",
              "      <th>Abbreviation Token Indicator</th>\n",
              "      <th>Abbr_Name</th>\n",
              "      <th>Abbr_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fy</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>target</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>keep</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jp</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>remove</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Token  Critical Word Indicator  ...  Abbr_Name  Abbr_Class\n",
              "0      fy                        0  ...          0           0\n",
              "1  target                        0  ...          0           0\n",
              "2    keep                        1  ...          0           0\n",
              "3      jp                        1  ...          1           0\n",
              "4  remove                        1  ...          0           0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icXRP4sYT3P0",
        "colab_type": "code",
        "outputId": "e45a292d-07ac-48cd-a16c-7a7776f8e09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## For classification of critical words,\n",
        "## Map the trained word vectors for each word\n",
        "\n",
        "word_vec = []\n",
        "word_vec_dim = []\n",
        "\n",
        "for x in range(len(vocab_df)):\n",
        "  word_vec.append(pd.DataFrame(w2v[vocab_df['Token'][x]]).transpose())\n",
        "\n",
        "for dim in range(1000):\n",
        "  word_vec_dim.append('Dim' + str(dim + 1))\n",
        "\n",
        "word_vec_df = pd.concat(word_vec, axis=0)\n",
        "word_vec_df.columns = word_vec_dim\n",
        "word_vec_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "word_vec_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dim1</th>\n",
              "      <th>Dim2</th>\n",
              "      <th>Dim3</th>\n",
              "      <th>Dim4</th>\n",
              "      <th>Dim5</th>\n",
              "      <th>Dim6</th>\n",
              "      <th>Dim7</th>\n",
              "      <th>Dim8</th>\n",
              "      <th>Dim9</th>\n",
              "      <th>Dim10</th>\n",
              "      <th>Dim11</th>\n",
              "      <th>Dim12</th>\n",
              "      <th>Dim13</th>\n",
              "      <th>Dim14</th>\n",
              "      <th>Dim15</th>\n",
              "      <th>Dim16</th>\n",
              "      <th>Dim17</th>\n",
              "      <th>Dim18</th>\n",
              "      <th>Dim19</th>\n",
              "      <th>Dim20</th>\n",
              "      <th>Dim21</th>\n",
              "      <th>Dim22</th>\n",
              "      <th>Dim23</th>\n",
              "      <th>Dim24</th>\n",
              "      <th>Dim25</th>\n",
              "      <th>Dim26</th>\n",
              "      <th>Dim27</th>\n",
              "      <th>Dim28</th>\n",
              "      <th>Dim29</th>\n",
              "      <th>Dim30</th>\n",
              "      <th>Dim31</th>\n",
              "      <th>Dim32</th>\n",
              "      <th>Dim33</th>\n",
              "      <th>Dim34</th>\n",
              "      <th>Dim35</th>\n",
              "      <th>Dim36</th>\n",
              "      <th>Dim37</th>\n",
              "      <th>Dim38</th>\n",
              "      <th>Dim39</th>\n",
              "      <th>Dim40</th>\n",
              "      <th>...</th>\n",
              "      <th>Dim961</th>\n",
              "      <th>Dim962</th>\n",
              "      <th>Dim963</th>\n",
              "      <th>Dim964</th>\n",
              "      <th>Dim965</th>\n",
              "      <th>Dim966</th>\n",
              "      <th>Dim967</th>\n",
              "      <th>Dim968</th>\n",
              "      <th>Dim969</th>\n",
              "      <th>Dim970</th>\n",
              "      <th>Dim971</th>\n",
              "      <th>Dim972</th>\n",
              "      <th>Dim973</th>\n",
              "      <th>Dim974</th>\n",
              "      <th>Dim975</th>\n",
              "      <th>Dim976</th>\n",
              "      <th>Dim977</th>\n",
              "      <th>Dim978</th>\n",
              "      <th>Dim979</th>\n",
              "      <th>Dim980</th>\n",
              "      <th>Dim981</th>\n",
              "      <th>Dim982</th>\n",
              "      <th>Dim983</th>\n",
              "      <th>Dim984</th>\n",
              "      <th>Dim985</th>\n",
              "      <th>Dim986</th>\n",
              "      <th>Dim987</th>\n",
              "      <th>Dim988</th>\n",
              "      <th>Dim989</th>\n",
              "      <th>Dim990</th>\n",
              "      <th>Dim991</th>\n",
              "      <th>Dim992</th>\n",
              "      <th>Dim993</th>\n",
              "      <th>Dim994</th>\n",
              "      <th>Dim995</th>\n",
              "      <th>Dim996</th>\n",
              "      <th>Dim997</th>\n",
              "      <th>Dim998</th>\n",
              "      <th>Dim999</th>\n",
              "      <th>Dim1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.079781</td>\n",
              "      <td>-0.025519</td>\n",
              "      <td>-0.243857</td>\n",
              "      <td>0.481250</td>\n",
              "      <td>-0.097796</td>\n",
              "      <td>-0.025103</td>\n",
              "      <td>0.096601</td>\n",
              "      <td>0.291724</td>\n",
              "      <td>-0.456119</td>\n",
              "      <td>-0.527140</td>\n",
              "      <td>-0.492613</td>\n",
              "      <td>-0.523470</td>\n",
              "      <td>0.057695</td>\n",
              "      <td>0.069989</td>\n",
              "      <td>0.291863</td>\n",
              "      <td>-0.085822</td>\n",
              "      <td>-0.160219</td>\n",
              "      <td>0.104416</td>\n",
              "      <td>-0.224287</td>\n",
              "      <td>-0.249879</td>\n",
              "      <td>-0.227970</td>\n",
              "      <td>0.352441</td>\n",
              "      <td>0.137310</td>\n",
              "      <td>-0.031105</td>\n",
              "      <td>-0.292824</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>0.384589</td>\n",
              "      <td>-0.171379</td>\n",
              "      <td>0.141584</td>\n",
              "      <td>0.191231</td>\n",
              "      <td>-0.029099</td>\n",
              "      <td>-0.054023</td>\n",
              "      <td>0.066428</td>\n",
              "      <td>-0.333136</td>\n",
              "      <td>0.065857</td>\n",
              "      <td>-0.119944</td>\n",
              "      <td>0.190828</td>\n",
              "      <td>0.419122</td>\n",
              "      <td>-0.147303</td>\n",
              "      <td>0.160678</td>\n",
              "      <td>...</td>\n",
              "      <td>0.491943</td>\n",
              "      <td>-0.233385</td>\n",
              "      <td>-0.110467</td>\n",
              "      <td>0.176024</td>\n",
              "      <td>-0.132378</td>\n",
              "      <td>0.034769</td>\n",
              "      <td>-0.170813</td>\n",
              "      <td>-0.419283</td>\n",
              "      <td>0.432286</td>\n",
              "      <td>0.342213</td>\n",
              "      <td>-0.521197</td>\n",
              "      <td>-0.300880</td>\n",
              "      <td>-0.256072</td>\n",
              "      <td>0.147677</td>\n",
              "      <td>0.017774</td>\n",
              "      <td>-0.079317</td>\n",
              "      <td>0.233280</td>\n",
              "      <td>-0.723025</td>\n",
              "      <td>0.320899</td>\n",
              "      <td>0.387058</td>\n",
              "      <td>-0.136161</td>\n",
              "      <td>-0.100076</td>\n",
              "      <td>-0.115502</td>\n",
              "      <td>-0.366601</td>\n",
              "      <td>-0.481600</td>\n",
              "      <td>0.230335</td>\n",
              "      <td>-0.186191</td>\n",
              "      <td>0.341697</td>\n",
              "      <td>-0.063077</td>\n",
              "      <td>0.236464</td>\n",
              "      <td>0.179565</td>\n",
              "      <td>0.499097</td>\n",
              "      <td>0.384646</td>\n",
              "      <td>0.061515</td>\n",
              "      <td>0.026558</td>\n",
              "      <td>-0.441899</td>\n",
              "      <td>0.105285</td>\n",
              "      <td>-0.091680</td>\n",
              "      <td>0.157746</td>\n",
              "      <td>0.151333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.183910</td>\n",
              "      <td>-0.061212</td>\n",
              "      <td>0.129800</td>\n",
              "      <td>0.520310</td>\n",
              "      <td>-0.011274</td>\n",
              "      <td>0.357148</td>\n",
              "      <td>-0.276536</td>\n",
              "      <td>0.138316</td>\n",
              "      <td>0.168843</td>\n",
              "      <td>-0.218067</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>-0.393613</td>\n",
              "      <td>0.588654</td>\n",
              "      <td>-0.389109</td>\n",
              "      <td>0.642491</td>\n",
              "      <td>0.075533</td>\n",
              "      <td>0.383125</td>\n",
              "      <td>-0.088680</td>\n",
              "      <td>0.355325</td>\n",
              "      <td>0.174431</td>\n",
              "      <td>0.021438</td>\n",
              "      <td>-0.014471</td>\n",
              "      <td>-0.222796</td>\n",
              "      <td>-0.398659</td>\n",
              "      <td>-0.249722</td>\n",
              "      <td>-0.352323</td>\n",
              "      <td>-0.184781</td>\n",
              "      <td>-0.310528</td>\n",
              "      <td>-0.057301</td>\n",
              "      <td>0.047881</td>\n",
              "      <td>-0.292628</td>\n",
              "      <td>-0.197707</td>\n",
              "      <td>0.057850</td>\n",
              "      <td>-0.606778</td>\n",
              "      <td>0.315939</td>\n",
              "      <td>-0.085344</td>\n",
              "      <td>0.247765</td>\n",
              "      <td>0.667252</td>\n",
              "      <td>0.321471</td>\n",
              "      <td>-0.014339</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008724</td>\n",
              "      <td>-0.055227</td>\n",
              "      <td>0.058422</td>\n",
              "      <td>0.092477</td>\n",
              "      <td>-0.103028</td>\n",
              "      <td>-0.340897</td>\n",
              "      <td>0.357281</td>\n",
              "      <td>0.079935</td>\n",
              "      <td>0.123921</td>\n",
              "      <td>-0.079473</td>\n",
              "      <td>-0.006668</td>\n",
              "      <td>0.081586</td>\n",
              "      <td>0.088914</td>\n",
              "      <td>-0.010275</td>\n",
              "      <td>-0.319333</td>\n",
              "      <td>0.317449</td>\n",
              "      <td>0.205100</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>-0.007748</td>\n",
              "      <td>0.345069</td>\n",
              "      <td>-0.128609</td>\n",
              "      <td>0.009163</td>\n",
              "      <td>-0.139763</td>\n",
              "      <td>-0.364857</td>\n",
              "      <td>-0.124788</td>\n",
              "      <td>-0.283637</td>\n",
              "      <td>-0.016459</td>\n",
              "      <td>0.235692</td>\n",
              "      <td>0.049831</td>\n",
              "      <td>0.174068</td>\n",
              "      <td>0.137410</td>\n",
              "      <td>0.120423</td>\n",
              "      <td>0.049469</td>\n",
              "      <td>0.514741</td>\n",
              "      <td>0.224115</td>\n",
              "      <td>-0.366353</td>\n",
              "      <td>-0.273836</td>\n",
              "      <td>0.234740</td>\n",
              "      <td>0.307678</td>\n",
              "      <td>0.253161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.271267</td>\n",
              "      <td>0.124715</td>\n",
              "      <td>0.024563</td>\n",
              "      <td>-0.094865</td>\n",
              "      <td>0.091894</td>\n",
              "      <td>0.062833</td>\n",
              "      <td>0.100830</td>\n",
              "      <td>0.017258</td>\n",
              "      <td>-0.022628</td>\n",
              "      <td>0.120851</td>\n",
              "      <td>0.005456</td>\n",
              "      <td>0.179561</td>\n",
              "      <td>0.145151</td>\n",
              "      <td>-0.274339</td>\n",
              "      <td>0.257788</td>\n",
              "      <td>0.043923</td>\n",
              "      <td>0.388484</td>\n",
              "      <td>0.002192</td>\n",
              "      <td>-0.009557</td>\n",
              "      <td>-0.321865</td>\n",
              "      <td>-0.102209</td>\n",
              "      <td>0.244217</td>\n",
              "      <td>0.220352</td>\n",
              "      <td>0.033578</td>\n",
              "      <td>0.139470</td>\n",
              "      <td>-0.269418</td>\n",
              "      <td>0.078591</td>\n",
              "      <td>0.318461</td>\n",
              "      <td>0.018931</td>\n",
              "      <td>0.003448</td>\n",
              "      <td>-0.111183</td>\n",
              "      <td>-0.190392</td>\n",
              "      <td>-0.032441</td>\n",
              "      <td>0.191246</td>\n",
              "      <td>0.098037</td>\n",
              "      <td>-0.207961</td>\n",
              "      <td>0.325078</td>\n",
              "      <td>-0.145846</td>\n",
              "      <td>-0.483748</td>\n",
              "      <td>-0.166002</td>\n",
              "      <td>...</td>\n",
              "      <td>0.053646</td>\n",
              "      <td>-0.069114</td>\n",
              "      <td>-0.075449</td>\n",
              "      <td>0.055255</td>\n",
              "      <td>-0.393169</td>\n",
              "      <td>-0.066259</td>\n",
              "      <td>0.134060</td>\n",
              "      <td>0.162547</td>\n",
              "      <td>-0.021797</td>\n",
              "      <td>-0.137397</td>\n",
              "      <td>0.233625</td>\n",
              "      <td>-0.139859</td>\n",
              "      <td>-0.098502</td>\n",
              "      <td>0.256120</td>\n",
              "      <td>0.167748</td>\n",
              "      <td>0.031214</td>\n",
              "      <td>0.318820</td>\n",
              "      <td>-0.205395</td>\n",
              "      <td>-0.200689</td>\n",
              "      <td>-0.161129</td>\n",
              "      <td>-0.120770</td>\n",
              "      <td>0.007059</td>\n",
              "      <td>0.116352</td>\n",
              "      <td>-0.054278</td>\n",
              "      <td>0.043781</td>\n",
              "      <td>0.067517</td>\n",
              "      <td>0.208657</td>\n",
              "      <td>0.226606</td>\n",
              "      <td>-0.309472</td>\n",
              "      <td>0.120875</td>\n",
              "      <td>0.193496</td>\n",
              "      <td>0.283361</td>\n",
              "      <td>0.050496</td>\n",
              "      <td>-0.081303</td>\n",
              "      <td>0.132771</td>\n",
              "      <td>-0.360822</td>\n",
              "      <td>-0.000573</td>\n",
              "      <td>-0.373614</td>\n",
              "      <td>0.108963</td>\n",
              "      <td>0.042342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.334936</td>\n",
              "      <td>-0.237400</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>0.307774</td>\n",
              "      <td>0.552991</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>-0.128793</td>\n",
              "      <td>0.184903</td>\n",
              "      <td>-0.300067</td>\n",
              "      <td>-0.160469</td>\n",
              "      <td>-0.137007</td>\n",
              "      <td>-0.380960</td>\n",
              "      <td>0.067295</td>\n",
              "      <td>-0.350619</td>\n",
              "      <td>0.319733</td>\n",
              "      <td>0.312155</td>\n",
              "      <td>0.234408</td>\n",
              "      <td>0.456366</td>\n",
              "      <td>0.103505</td>\n",
              "      <td>-0.163476</td>\n",
              "      <td>-0.112946</td>\n",
              "      <td>0.273597</td>\n",
              "      <td>0.274887</td>\n",
              "      <td>-0.008497</td>\n",
              "      <td>-0.404606</td>\n",
              "      <td>-0.219477</td>\n",
              "      <td>0.200002</td>\n",
              "      <td>0.470362</td>\n",
              "      <td>0.067487</td>\n",
              "      <td>-0.013588</td>\n",
              "      <td>-0.049962</td>\n",
              "      <td>-0.066518</td>\n",
              "      <td>-0.108149</td>\n",
              "      <td>-0.090050</td>\n",
              "      <td>0.477854</td>\n",
              "      <td>-0.432016</td>\n",
              "      <td>0.279654</td>\n",
              "      <td>0.297045</td>\n",
              "      <td>-0.167063</td>\n",
              "      <td>0.094208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>-0.071417</td>\n",
              "      <td>-0.103228</td>\n",
              "      <td>-0.008193</td>\n",
              "      <td>-0.482496</td>\n",
              "      <td>-0.107093</td>\n",
              "      <td>0.380227</td>\n",
              "      <td>-0.081455</td>\n",
              "      <td>0.418951</td>\n",
              "      <td>-0.213351</td>\n",
              "      <td>-0.182586</td>\n",
              "      <td>-0.167677</td>\n",
              "      <td>0.183418</td>\n",
              "      <td>-0.053785</td>\n",
              "      <td>0.092943</td>\n",
              "      <td>-0.330301</td>\n",
              "      <td>-0.024515</td>\n",
              "      <td>-0.559753</td>\n",
              "      <td>0.022932</td>\n",
              "      <td>0.180525</td>\n",
              "      <td>0.188712</td>\n",
              "      <td>0.027331</td>\n",
              "      <td>-0.235138</td>\n",
              "      <td>-0.330035</td>\n",
              "      <td>0.122914</td>\n",
              "      <td>0.102582</td>\n",
              "      <td>-0.103969</td>\n",
              "      <td>-0.070550</td>\n",
              "      <td>-0.079660</td>\n",
              "      <td>0.035513</td>\n",
              "      <td>-0.149414</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>-0.103845</td>\n",
              "      <td>0.242430</td>\n",
              "      <td>0.017625</td>\n",
              "      <td>-0.328206</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.093238</td>\n",
              "      <td>0.037537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.127603</td>\n",
              "      <td>0.146247</td>\n",
              "      <td>-0.090662</td>\n",
              "      <td>-0.003150</td>\n",
              "      <td>-0.134571</td>\n",
              "      <td>-0.179288</td>\n",
              "      <td>0.151212</td>\n",
              "      <td>-0.235700</td>\n",
              "      <td>-0.211594</td>\n",
              "      <td>0.191210</td>\n",
              "      <td>0.101248</td>\n",
              "      <td>0.148342</td>\n",
              "      <td>0.046597</td>\n",
              "      <td>-0.303030</td>\n",
              "      <td>0.110344</td>\n",
              "      <td>-0.064218</td>\n",
              "      <td>0.293248</td>\n",
              "      <td>0.008584</td>\n",
              "      <td>-0.247761</td>\n",
              "      <td>-0.101321</td>\n",
              "      <td>0.153911</td>\n",
              "      <td>0.034562</td>\n",
              "      <td>0.227221</td>\n",
              "      <td>-0.114165</td>\n",
              "      <td>-0.025303</td>\n",
              "      <td>-0.336854</td>\n",
              "      <td>0.231757</td>\n",
              "      <td>-0.088892</td>\n",
              "      <td>-0.383875</td>\n",
              "      <td>0.013731</td>\n",
              "      <td>-0.083015</td>\n",
              "      <td>-0.102411</td>\n",
              "      <td>0.060261</td>\n",
              "      <td>0.046408</td>\n",
              "      <td>-0.071695</td>\n",
              "      <td>-0.071815</td>\n",
              "      <td>0.122069</td>\n",
              "      <td>-0.096766</td>\n",
              "      <td>-0.461869</td>\n",
              "      <td>-0.396110</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006019</td>\n",
              "      <td>0.224938</td>\n",
              "      <td>0.450019</td>\n",
              "      <td>0.103116</td>\n",
              "      <td>-0.477780</td>\n",
              "      <td>0.180737</td>\n",
              "      <td>0.233281</td>\n",
              "      <td>-0.350057</td>\n",
              "      <td>-0.360580</td>\n",
              "      <td>0.072298</td>\n",
              "      <td>0.610170</td>\n",
              "      <td>0.077580</td>\n",
              "      <td>-0.379926</td>\n",
              "      <td>0.154614</td>\n",
              "      <td>0.459915</td>\n",
              "      <td>0.218706</td>\n",
              "      <td>-0.019017</td>\n",
              "      <td>-0.152010</td>\n",
              "      <td>-0.155587</td>\n",
              "      <td>-0.052518</td>\n",
              "      <td>-0.018161</td>\n",
              "      <td>0.111680</td>\n",
              "      <td>0.089554</td>\n",
              "      <td>-0.123803</td>\n",
              "      <td>-0.360023</td>\n",
              "      <td>-0.430826</td>\n",
              "      <td>-0.089904</td>\n",
              "      <td>0.501573</td>\n",
              "      <td>-0.132513</td>\n",
              "      <td>-0.036738</td>\n",
              "      <td>0.229372</td>\n",
              "      <td>0.062292</td>\n",
              "      <td>0.022761</td>\n",
              "      <td>0.130935</td>\n",
              "      <td>-0.145899</td>\n",
              "      <td>-0.445411</td>\n",
              "      <td>0.181044</td>\n",
              "      <td>-0.870611</td>\n",
              "      <td>0.122402</td>\n",
              "      <td>-0.205108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.034763</td>\n",
              "      <td>-0.161011</td>\n",
              "      <td>0.140570</td>\n",
              "      <td>0.175992</td>\n",
              "      <td>0.459962</td>\n",
              "      <td>-0.242631</td>\n",
              "      <td>-0.051741</td>\n",
              "      <td>-0.128755</td>\n",
              "      <td>-0.103677</td>\n",
              "      <td>0.199563</td>\n",
              "      <td>0.148768</td>\n",
              "      <td>-0.170274</td>\n",
              "      <td>0.048759</td>\n",
              "      <td>-0.182653</td>\n",
              "      <td>0.170006</td>\n",
              "      <td>0.142879</td>\n",
              "      <td>0.371174</td>\n",
              "      <td>0.162317</td>\n",
              "      <td>0.039228</td>\n",
              "      <td>-0.147637</td>\n",
              "      <td>-0.082493</td>\n",
              "      <td>0.169107</td>\n",
              "      <td>0.159363</td>\n",
              "      <td>-0.050029</td>\n",
              "      <td>-0.253319</td>\n",
              "      <td>-0.006641</td>\n",
              "      <td>0.125198</td>\n",
              "      <td>0.405186</td>\n",
              "      <td>-0.030552</td>\n",
              "      <td>0.112613</td>\n",
              "      <td>0.132836</td>\n",
              "      <td>0.021062</td>\n",
              "      <td>-0.007054</td>\n",
              "      <td>0.252117</td>\n",
              "      <td>0.444617</td>\n",
              "      <td>-0.160032</td>\n",
              "      <td>0.111042</td>\n",
              "      <td>0.080811</td>\n",
              "      <td>-0.343690</td>\n",
              "      <td>-0.009980</td>\n",
              "      <td>...</td>\n",
              "      <td>0.224006</td>\n",
              "      <td>-0.061652</td>\n",
              "      <td>-0.208635</td>\n",
              "      <td>-0.064257</td>\n",
              "      <td>-0.036795</td>\n",
              "      <td>-0.040645</td>\n",
              "      <td>0.127223</td>\n",
              "      <td>0.199031</td>\n",
              "      <td>-0.140367</td>\n",
              "      <td>-0.037575</td>\n",
              "      <td>-0.032066</td>\n",
              "      <td>0.010635</td>\n",
              "      <td>-0.133837</td>\n",
              "      <td>0.170067</td>\n",
              "      <td>0.165061</td>\n",
              "      <td>0.126627</td>\n",
              "      <td>-0.377569</td>\n",
              "      <td>-0.390835</td>\n",
              "      <td>-0.121297</td>\n",
              "      <td>-0.071974</td>\n",
              "      <td>0.188917</td>\n",
              "      <td>0.155280</td>\n",
              "      <td>-0.100495</td>\n",
              "      <td>0.101031</td>\n",
              "      <td>-0.283114</td>\n",
              "      <td>0.066059</td>\n",
              "      <td>-0.020677</td>\n",
              "      <td>-0.016811</td>\n",
              "      <td>-0.240801</td>\n",
              "      <td>0.352777</td>\n",
              "      <td>0.112451</td>\n",
              "      <td>0.187223</td>\n",
              "      <td>-0.088103</td>\n",
              "      <td>0.135670</td>\n",
              "      <td>-0.655425</td>\n",
              "      <td>0.151951</td>\n",
              "      <td>0.354230</td>\n",
              "      <td>-0.027659</td>\n",
              "      <td>0.158659</td>\n",
              "      <td>0.315700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.110494</td>\n",
              "      <td>0.263056</td>\n",
              "      <td>0.020745</td>\n",
              "      <td>-0.083690</td>\n",
              "      <td>0.317877</td>\n",
              "      <td>-0.159514</td>\n",
              "      <td>0.098328</td>\n",
              "      <td>-0.285037</td>\n",
              "      <td>0.190302</td>\n",
              "      <td>0.257754</td>\n",
              "      <td>0.368462</td>\n",
              "      <td>0.116496</td>\n",
              "      <td>0.321317</td>\n",
              "      <td>-0.243893</td>\n",
              "      <td>0.233373</td>\n",
              "      <td>0.031371</td>\n",
              "      <td>0.067454</td>\n",
              "      <td>0.040376</td>\n",
              "      <td>0.082453</td>\n",
              "      <td>0.054444</td>\n",
              "      <td>0.122221</td>\n",
              "      <td>-0.016186</td>\n",
              "      <td>0.073776</td>\n",
              "      <td>0.393353</td>\n",
              "      <td>-0.043752</td>\n",
              "      <td>-0.453130</td>\n",
              "      <td>-0.073461</td>\n",
              "      <td>0.517180</td>\n",
              "      <td>-0.115861</td>\n",
              "      <td>-0.350563</td>\n",
              "      <td>-0.017058</td>\n",
              "      <td>0.031625</td>\n",
              "      <td>0.118507</td>\n",
              "      <td>0.088435</td>\n",
              "      <td>-0.056510</td>\n",
              "      <td>0.007562</td>\n",
              "      <td>0.014261</td>\n",
              "      <td>-0.367977</td>\n",
              "      <td>-0.868241</td>\n",
              "      <td>-0.190956</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.041060</td>\n",
              "      <td>0.009688</td>\n",
              "      <td>0.015103</td>\n",
              "      <td>-0.035007</td>\n",
              "      <td>-0.201611</td>\n",
              "      <td>0.184168</td>\n",
              "      <td>0.185245</td>\n",
              "      <td>0.343298</td>\n",
              "      <td>-0.242966</td>\n",
              "      <td>0.017674</td>\n",
              "      <td>0.051220</td>\n",
              "      <td>-0.200444</td>\n",
              "      <td>0.154912</td>\n",
              "      <td>-0.083202</td>\n",
              "      <td>0.183110</td>\n",
              "      <td>0.121521</td>\n",
              "      <td>0.066193</td>\n",
              "      <td>-0.111828</td>\n",
              "      <td>-0.217700</td>\n",
              "      <td>-0.325334</td>\n",
              "      <td>0.153115</td>\n",
              "      <td>0.052534</td>\n",
              "      <td>-0.242556</td>\n",
              "      <td>0.125184</td>\n",
              "      <td>0.057218</td>\n",
              "      <td>0.133159</td>\n",
              "      <td>0.253385</td>\n",
              "      <td>0.144550</td>\n",
              "      <td>-0.422281</td>\n",
              "      <td>0.218494</td>\n",
              "      <td>0.175572</td>\n",
              "      <td>-0.431394</td>\n",
              "      <td>0.025009</td>\n",
              "      <td>-0.254654</td>\n",
              "      <td>0.137788</td>\n",
              "      <td>-0.129653</td>\n",
              "      <td>0.100244</td>\n",
              "      <td>-0.034440</td>\n",
              "      <td>0.027490</td>\n",
              "      <td>-0.012786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.268107</td>\n",
              "      <td>0.011173</td>\n",
              "      <td>0.048714</td>\n",
              "      <td>0.000897</td>\n",
              "      <td>0.252820</td>\n",
              "      <td>-0.074468</td>\n",
              "      <td>0.012479</td>\n",
              "      <td>-0.102106</td>\n",
              "      <td>-0.005142</td>\n",
              "      <td>0.445745</td>\n",
              "      <td>0.230651</td>\n",
              "      <td>0.321489</td>\n",
              "      <td>0.168059</td>\n",
              "      <td>-0.206180</td>\n",
              "      <td>0.222813</td>\n",
              "      <td>0.288158</td>\n",
              "      <td>0.522919</td>\n",
              "      <td>0.159832</td>\n",
              "      <td>0.053895</td>\n",
              "      <td>-0.021069</td>\n",
              "      <td>-0.162871</td>\n",
              "      <td>0.265996</td>\n",
              "      <td>0.114369</td>\n",
              "      <td>-0.054784</td>\n",
              "      <td>0.023998</td>\n",
              "      <td>-0.497897</td>\n",
              "      <td>0.410240</td>\n",
              "      <td>0.488191</td>\n",
              "      <td>0.036219</td>\n",
              "      <td>-0.009524</td>\n",
              "      <td>-0.285679</td>\n",
              "      <td>-0.130584</td>\n",
              "      <td>-0.054320</td>\n",
              "      <td>0.201591</td>\n",
              "      <td>0.101228</td>\n",
              "      <td>-0.093514</td>\n",
              "      <td>0.542190</td>\n",
              "      <td>-0.395032</td>\n",
              "      <td>-0.727288</td>\n",
              "      <td>-0.142969</td>\n",
              "      <td>...</td>\n",
              "      <td>0.141931</td>\n",
              "      <td>-0.059457</td>\n",
              "      <td>-0.250941</td>\n",
              "      <td>-0.015322</td>\n",
              "      <td>-0.559130</td>\n",
              "      <td>0.077343</td>\n",
              "      <td>0.219120</td>\n",
              "      <td>0.493471</td>\n",
              "      <td>-0.270443</td>\n",
              "      <td>-0.062482</td>\n",
              "      <td>0.399766</td>\n",
              "      <td>-0.150523</td>\n",
              "      <td>-0.219753</td>\n",
              "      <td>0.268484</td>\n",
              "      <td>0.413417</td>\n",
              "      <td>0.117013</td>\n",
              "      <td>0.060151</td>\n",
              "      <td>-0.307243</td>\n",
              "      <td>-0.350530</td>\n",
              "      <td>-0.242909</td>\n",
              "      <td>-0.119714</td>\n",
              "      <td>-0.107818</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>-0.154829</td>\n",
              "      <td>0.051248</td>\n",
              "      <td>0.138710</td>\n",
              "      <td>0.168785</td>\n",
              "      <td>0.267176</td>\n",
              "      <td>-0.535444</td>\n",
              "      <td>0.173816</td>\n",
              "      <td>0.175458</td>\n",
              "      <td>0.235406</td>\n",
              "      <td>0.049407</td>\n",
              "      <td>-0.028393</td>\n",
              "      <td>-0.073177</td>\n",
              "      <td>-0.351295</td>\n",
              "      <td>0.038374</td>\n",
              "      <td>-0.718208</td>\n",
              "      <td>0.211355</td>\n",
              "      <td>-0.037011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.151989</td>\n",
              "      <td>0.100551</td>\n",
              "      <td>0.126916</td>\n",
              "      <td>0.019886</td>\n",
              "      <td>0.164062</td>\n",
              "      <td>-0.271461</td>\n",
              "      <td>0.094277</td>\n",
              "      <td>0.014035</td>\n",
              "      <td>-0.041832</td>\n",
              "      <td>0.211793</td>\n",
              "      <td>0.339095</td>\n",
              "      <td>0.403866</td>\n",
              "      <td>0.013407</td>\n",
              "      <td>0.178462</td>\n",
              "      <td>0.143547</td>\n",
              "      <td>0.158849</td>\n",
              "      <td>0.393222</td>\n",
              "      <td>0.103208</td>\n",
              "      <td>-0.198883</td>\n",
              "      <td>0.118967</td>\n",
              "      <td>-0.085434</td>\n",
              "      <td>0.190440</td>\n",
              "      <td>0.450476</td>\n",
              "      <td>0.179067</td>\n",
              "      <td>0.035952</td>\n",
              "      <td>0.207082</td>\n",
              "      <td>0.228413</td>\n",
              "      <td>0.231009</td>\n",
              "      <td>-0.144860</td>\n",
              "      <td>-0.163931</td>\n",
              "      <td>0.195402</td>\n",
              "      <td>0.269231</td>\n",
              "      <td>0.086868</td>\n",
              "      <td>0.155731</td>\n",
              "      <td>-0.013920</td>\n",
              "      <td>0.073765</td>\n",
              "      <td>0.236592</td>\n",
              "      <td>-0.062063</td>\n",
              "      <td>-0.524370</td>\n",
              "      <td>-0.131448</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099256</td>\n",
              "      <td>-0.177377</td>\n",
              "      <td>-0.253751</td>\n",
              "      <td>-0.249019</td>\n",
              "      <td>-0.177402</td>\n",
              "      <td>0.273509</td>\n",
              "      <td>0.060083</td>\n",
              "      <td>0.225747</td>\n",
              "      <td>-0.199107</td>\n",
              "      <td>-0.032746</td>\n",
              "      <td>0.010176</td>\n",
              "      <td>0.031080</td>\n",
              "      <td>0.002973</td>\n",
              "      <td>0.460473</td>\n",
              "      <td>0.285270</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>-0.276626</td>\n",
              "      <td>0.151094</td>\n",
              "      <td>-0.226739</td>\n",
              "      <td>-0.356126</td>\n",
              "      <td>0.221871</td>\n",
              "      <td>-0.252445</td>\n",
              "      <td>-0.294362</td>\n",
              "      <td>0.744626</td>\n",
              "      <td>0.164862</td>\n",
              "      <td>0.241230</td>\n",
              "      <td>0.262753</td>\n",
              "      <td>-0.357006</td>\n",
              "      <td>-0.281661</td>\n",
              "      <td>0.065284</td>\n",
              "      <td>-0.118605</td>\n",
              "      <td>-0.239055</td>\n",
              "      <td>-0.194856</td>\n",
              "      <td>0.068432</td>\n",
              "      <td>-0.525261</td>\n",
              "      <td>-0.172969</td>\n",
              "      <td>0.267976</td>\n",
              "      <td>-0.323329</td>\n",
              "      <td>0.060081</td>\n",
              "      <td>-0.062461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.174452</td>\n",
              "      <td>-0.107560</td>\n",
              "      <td>0.257954</td>\n",
              "      <td>-0.254951</td>\n",
              "      <td>-0.132018</td>\n",
              "      <td>-0.228701</td>\n",
              "      <td>0.150555</td>\n",
              "      <td>-0.245272</td>\n",
              "      <td>-0.210707</td>\n",
              "      <td>-0.057574</td>\n",
              "      <td>-0.246034</td>\n",
              "      <td>-0.213247</td>\n",
              "      <td>-0.065317</td>\n",
              "      <td>-0.030010</td>\n",
              "      <td>-0.194335</td>\n",
              "      <td>-0.097309</td>\n",
              "      <td>0.177408</td>\n",
              "      <td>0.421320</td>\n",
              "      <td>0.226604</td>\n",
              "      <td>0.166160</td>\n",
              "      <td>-0.287422</td>\n",
              "      <td>-0.087127</td>\n",
              "      <td>0.411904</td>\n",
              "      <td>-0.074701</td>\n",
              "      <td>-0.411938</td>\n",
              "      <td>0.011719</td>\n",
              "      <td>0.256076</td>\n",
              "      <td>-0.242647</td>\n",
              "      <td>-0.332309</td>\n",
              "      <td>-0.186846</td>\n",
              "      <td>0.121583</td>\n",
              "      <td>-0.190332</td>\n",
              "      <td>-0.066937</td>\n",
              "      <td>-0.115632</td>\n",
              "      <td>-0.604305</td>\n",
              "      <td>0.025050</td>\n",
              "      <td>-0.109032</td>\n",
              "      <td>0.040153</td>\n",
              "      <td>0.265488</td>\n",
              "      <td>-0.115242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.040703</td>\n",
              "      <td>-0.161550</td>\n",
              "      <td>0.106037</td>\n",
              "      <td>-0.479894</td>\n",
              "      <td>0.198198</td>\n",
              "      <td>0.073080</td>\n",
              "      <td>0.445559</td>\n",
              "      <td>-0.207496</td>\n",
              "      <td>-0.082609</td>\n",
              "      <td>0.356588</td>\n",
              "      <td>0.196779</td>\n",
              "      <td>-0.195157</td>\n",
              "      <td>0.065719</td>\n",
              "      <td>0.110567</td>\n",
              "      <td>0.187485</td>\n",
              "      <td>-0.167426</td>\n",
              "      <td>-0.717204</td>\n",
              "      <td>-0.460665</td>\n",
              "      <td>-0.047989</td>\n",
              "      <td>0.040978</td>\n",
              "      <td>-0.054262</td>\n",
              "      <td>0.019067</td>\n",
              "      <td>-0.412437</td>\n",
              "      <td>0.161885</td>\n",
              "      <td>0.086397</td>\n",
              "      <td>-0.202234</td>\n",
              "      <td>0.304916</td>\n",
              "      <td>-0.246528</td>\n",
              "      <td>-0.230728</td>\n",
              "      <td>0.105194</td>\n",
              "      <td>-0.402785</td>\n",
              "      <td>-0.689989</td>\n",
              "      <td>0.260279</td>\n",
              "      <td>0.272787</td>\n",
              "      <td>-0.064803</td>\n",
              "      <td>0.272452</td>\n",
              "      <td>0.134051</td>\n",
              "      <td>0.088473</td>\n",
              "      <td>-0.113517</td>\n",
              "      <td>-0.400128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.091684</td>\n",
              "      <td>0.030425</td>\n",
              "      <td>0.088823</td>\n",
              "      <td>-0.075891</td>\n",
              "      <td>0.032550</td>\n",
              "      <td>0.050734</td>\n",
              "      <td>0.146405</td>\n",
              "      <td>-0.101691</td>\n",
              "      <td>-0.043463</td>\n",
              "      <td>0.166755</td>\n",
              "      <td>0.060246</td>\n",
              "      <td>0.010984</td>\n",
              "      <td>-0.149463</td>\n",
              "      <td>-0.043756</td>\n",
              "      <td>0.006612</td>\n",
              "      <td>0.094080</td>\n",
              "      <td>0.160333</td>\n",
              "      <td>0.134583</td>\n",
              "      <td>-0.119860</td>\n",
              "      <td>-0.052640</td>\n",
              "      <td>-0.070269</td>\n",
              "      <td>0.111028</td>\n",
              "      <td>0.214780</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>-0.010540</td>\n",
              "      <td>-0.035902</td>\n",
              "      <td>0.066888</td>\n",
              "      <td>0.114089</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>-0.037004</td>\n",
              "      <td>0.017097</td>\n",
              "      <td>0.036678</td>\n",
              "      <td>-0.051375</td>\n",
              "      <td>0.043096</td>\n",
              "      <td>-0.106216</td>\n",
              "      <td>-0.036568</td>\n",
              "      <td>0.170080</td>\n",
              "      <td>-0.025191</td>\n",
              "      <td>-0.102954</td>\n",
              "      <td>-0.127890</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002686</td>\n",
              "      <td>-0.140694</td>\n",
              "      <td>-0.056267</td>\n",
              "      <td>-0.104885</td>\n",
              "      <td>-0.043995</td>\n",
              "      <td>0.108745</td>\n",
              "      <td>-0.004836</td>\n",
              "      <td>0.108775</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>-0.007211</td>\n",
              "      <td>0.039406</td>\n",
              "      <td>0.066866</td>\n",
              "      <td>0.066070</td>\n",
              "      <td>0.180496</td>\n",
              "      <td>0.176204</td>\n",
              "      <td>-0.036603</td>\n",
              "      <td>-0.061266</td>\n",
              "      <td>0.001557</td>\n",
              "      <td>-0.081725</td>\n",
              "      <td>-0.088014</td>\n",
              "      <td>-0.028604</td>\n",
              "      <td>-0.030241</td>\n",
              "      <td>-0.096843</td>\n",
              "      <td>0.176086</td>\n",
              "      <td>0.006787</td>\n",
              "      <td>0.018720</td>\n",
              "      <td>0.049109</td>\n",
              "      <td>-0.092781</td>\n",
              "      <td>-0.208739</td>\n",
              "      <td>0.113910</td>\n",
              "      <td>-0.097908</td>\n",
              "      <td>-0.116718</td>\n",
              "      <td>-0.055430</td>\n",
              "      <td>0.022146</td>\n",
              "      <td>-0.205472</td>\n",
              "      <td>-0.024099</td>\n",
              "      <td>0.086062</td>\n",
              "      <td>-0.142532</td>\n",
              "      <td>0.015970</td>\n",
              "      <td>-0.062013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.034763</td>\n",
              "      <td>-0.161011</td>\n",
              "      <td>0.140570</td>\n",
              "      <td>0.175992</td>\n",
              "      <td>0.459962</td>\n",
              "      <td>-0.242631</td>\n",
              "      <td>-0.051741</td>\n",
              "      <td>-0.128755</td>\n",
              "      <td>-0.103677</td>\n",
              "      <td>0.199563</td>\n",
              "      <td>0.148768</td>\n",
              "      <td>-0.170274</td>\n",
              "      <td>0.048759</td>\n",
              "      <td>-0.182653</td>\n",
              "      <td>0.170006</td>\n",
              "      <td>0.142879</td>\n",
              "      <td>0.371174</td>\n",
              "      <td>0.162317</td>\n",
              "      <td>0.039228</td>\n",
              "      <td>-0.147637</td>\n",
              "      <td>-0.082493</td>\n",
              "      <td>0.169107</td>\n",
              "      <td>0.159363</td>\n",
              "      <td>-0.050029</td>\n",
              "      <td>-0.253319</td>\n",
              "      <td>-0.006641</td>\n",
              "      <td>0.125198</td>\n",
              "      <td>0.405186</td>\n",
              "      <td>-0.030552</td>\n",
              "      <td>0.112613</td>\n",
              "      <td>0.132836</td>\n",
              "      <td>0.021062</td>\n",
              "      <td>-0.007054</td>\n",
              "      <td>0.252117</td>\n",
              "      <td>0.444617</td>\n",
              "      <td>-0.160032</td>\n",
              "      <td>0.111042</td>\n",
              "      <td>0.080811</td>\n",
              "      <td>-0.343690</td>\n",
              "      <td>-0.009980</td>\n",
              "      <td>...</td>\n",
              "      <td>0.224006</td>\n",
              "      <td>-0.061652</td>\n",
              "      <td>-0.208635</td>\n",
              "      <td>-0.064257</td>\n",
              "      <td>-0.036795</td>\n",
              "      <td>-0.040645</td>\n",
              "      <td>0.127223</td>\n",
              "      <td>0.199031</td>\n",
              "      <td>-0.140367</td>\n",
              "      <td>-0.037575</td>\n",
              "      <td>-0.032066</td>\n",
              "      <td>0.010635</td>\n",
              "      <td>-0.133837</td>\n",
              "      <td>0.170067</td>\n",
              "      <td>0.165061</td>\n",
              "      <td>0.126627</td>\n",
              "      <td>-0.377569</td>\n",
              "      <td>-0.390835</td>\n",
              "      <td>-0.121297</td>\n",
              "      <td>-0.071974</td>\n",
              "      <td>0.188917</td>\n",
              "      <td>0.155280</td>\n",
              "      <td>-0.100495</td>\n",
              "      <td>0.101031</td>\n",
              "      <td>-0.283114</td>\n",
              "      <td>0.066059</td>\n",
              "      <td>-0.020677</td>\n",
              "      <td>-0.016811</td>\n",
              "      <td>-0.240801</td>\n",
              "      <td>0.352777</td>\n",
              "      <td>0.112451</td>\n",
              "      <td>0.187223</td>\n",
              "      <td>-0.088103</td>\n",
              "      <td>0.135670</td>\n",
              "      <td>-0.655425</td>\n",
              "      <td>0.151951</td>\n",
              "      <td>0.354230</td>\n",
              "      <td>-0.027659</td>\n",
              "      <td>0.158659</td>\n",
              "      <td>0.315700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.131177</td>\n",
              "      <td>0.011852</td>\n",
              "      <td>0.343895</td>\n",
              "      <td>-0.190291</td>\n",
              "      <td>-0.426993</td>\n",
              "      <td>-0.455709</td>\n",
              "      <td>0.157624</td>\n",
              "      <td>-0.038461</td>\n",
              "      <td>-0.090271</td>\n",
              "      <td>0.173956</td>\n",
              "      <td>-0.076459</td>\n",
              "      <td>-0.427939</td>\n",
              "      <td>0.042937</td>\n",
              "      <td>-0.289962</td>\n",
              "      <td>0.021822</td>\n",
              "      <td>-0.105752</td>\n",
              "      <td>0.291917</td>\n",
              "      <td>0.220622</td>\n",
              "      <td>0.067330</td>\n",
              "      <td>-0.245997</td>\n",
              "      <td>0.068715</td>\n",
              "      <td>0.201425</td>\n",
              "      <td>-0.091065</td>\n",
              "      <td>-0.214262</td>\n",
              "      <td>0.023920</td>\n",
              "      <td>0.027944</td>\n",
              "      <td>0.122030</td>\n",
              "      <td>0.159784</td>\n",
              "      <td>-0.438084</td>\n",
              "      <td>-0.080485</td>\n",
              "      <td>0.067798</td>\n",
              "      <td>0.053519</td>\n",
              "      <td>-0.129062</td>\n",
              "      <td>0.386468</td>\n",
              "      <td>-0.053467</td>\n",
              "      <td>0.367630</td>\n",
              "      <td>-0.170132</td>\n",
              "      <td>-0.046087</td>\n",
              "      <td>-0.163592</td>\n",
              "      <td>0.179016</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001224</td>\n",
              "      <td>0.066361</td>\n",
              "      <td>0.053245</td>\n",
              "      <td>0.117595</td>\n",
              "      <td>-0.204085</td>\n",
              "      <td>-0.016746</td>\n",
              "      <td>-0.175817</td>\n",
              "      <td>0.117113</td>\n",
              "      <td>0.048044</td>\n",
              "      <td>0.183040</td>\n",
              "      <td>0.143743</td>\n",
              "      <td>0.120420</td>\n",
              "      <td>-0.173429</td>\n",
              "      <td>-0.401938</td>\n",
              "      <td>0.374455</td>\n",
              "      <td>-0.050551</td>\n",
              "      <td>-0.022803</td>\n",
              "      <td>0.348452</td>\n",
              "      <td>0.053552</td>\n",
              "      <td>0.004947</td>\n",
              "      <td>-0.028898</td>\n",
              "      <td>0.544414</td>\n",
              "      <td>-0.153349</td>\n",
              "      <td>-0.166188</td>\n",
              "      <td>0.215864</td>\n",
              "      <td>0.147579</td>\n",
              "      <td>0.021842</td>\n",
              "      <td>-0.195775</td>\n",
              "      <td>0.166560</td>\n",
              "      <td>0.168864</td>\n",
              "      <td>0.293633</td>\n",
              "      <td>0.314193</td>\n",
              "      <td>-0.302561</td>\n",
              "      <td>0.144146</td>\n",
              "      <td>0.148220</td>\n",
              "      <td>0.156493</td>\n",
              "      <td>-0.016966</td>\n",
              "      <td>-0.018110</td>\n",
              "      <td>-0.223994</td>\n",
              "      <td>0.098030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.109272</td>\n",
              "      <td>0.282584</td>\n",
              "      <td>-0.408413</td>\n",
              "      <td>0.346705</td>\n",
              "      <td>0.090197</td>\n",
              "      <td>-0.236857</td>\n",
              "      <td>-0.363736</td>\n",
              "      <td>-0.162158</td>\n",
              "      <td>0.078746</td>\n",
              "      <td>-0.331315</td>\n",
              "      <td>0.323429</td>\n",
              "      <td>0.191484</td>\n",
              "      <td>0.620186</td>\n",
              "      <td>0.047777</td>\n",
              "      <td>0.388409</td>\n",
              "      <td>-0.153525</td>\n",
              "      <td>-0.024781</td>\n",
              "      <td>-0.523921</td>\n",
              "      <td>0.118559</td>\n",
              "      <td>-0.119699</td>\n",
              "      <td>0.401831</td>\n",
              "      <td>-0.075517</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>0.009026</td>\n",
              "      <td>-0.079755</td>\n",
              "      <td>-0.028223</td>\n",
              "      <td>-0.376197</td>\n",
              "      <td>0.111978</td>\n",
              "      <td>0.136641</td>\n",
              "      <td>-0.007018</td>\n",
              "      <td>0.102985</td>\n",
              "      <td>0.004254</td>\n",
              "      <td>0.141979</td>\n",
              "      <td>-0.007868</td>\n",
              "      <td>0.676502</td>\n",
              "      <td>-0.205055</td>\n",
              "      <td>-0.354418</td>\n",
              "      <td>0.129477</td>\n",
              "      <td>-0.413299</td>\n",
              "      <td>-0.169389</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.189953</td>\n",
              "      <td>0.059302</td>\n",
              "      <td>-0.021004</td>\n",
              "      <td>0.177958</td>\n",
              "      <td>-0.296802</td>\n",
              "      <td>0.108101</td>\n",
              "      <td>0.140926</td>\n",
              "      <td>-0.326161</td>\n",
              "      <td>-0.233955</td>\n",
              "      <td>-0.194551</td>\n",
              "      <td>-0.252298</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>-0.056060</td>\n",
              "      <td>0.157504</td>\n",
              "      <td>-0.097283</td>\n",
              "      <td>0.390093</td>\n",
              "      <td>0.324675</td>\n",
              "      <td>-0.368497</td>\n",
              "      <td>-0.034976</td>\n",
              "      <td>-0.004841</td>\n",
              "      <td>0.626138</td>\n",
              "      <td>-0.217051</td>\n",
              "      <td>-0.158731</td>\n",
              "      <td>-0.150078</td>\n",
              "      <td>-0.340399</td>\n",
              "      <td>0.203518</td>\n",
              "      <td>-0.136093</td>\n",
              "      <td>0.322835</td>\n",
              "      <td>0.078623</td>\n",
              "      <td>-0.150136</td>\n",
              "      <td>0.388810</td>\n",
              "      <td>0.300427</td>\n",
              "      <td>-0.008682</td>\n",
              "      <td>-0.098611</td>\n",
              "      <td>0.202972</td>\n",
              "      <td>-0.688400</td>\n",
              "      <td>0.027687</td>\n",
              "      <td>-0.062762</td>\n",
              "      <td>0.424503</td>\n",
              "      <td>0.235132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.079781</td>\n",
              "      <td>-0.025519</td>\n",
              "      <td>-0.243857</td>\n",
              "      <td>0.481250</td>\n",
              "      <td>-0.097796</td>\n",
              "      <td>-0.025103</td>\n",
              "      <td>0.096601</td>\n",
              "      <td>0.291724</td>\n",
              "      <td>-0.456119</td>\n",
              "      <td>-0.527140</td>\n",
              "      <td>-0.492613</td>\n",
              "      <td>-0.523470</td>\n",
              "      <td>0.057695</td>\n",
              "      <td>0.069989</td>\n",
              "      <td>0.291863</td>\n",
              "      <td>-0.085822</td>\n",
              "      <td>-0.160219</td>\n",
              "      <td>0.104416</td>\n",
              "      <td>-0.224287</td>\n",
              "      <td>-0.249879</td>\n",
              "      <td>-0.227970</td>\n",
              "      <td>0.352441</td>\n",
              "      <td>0.137310</td>\n",
              "      <td>-0.031105</td>\n",
              "      <td>-0.292824</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>0.384589</td>\n",
              "      <td>-0.171379</td>\n",
              "      <td>0.141584</td>\n",
              "      <td>0.191231</td>\n",
              "      <td>-0.029099</td>\n",
              "      <td>-0.054023</td>\n",
              "      <td>0.066428</td>\n",
              "      <td>-0.333136</td>\n",
              "      <td>0.065857</td>\n",
              "      <td>-0.119944</td>\n",
              "      <td>0.190828</td>\n",
              "      <td>0.419122</td>\n",
              "      <td>-0.147303</td>\n",
              "      <td>0.160678</td>\n",
              "      <td>...</td>\n",
              "      <td>0.491943</td>\n",
              "      <td>-0.233385</td>\n",
              "      <td>-0.110467</td>\n",
              "      <td>0.176024</td>\n",
              "      <td>-0.132378</td>\n",
              "      <td>0.034769</td>\n",
              "      <td>-0.170813</td>\n",
              "      <td>-0.419283</td>\n",
              "      <td>0.432286</td>\n",
              "      <td>0.342213</td>\n",
              "      <td>-0.521197</td>\n",
              "      <td>-0.300880</td>\n",
              "      <td>-0.256072</td>\n",
              "      <td>0.147677</td>\n",
              "      <td>0.017774</td>\n",
              "      <td>-0.079317</td>\n",
              "      <td>0.233280</td>\n",
              "      <td>-0.723025</td>\n",
              "      <td>0.320899</td>\n",
              "      <td>0.387058</td>\n",
              "      <td>-0.136161</td>\n",
              "      <td>-0.100076</td>\n",
              "      <td>-0.115502</td>\n",
              "      <td>-0.366601</td>\n",
              "      <td>-0.481600</td>\n",
              "      <td>0.230335</td>\n",
              "      <td>-0.186191</td>\n",
              "      <td>0.341697</td>\n",
              "      <td>-0.063077</td>\n",
              "      <td>0.236464</td>\n",
              "      <td>0.179565</td>\n",
              "      <td>0.499097</td>\n",
              "      <td>0.384646</td>\n",
              "      <td>0.061515</td>\n",
              "      <td>0.026558</td>\n",
              "      <td>-0.441899</td>\n",
              "      <td>0.105285</td>\n",
              "      <td>-0.091680</td>\n",
              "      <td>0.157746</td>\n",
              "      <td>0.151333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.183910</td>\n",
              "      <td>-0.061212</td>\n",
              "      <td>0.129800</td>\n",
              "      <td>0.520310</td>\n",
              "      <td>-0.011274</td>\n",
              "      <td>0.357148</td>\n",
              "      <td>-0.276536</td>\n",
              "      <td>0.138316</td>\n",
              "      <td>0.168843</td>\n",
              "      <td>-0.218067</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>-0.393613</td>\n",
              "      <td>0.588654</td>\n",
              "      <td>-0.389109</td>\n",
              "      <td>0.642491</td>\n",
              "      <td>0.075533</td>\n",
              "      <td>0.383125</td>\n",
              "      <td>-0.088680</td>\n",
              "      <td>0.355325</td>\n",
              "      <td>0.174431</td>\n",
              "      <td>0.021438</td>\n",
              "      <td>-0.014471</td>\n",
              "      <td>-0.222796</td>\n",
              "      <td>-0.398659</td>\n",
              "      <td>-0.249722</td>\n",
              "      <td>-0.352323</td>\n",
              "      <td>-0.184781</td>\n",
              "      <td>-0.310528</td>\n",
              "      <td>-0.057301</td>\n",
              "      <td>0.047881</td>\n",
              "      <td>-0.292628</td>\n",
              "      <td>-0.197707</td>\n",
              "      <td>0.057850</td>\n",
              "      <td>-0.606778</td>\n",
              "      <td>0.315939</td>\n",
              "      <td>-0.085344</td>\n",
              "      <td>0.247765</td>\n",
              "      <td>0.667252</td>\n",
              "      <td>0.321471</td>\n",
              "      <td>-0.014339</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008724</td>\n",
              "      <td>-0.055227</td>\n",
              "      <td>0.058422</td>\n",
              "      <td>0.092477</td>\n",
              "      <td>-0.103028</td>\n",
              "      <td>-0.340897</td>\n",
              "      <td>0.357281</td>\n",
              "      <td>0.079935</td>\n",
              "      <td>0.123921</td>\n",
              "      <td>-0.079473</td>\n",
              "      <td>-0.006668</td>\n",
              "      <td>0.081586</td>\n",
              "      <td>0.088914</td>\n",
              "      <td>-0.010275</td>\n",
              "      <td>-0.319333</td>\n",
              "      <td>0.317449</td>\n",
              "      <td>0.205100</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>-0.007748</td>\n",
              "      <td>0.345069</td>\n",
              "      <td>-0.128609</td>\n",
              "      <td>0.009163</td>\n",
              "      <td>-0.139763</td>\n",
              "      <td>-0.364857</td>\n",
              "      <td>-0.124788</td>\n",
              "      <td>-0.283637</td>\n",
              "      <td>-0.016459</td>\n",
              "      <td>0.235692</td>\n",
              "      <td>0.049831</td>\n",
              "      <td>0.174068</td>\n",
              "      <td>0.137410</td>\n",
              "      <td>0.120423</td>\n",
              "      <td>0.049469</td>\n",
              "      <td>0.514741</td>\n",
              "      <td>0.224115</td>\n",
              "      <td>-0.366353</td>\n",
              "      <td>-0.273836</td>\n",
              "      <td>0.234740</td>\n",
              "      <td>0.307678</td>\n",
              "      <td>0.253161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.038220</td>\n",
              "      <td>-0.046820</td>\n",
              "      <td>0.220528</td>\n",
              "      <td>0.343543</td>\n",
              "      <td>-0.180420</td>\n",
              "      <td>-0.339405</td>\n",
              "      <td>-0.274143</td>\n",
              "      <td>-0.071935</td>\n",
              "      <td>-0.324170</td>\n",
              "      <td>0.127505</td>\n",
              "      <td>-0.073410</td>\n",
              "      <td>-0.256905</td>\n",
              "      <td>0.265148</td>\n",
              "      <td>-0.134348</td>\n",
              "      <td>0.201436</td>\n",
              "      <td>0.014513</td>\n",
              "      <td>0.129010</td>\n",
              "      <td>-0.373396</td>\n",
              "      <td>0.186273</td>\n",
              "      <td>0.161451</td>\n",
              "      <td>0.491607</td>\n",
              "      <td>-0.099539</td>\n",
              "      <td>-0.217403</td>\n",
              "      <td>-0.015820</td>\n",
              "      <td>-0.203644</td>\n",
              "      <td>-0.219550</td>\n",
              "      <td>0.089621</td>\n",
              "      <td>0.368182</td>\n",
              "      <td>-0.194693</td>\n",
              "      <td>0.078800</td>\n",
              "      <td>0.260756</td>\n",
              "      <td>-0.215648</td>\n",
              "      <td>0.012597</td>\n",
              "      <td>-0.067399</td>\n",
              "      <td>0.212225</td>\n",
              "      <td>0.182505</td>\n",
              "      <td>0.133254</td>\n",
              "      <td>-0.276072</td>\n",
              "      <td>-0.170117</td>\n",
              "      <td>0.009740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.106701</td>\n",
              "      <td>-0.213431</td>\n",
              "      <td>-0.127795</td>\n",
              "      <td>0.041472</td>\n",
              "      <td>-0.274942</td>\n",
              "      <td>0.028025</td>\n",
              "      <td>-0.138915</td>\n",
              "      <td>-0.011744</td>\n",
              "      <td>0.223165</td>\n",
              "      <td>0.101055</td>\n",
              "      <td>0.281813</td>\n",
              "      <td>-0.070949</td>\n",
              "      <td>-0.213869</td>\n",
              "      <td>0.327390</td>\n",
              "      <td>0.042028</td>\n",
              "      <td>0.034390</td>\n",
              "      <td>0.549446</td>\n",
              "      <td>-0.579972</td>\n",
              "      <td>0.087896</td>\n",
              "      <td>-0.083156</td>\n",
              "      <td>0.246381</td>\n",
              "      <td>-0.182888</td>\n",
              "      <td>-0.404738</td>\n",
              "      <td>-0.346967</td>\n",
              "      <td>-0.162559</td>\n",
              "      <td>0.094606</td>\n",
              "      <td>-0.291927</td>\n",
              "      <td>0.383894</td>\n",
              "      <td>-0.483298</td>\n",
              "      <td>-0.188750</td>\n",
              "      <td>0.374880</td>\n",
              "      <td>0.412472</td>\n",
              "      <td>0.038545</td>\n",
              "      <td>0.310302</td>\n",
              "      <td>0.353530</td>\n",
              "      <td>-0.522277</td>\n",
              "      <td>0.273057</td>\n",
              "      <td>-0.108797</td>\n",
              "      <td>0.307164</td>\n",
              "      <td>0.134890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-0.280344</td>\n",
              "      <td>-0.029469</td>\n",
              "      <td>-0.116329</td>\n",
              "      <td>-0.200214</td>\n",
              "      <td>0.326494</td>\n",
              "      <td>-0.082214</td>\n",
              "      <td>0.054345</td>\n",
              "      <td>-0.050127</td>\n",
              "      <td>0.105254</td>\n",
              "      <td>-0.226622</td>\n",
              "      <td>-0.011727</td>\n",
              "      <td>0.157044</td>\n",
              "      <td>0.371994</td>\n",
              "      <td>-0.224915</td>\n",
              "      <td>0.102847</td>\n",
              "      <td>-0.269393</td>\n",
              "      <td>0.167294</td>\n",
              "      <td>-0.341204</td>\n",
              "      <td>0.160095</td>\n",
              "      <td>-0.196916</td>\n",
              "      <td>-0.395163</td>\n",
              "      <td>0.143173</td>\n",
              "      <td>0.114345</td>\n",
              "      <td>-0.029313</td>\n",
              "      <td>0.136816</td>\n",
              "      <td>-0.262680</td>\n",
              "      <td>-0.135231</td>\n",
              "      <td>0.542769</td>\n",
              "      <td>-0.006948</td>\n",
              "      <td>0.078266</td>\n",
              "      <td>-0.093706</td>\n",
              "      <td>-0.255805</td>\n",
              "      <td>-0.065189</td>\n",
              "      <td>0.140622</td>\n",
              "      <td>0.352430</td>\n",
              "      <td>-0.343985</td>\n",
              "      <td>0.005244</td>\n",
              "      <td>0.136126</td>\n",
              "      <td>-0.234642</td>\n",
              "      <td>-0.101518</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.300295</td>\n",
              "      <td>0.053297</td>\n",
              "      <td>0.016039</td>\n",
              "      <td>0.011066</td>\n",
              "      <td>0.023466</td>\n",
              "      <td>0.006652</td>\n",
              "      <td>0.115384</td>\n",
              "      <td>0.188112</td>\n",
              "      <td>-0.329218</td>\n",
              "      <td>0.280987</td>\n",
              "      <td>0.209575</td>\n",
              "      <td>-0.499275</td>\n",
              "      <td>-0.080543</td>\n",
              "      <td>-0.113152</td>\n",
              "      <td>0.204546</td>\n",
              "      <td>-0.095905</td>\n",
              "      <td>0.366013</td>\n",
              "      <td>-0.269696</td>\n",
              "      <td>-0.063990</td>\n",
              "      <td>-0.331105</td>\n",
              "      <td>-0.047419</td>\n",
              "      <td>0.061213</td>\n",
              "      <td>0.273596</td>\n",
              "      <td>0.124814</td>\n",
              "      <td>-0.186554</td>\n",
              "      <td>0.071373</td>\n",
              "      <td>0.125591</td>\n",
              "      <td>0.196156</td>\n",
              "      <td>-0.420686</td>\n",
              "      <td>-0.297746</td>\n",
              "      <td>-0.075369</td>\n",
              "      <td>0.039002</td>\n",
              "      <td>0.205245</td>\n",
              "      <td>-0.024739</td>\n",
              "      <td>0.403491</td>\n",
              "      <td>-0.609493</td>\n",
              "      <td>-0.244644</td>\n",
              "      <td>0.176493</td>\n",
              "      <td>0.130165</td>\n",
              "      <td>-0.017426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.038220</td>\n",
              "      <td>-0.046820</td>\n",
              "      <td>0.220528</td>\n",
              "      <td>0.343543</td>\n",
              "      <td>-0.180420</td>\n",
              "      <td>-0.339405</td>\n",
              "      <td>-0.274143</td>\n",
              "      <td>-0.071935</td>\n",
              "      <td>-0.324170</td>\n",
              "      <td>0.127505</td>\n",
              "      <td>-0.073410</td>\n",
              "      <td>-0.256905</td>\n",
              "      <td>0.265148</td>\n",
              "      <td>-0.134348</td>\n",
              "      <td>0.201436</td>\n",
              "      <td>0.014513</td>\n",
              "      <td>0.129010</td>\n",
              "      <td>-0.373396</td>\n",
              "      <td>0.186273</td>\n",
              "      <td>0.161451</td>\n",
              "      <td>0.491607</td>\n",
              "      <td>-0.099539</td>\n",
              "      <td>-0.217403</td>\n",
              "      <td>-0.015820</td>\n",
              "      <td>-0.203644</td>\n",
              "      <td>-0.219550</td>\n",
              "      <td>0.089621</td>\n",
              "      <td>0.368182</td>\n",
              "      <td>-0.194693</td>\n",
              "      <td>0.078800</td>\n",
              "      <td>0.260756</td>\n",
              "      <td>-0.215648</td>\n",
              "      <td>0.012597</td>\n",
              "      <td>-0.067399</td>\n",
              "      <td>0.212225</td>\n",
              "      <td>0.182505</td>\n",
              "      <td>0.133254</td>\n",
              "      <td>-0.276072</td>\n",
              "      <td>-0.170117</td>\n",
              "      <td>0.009740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.106701</td>\n",
              "      <td>-0.213431</td>\n",
              "      <td>-0.127795</td>\n",
              "      <td>0.041472</td>\n",
              "      <td>-0.274942</td>\n",
              "      <td>0.028025</td>\n",
              "      <td>-0.138915</td>\n",
              "      <td>-0.011744</td>\n",
              "      <td>0.223165</td>\n",
              "      <td>0.101055</td>\n",
              "      <td>0.281813</td>\n",
              "      <td>-0.070949</td>\n",
              "      <td>-0.213869</td>\n",
              "      <td>0.327390</td>\n",
              "      <td>0.042028</td>\n",
              "      <td>0.034390</td>\n",
              "      <td>0.549446</td>\n",
              "      <td>-0.579972</td>\n",
              "      <td>0.087896</td>\n",
              "      <td>-0.083156</td>\n",
              "      <td>0.246381</td>\n",
              "      <td>-0.182888</td>\n",
              "      <td>-0.404738</td>\n",
              "      <td>-0.346967</td>\n",
              "      <td>-0.162559</td>\n",
              "      <td>0.094606</td>\n",
              "      <td>-0.291927</td>\n",
              "      <td>0.383894</td>\n",
              "      <td>-0.483298</td>\n",
              "      <td>-0.188750</td>\n",
              "      <td>0.374880</td>\n",
              "      <td>0.412472</td>\n",
              "      <td>0.038545</td>\n",
              "      <td>0.310302</td>\n",
              "      <td>0.353530</td>\n",
              "      <td>-0.522277</td>\n",
              "      <td>0.273057</td>\n",
              "      <td>-0.108797</td>\n",
              "      <td>0.307164</td>\n",
              "      <td>0.134890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.109272</td>\n",
              "      <td>0.282584</td>\n",
              "      <td>-0.408413</td>\n",
              "      <td>0.346705</td>\n",
              "      <td>0.090197</td>\n",
              "      <td>-0.236857</td>\n",
              "      <td>-0.363736</td>\n",
              "      <td>-0.162158</td>\n",
              "      <td>0.078746</td>\n",
              "      <td>-0.331315</td>\n",
              "      <td>0.323429</td>\n",
              "      <td>0.191484</td>\n",
              "      <td>0.620186</td>\n",
              "      <td>0.047777</td>\n",
              "      <td>0.388409</td>\n",
              "      <td>-0.153525</td>\n",
              "      <td>-0.024781</td>\n",
              "      <td>-0.523921</td>\n",
              "      <td>0.118559</td>\n",
              "      <td>-0.119699</td>\n",
              "      <td>0.401831</td>\n",
              "      <td>-0.075517</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>0.009026</td>\n",
              "      <td>-0.079755</td>\n",
              "      <td>-0.028223</td>\n",
              "      <td>-0.376197</td>\n",
              "      <td>0.111978</td>\n",
              "      <td>0.136641</td>\n",
              "      <td>-0.007018</td>\n",
              "      <td>0.102985</td>\n",
              "      <td>0.004254</td>\n",
              "      <td>0.141979</td>\n",
              "      <td>-0.007868</td>\n",
              "      <td>0.676502</td>\n",
              "      <td>-0.205055</td>\n",
              "      <td>-0.354418</td>\n",
              "      <td>0.129477</td>\n",
              "      <td>-0.413299</td>\n",
              "      <td>-0.169389</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.189953</td>\n",
              "      <td>0.059302</td>\n",
              "      <td>-0.021004</td>\n",
              "      <td>0.177958</td>\n",
              "      <td>-0.296802</td>\n",
              "      <td>0.108101</td>\n",
              "      <td>0.140926</td>\n",
              "      <td>-0.326161</td>\n",
              "      <td>-0.233955</td>\n",
              "      <td>-0.194551</td>\n",
              "      <td>-0.252298</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>-0.056060</td>\n",
              "      <td>0.157504</td>\n",
              "      <td>-0.097283</td>\n",
              "      <td>0.390093</td>\n",
              "      <td>0.324675</td>\n",
              "      <td>-0.368497</td>\n",
              "      <td>-0.034976</td>\n",
              "      <td>-0.004841</td>\n",
              "      <td>0.626138</td>\n",
              "      <td>-0.217051</td>\n",
              "      <td>-0.158731</td>\n",
              "      <td>-0.150078</td>\n",
              "      <td>-0.340399</td>\n",
              "      <td>0.203518</td>\n",
              "      <td>-0.136093</td>\n",
              "      <td>0.322835</td>\n",
              "      <td>0.078623</td>\n",
              "      <td>-0.150136</td>\n",
              "      <td>0.388810</td>\n",
              "      <td>0.300427</td>\n",
              "      <td>-0.008682</td>\n",
              "      <td>-0.098611</td>\n",
              "      <td>0.202972</td>\n",
              "      <td>-0.688400</td>\n",
              "      <td>0.027687</td>\n",
              "      <td>-0.062762</td>\n",
              "      <td>0.424503</td>\n",
              "      <td>0.235132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-0.024214</td>\n",
              "      <td>-0.118902</td>\n",
              "      <td>0.111218</td>\n",
              "      <td>-0.005674</td>\n",
              "      <td>0.232269</td>\n",
              "      <td>-0.162149</td>\n",
              "      <td>-0.079581</td>\n",
              "      <td>-0.596274</td>\n",
              "      <td>0.339283</td>\n",
              "      <td>0.007925</td>\n",
              "      <td>0.706483</td>\n",
              "      <td>-0.078089</td>\n",
              "      <td>0.469055</td>\n",
              "      <td>-0.049879</td>\n",
              "      <td>-0.008720</td>\n",
              "      <td>0.005884</td>\n",
              "      <td>-0.144717</td>\n",
              "      <td>-0.118947</td>\n",
              "      <td>0.019715</td>\n",
              "      <td>0.106295</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>-0.016719</td>\n",
              "      <td>-0.101333</td>\n",
              "      <td>0.375820</td>\n",
              "      <td>0.043957</td>\n",
              "      <td>-0.206252</td>\n",
              "      <td>-0.019232</td>\n",
              "      <td>0.420073</td>\n",
              "      <td>0.079629</td>\n",
              "      <td>-0.218854</td>\n",
              "      <td>0.176577</td>\n",
              "      <td>-0.033097</td>\n",
              "      <td>0.047399</td>\n",
              "      <td>0.444687</td>\n",
              "      <td>0.127588</td>\n",
              "      <td>-0.246684</td>\n",
              "      <td>-0.165768</td>\n",
              "      <td>-0.369294</td>\n",
              "      <td>-0.130270</td>\n",
              "      <td>0.099723</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.136617</td>\n",
              "      <td>0.294048</td>\n",
              "      <td>-0.268164</td>\n",
              "      <td>0.131462</td>\n",
              "      <td>0.225594</td>\n",
              "      <td>-0.272465</td>\n",
              "      <td>0.323852</td>\n",
              "      <td>0.659396</td>\n",
              "      <td>-0.245101</td>\n",
              "      <td>-0.158062</td>\n",
              "      <td>0.016885</td>\n",
              "      <td>-0.167114</td>\n",
              "      <td>0.231614</td>\n",
              "      <td>-0.226271</td>\n",
              "      <td>0.127263</td>\n",
              "      <td>-0.003819</td>\n",
              "      <td>0.222724</td>\n",
              "      <td>-0.291490</td>\n",
              "      <td>0.046740</td>\n",
              "      <td>-0.249908</td>\n",
              "      <td>0.314161</td>\n",
              "      <td>-0.102778</td>\n",
              "      <td>0.097663</td>\n",
              "      <td>-0.000763</td>\n",
              "      <td>-0.105366</td>\n",
              "      <td>0.160048</td>\n",
              "      <td>0.168374</td>\n",
              "      <td>-0.059639</td>\n",
              "      <td>-0.325015</td>\n",
              "      <td>0.087745</td>\n",
              "      <td>-0.028548</td>\n",
              "      <td>-0.395954</td>\n",
              "      <td>-0.069225</td>\n",
              "      <td>-0.412987</td>\n",
              "      <td>-0.065389</td>\n",
              "      <td>0.075032</td>\n",
              "      <td>-0.012600</td>\n",
              "      <td>0.232870</td>\n",
              "      <td>0.383704</td>\n",
              "      <td>0.589763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.145896</td>\n",
              "      <td>0.208463</td>\n",
              "      <td>-0.022059</td>\n",
              "      <td>0.018980</td>\n",
              "      <td>0.123219</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>0.164418</td>\n",
              "      <td>-0.207327</td>\n",
              "      <td>0.182308</td>\n",
              "      <td>0.036860</td>\n",
              "      <td>0.385250</td>\n",
              "      <td>0.270128</td>\n",
              "      <td>0.263641</td>\n",
              "      <td>-0.226692</td>\n",
              "      <td>-0.252058</td>\n",
              "      <td>0.310296</td>\n",
              "      <td>-0.309980</td>\n",
              "      <td>-0.098418</td>\n",
              "      <td>-0.067656</td>\n",
              "      <td>-0.238931</td>\n",
              "      <td>-0.040980</td>\n",
              "      <td>0.198811</td>\n",
              "      <td>-0.027564</td>\n",
              "      <td>0.288101</td>\n",
              "      <td>0.215583</td>\n",
              "      <td>-0.113309</td>\n",
              "      <td>-0.070470</td>\n",
              "      <td>0.184694</td>\n",
              "      <td>0.028762</td>\n",
              "      <td>-0.172363</td>\n",
              "      <td>0.040005</td>\n",
              "      <td>0.180797</td>\n",
              "      <td>0.013160</td>\n",
              "      <td>0.279160</td>\n",
              "      <td>-0.166726</td>\n",
              "      <td>-0.226000</td>\n",
              "      <td>0.061080</td>\n",
              "      <td>-0.259397</td>\n",
              "      <td>-0.101736</td>\n",
              "      <td>0.166626</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.093840</td>\n",
              "      <td>0.192417</td>\n",
              "      <td>0.142801</td>\n",
              "      <td>0.005308</td>\n",
              "      <td>0.136126</td>\n",
              "      <td>-0.075870</td>\n",
              "      <td>0.118848</td>\n",
              "      <td>0.407205</td>\n",
              "      <td>-0.069584</td>\n",
              "      <td>-0.011542</td>\n",
              "      <td>0.161756</td>\n",
              "      <td>-0.020883</td>\n",
              "      <td>0.247938</td>\n",
              "      <td>-0.141666</td>\n",
              "      <td>0.226758</td>\n",
              "      <td>-0.120156</td>\n",
              "      <td>-0.028201</td>\n",
              "      <td>0.167421</td>\n",
              "      <td>-0.082667</td>\n",
              "      <td>-0.006256</td>\n",
              "      <td>0.012826</td>\n",
              "      <td>-0.033876</td>\n",
              "      <td>0.204542</td>\n",
              "      <td>-0.019344</td>\n",
              "      <td>0.044264</td>\n",
              "      <td>0.128895</td>\n",
              "      <td>-0.153057</td>\n",
              "      <td>-0.045353</td>\n",
              "      <td>0.078560</td>\n",
              "      <td>-0.216054</td>\n",
              "      <td>-0.354992</td>\n",
              "      <td>-0.158272</td>\n",
              "      <td>-0.083983</td>\n",
              "      <td>-0.016743</td>\n",
              "      <td>0.022313</td>\n",
              "      <td>0.210359</td>\n",
              "      <td>-0.108258</td>\n",
              "      <td>-0.054786</td>\n",
              "      <td>-0.035667</td>\n",
              "      <td>0.016383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.071846</td>\n",
              "      <td>0.259861</td>\n",
              "      <td>0.375056</td>\n",
              "      <td>-0.031679</td>\n",
              "      <td>0.074373</td>\n",
              "      <td>-0.086972</td>\n",
              "      <td>-0.008537</td>\n",
              "      <td>-0.312404</td>\n",
              "      <td>0.446938</td>\n",
              "      <td>0.132119</td>\n",
              "      <td>0.497121</td>\n",
              "      <td>0.127087</td>\n",
              "      <td>0.293725</td>\n",
              "      <td>0.199074</td>\n",
              "      <td>-0.296528</td>\n",
              "      <td>0.144338</td>\n",
              "      <td>-0.635486</td>\n",
              "      <td>-0.267129</td>\n",
              "      <td>0.250532</td>\n",
              "      <td>-0.397699</td>\n",
              "      <td>0.139665</td>\n",
              "      <td>0.202757</td>\n",
              "      <td>-0.169822</td>\n",
              "      <td>0.491463</td>\n",
              "      <td>0.186002</td>\n",
              "      <td>0.213659</td>\n",
              "      <td>-0.082222</td>\n",
              "      <td>0.421471</td>\n",
              "      <td>0.163063</td>\n",
              "      <td>-0.641583</td>\n",
              "      <td>-0.169318</td>\n",
              "      <td>0.153492</td>\n",
              "      <td>0.083309</td>\n",
              "      <td>0.169925</td>\n",
              "      <td>-0.140133</td>\n",
              "      <td>0.066302</td>\n",
              "      <td>0.074133</td>\n",
              "      <td>-0.332224</td>\n",
              "      <td>-0.044997</td>\n",
              "      <td>0.186369</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.295588</td>\n",
              "      <td>-0.229415</td>\n",
              "      <td>-0.026312</td>\n",
              "      <td>0.199029</td>\n",
              "      <td>0.624001</td>\n",
              "      <td>0.118811</td>\n",
              "      <td>-0.126557</td>\n",
              "      <td>0.693566</td>\n",
              "      <td>-0.187326</td>\n",
              "      <td>0.079882</td>\n",
              "      <td>-0.161269</td>\n",
              "      <td>-0.196616</td>\n",
              "      <td>0.114497</td>\n",
              "      <td>-0.081842</td>\n",
              "      <td>0.276379</td>\n",
              "      <td>-0.069070</td>\n",
              "      <td>0.173371</td>\n",
              "      <td>0.245953</td>\n",
              "      <td>-0.237436</td>\n",
              "      <td>-0.117669</td>\n",
              "      <td>0.340112</td>\n",
              "      <td>-0.203934</td>\n",
              "      <td>-0.145479</td>\n",
              "      <td>0.072121</td>\n",
              "      <td>0.337543</td>\n",
              "      <td>0.493459</td>\n",
              "      <td>-0.054663</td>\n",
              "      <td>0.009033</td>\n",
              "      <td>-0.182383</td>\n",
              "      <td>-0.386404</td>\n",
              "      <td>0.035647</td>\n",
              "      <td>-0.539012</td>\n",
              "      <td>-0.407341</td>\n",
              "      <td>-0.042880</td>\n",
              "      <td>0.370386</td>\n",
              "      <td>0.064291</td>\n",
              "      <td>0.085371</td>\n",
              "      <td>0.361547</td>\n",
              "      <td>0.179145</td>\n",
              "      <td>0.253851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.221306</td>\n",
              "      <td>0.258792</td>\n",
              "      <td>0.032510</td>\n",
              "      <td>-0.467510</td>\n",
              "      <td>0.330911</td>\n",
              "      <td>-0.387326</td>\n",
              "      <td>0.144455</td>\n",
              "      <td>-0.503058</td>\n",
              "      <td>0.448425</td>\n",
              "      <td>0.263591</td>\n",
              "      <td>0.149949</td>\n",
              "      <td>0.100404</td>\n",
              "      <td>0.136771</td>\n",
              "      <td>-0.175576</td>\n",
              "      <td>-0.534770</td>\n",
              "      <td>0.201902</td>\n",
              "      <td>-0.899358</td>\n",
              "      <td>-0.330857</td>\n",
              "      <td>0.225864</td>\n",
              "      <td>-0.739319</td>\n",
              "      <td>0.055984</td>\n",
              "      <td>0.191995</td>\n",
              "      <td>-0.004255</td>\n",
              "      <td>0.485340</td>\n",
              "      <td>-0.131972</td>\n",
              "      <td>0.024133</td>\n",
              "      <td>-0.369193</td>\n",
              "      <td>0.560159</td>\n",
              "      <td>-0.113719</td>\n",
              "      <td>-1.078470</td>\n",
              "      <td>-0.056033</td>\n",
              "      <td>0.134692</td>\n",
              "      <td>0.120527</td>\n",
              "      <td>-0.132278</td>\n",
              "      <td>-0.060225</td>\n",
              "      <td>0.165888</td>\n",
              "      <td>-0.290869</td>\n",
              "      <td>-0.059579</td>\n",
              "      <td>0.012640</td>\n",
              "      <td>-0.097411</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.136150</td>\n",
              "      <td>-0.329769</td>\n",
              "      <td>0.316256</td>\n",
              "      <td>0.678974</td>\n",
              "      <td>0.718039</td>\n",
              "      <td>0.619782</td>\n",
              "      <td>-0.557699</td>\n",
              "      <td>0.193653</td>\n",
              "      <td>-0.099049</td>\n",
              "      <td>0.353913</td>\n",
              "      <td>-0.228232</td>\n",
              "      <td>-0.395095</td>\n",
              "      <td>0.332278</td>\n",
              "      <td>-0.529639</td>\n",
              "      <td>0.111118</td>\n",
              "      <td>0.216537</td>\n",
              "      <td>-0.621992</td>\n",
              "      <td>0.559849</td>\n",
              "      <td>-0.460529</td>\n",
              "      <td>0.264612</td>\n",
              "      <td>0.291370</td>\n",
              "      <td>0.108111</td>\n",
              "      <td>-0.245488</td>\n",
              "      <td>0.129223</td>\n",
              "      <td>0.291018</td>\n",
              "      <td>0.538440</td>\n",
              "      <td>-0.682330</td>\n",
              "      <td>-0.090015</td>\n",
              "      <td>-0.158808</td>\n",
              "      <td>-0.318339</td>\n",
              "      <td>-0.007142</td>\n",
              "      <td>-0.879991</td>\n",
              "      <td>-0.242374</td>\n",
              "      <td>0.034492</td>\n",
              "      <td>0.496280</td>\n",
              "      <td>0.181121</td>\n",
              "      <td>-0.123160</td>\n",
              "      <td>0.472145</td>\n",
              "      <td>-0.243705</td>\n",
              "      <td>-0.244137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.221306</td>\n",
              "      <td>0.258792</td>\n",
              "      <td>0.032510</td>\n",
              "      <td>-0.467510</td>\n",
              "      <td>0.330911</td>\n",
              "      <td>-0.387326</td>\n",
              "      <td>0.144455</td>\n",
              "      <td>-0.503058</td>\n",
              "      <td>0.448425</td>\n",
              "      <td>0.263591</td>\n",
              "      <td>0.149949</td>\n",
              "      <td>0.100404</td>\n",
              "      <td>0.136771</td>\n",
              "      <td>-0.175576</td>\n",
              "      <td>-0.534770</td>\n",
              "      <td>0.201902</td>\n",
              "      <td>-0.899358</td>\n",
              "      <td>-0.330857</td>\n",
              "      <td>0.225864</td>\n",
              "      <td>-0.739319</td>\n",
              "      <td>0.055984</td>\n",
              "      <td>0.191995</td>\n",
              "      <td>-0.004255</td>\n",
              "      <td>0.485340</td>\n",
              "      <td>-0.131972</td>\n",
              "      <td>0.024133</td>\n",
              "      <td>-0.369193</td>\n",
              "      <td>0.560159</td>\n",
              "      <td>-0.113719</td>\n",
              "      <td>-1.078470</td>\n",
              "      <td>-0.056033</td>\n",
              "      <td>0.134692</td>\n",
              "      <td>0.120527</td>\n",
              "      <td>-0.132278</td>\n",
              "      <td>-0.060225</td>\n",
              "      <td>0.165888</td>\n",
              "      <td>-0.290869</td>\n",
              "      <td>-0.059579</td>\n",
              "      <td>0.012640</td>\n",
              "      <td>-0.097411</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.136150</td>\n",
              "      <td>-0.329769</td>\n",
              "      <td>0.316256</td>\n",
              "      <td>0.678974</td>\n",
              "      <td>0.718039</td>\n",
              "      <td>0.619782</td>\n",
              "      <td>-0.557699</td>\n",
              "      <td>0.193653</td>\n",
              "      <td>-0.099049</td>\n",
              "      <td>0.353913</td>\n",
              "      <td>-0.228232</td>\n",
              "      <td>-0.395095</td>\n",
              "      <td>0.332278</td>\n",
              "      <td>-0.529639</td>\n",
              "      <td>0.111118</td>\n",
              "      <td>0.216537</td>\n",
              "      <td>-0.621992</td>\n",
              "      <td>0.559849</td>\n",
              "      <td>-0.460529</td>\n",
              "      <td>0.264612</td>\n",
              "      <td>0.291370</td>\n",
              "      <td>0.108111</td>\n",
              "      <td>-0.245488</td>\n",
              "      <td>0.129223</td>\n",
              "      <td>0.291018</td>\n",
              "      <td>0.538440</td>\n",
              "      <td>-0.682330</td>\n",
              "      <td>-0.090015</td>\n",
              "      <td>-0.158808</td>\n",
              "      <td>-0.318339</td>\n",
              "      <td>-0.007142</td>\n",
              "      <td>-0.879991</td>\n",
              "      <td>-0.242374</td>\n",
              "      <td>0.034492</td>\n",
              "      <td>0.496280</td>\n",
              "      <td>0.181121</td>\n",
              "      <td>-0.123160</td>\n",
              "      <td>0.472145</td>\n",
              "      <td>-0.243705</td>\n",
              "      <td>-0.244137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>-0.047195</td>\n",
              "      <td>-0.020316</td>\n",
              "      <td>0.065144</td>\n",
              "      <td>0.029061</td>\n",
              "      <td>-0.238742</td>\n",
              "      <td>-0.139628</td>\n",
              "      <td>-0.093202</td>\n",
              "      <td>0.118627</td>\n",
              "      <td>-0.135741</td>\n",
              "      <td>0.163837</td>\n",
              "      <td>-0.066624</td>\n",
              "      <td>-0.056639</td>\n",
              "      <td>0.014631</td>\n",
              "      <td>0.442300</td>\n",
              "      <td>-0.081354</td>\n",
              "      <td>-0.038245</td>\n",
              "      <td>0.039199</td>\n",
              "      <td>-0.168927</td>\n",
              "      <td>0.264266</td>\n",
              "      <td>0.072200</td>\n",
              "      <td>0.088744</td>\n",
              "      <td>-0.193594</td>\n",
              "      <td>-0.315972</td>\n",
              "      <td>-0.146151</td>\n",
              "      <td>0.023743</td>\n",
              "      <td>0.400332</td>\n",
              "      <td>-0.043778</td>\n",
              "      <td>0.188186</td>\n",
              "      <td>0.154146</td>\n",
              "      <td>-0.486136</td>\n",
              "      <td>-0.054118</td>\n",
              "      <td>0.431888</td>\n",
              "      <td>-0.017623</td>\n",
              "      <td>-0.211081</td>\n",
              "      <td>-0.116285</td>\n",
              "      <td>0.440730</td>\n",
              "      <td>-0.089668</td>\n",
              "      <td>0.194354</td>\n",
              "      <td>0.049439</td>\n",
              "      <td>0.050479</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.157545</td>\n",
              "      <td>-0.251919</td>\n",
              "      <td>0.042300</td>\n",
              "      <td>0.461555</td>\n",
              "      <td>0.683388</td>\n",
              "      <td>0.174555</td>\n",
              "      <td>-0.309756</td>\n",
              "      <td>0.101324</td>\n",
              "      <td>-0.048571</td>\n",
              "      <td>0.328198</td>\n",
              "      <td>-0.293173</td>\n",
              "      <td>0.035648</td>\n",
              "      <td>-0.252252</td>\n",
              "      <td>-0.106398</td>\n",
              "      <td>-0.273697</td>\n",
              "      <td>0.392119</td>\n",
              "      <td>-0.288066</td>\n",
              "      <td>0.305129</td>\n",
              "      <td>0.065549</td>\n",
              "      <td>0.171097</td>\n",
              "      <td>0.062117</td>\n",
              "      <td>-0.144831</td>\n",
              "      <td>0.076732</td>\n",
              "      <td>-0.038637</td>\n",
              "      <td>0.145066</td>\n",
              "      <td>0.246056</td>\n",
              "      <td>-0.116995</td>\n",
              "      <td>0.150751</td>\n",
              "      <td>0.019175</td>\n",
              "      <td>0.215287</td>\n",
              "      <td>0.328141</td>\n",
              "      <td>-0.523236</td>\n",
              "      <td>0.003707</td>\n",
              "      <td>-0.165569</td>\n",
              "      <td>-0.314413</td>\n",
              "      <td>0.158558</td>\n",
              "      <td>0.229790</td>\n",
              "      <td>0.140653</td>\n",
              "      <td>0.142219</td>\n",
              "      <td>0.289036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.159736</td>\n",
              "      <td>-0.249732</td>\n",
              "      <td>0.032930</td>\n",
              "      <td>-0.292062</td>\n",
              "      <td>0.056652</td>\n",
              "      <td>-0.301541</td>\n",
              "      <td>0.283038</td>\n",
              "      <td>-0.412102</td>\n",
              "      <td>0.064853</td>\n",
              "      <td>0.272608</td>\n",
              "      <td>0.021626</td>\n",
              "      <td>-0.198313</td>\n",
              "      <td>0.040248</td>\n",
              "      <td>-0.075882</td>\n",
              "      <td>0.118980</td>\n",
              "      <td>-0.095190</td>\n",
              "      <td>0.295580</td>\n",
              "      <td>0.169002</td>\n",
              "      <td>0.308304</td>\n",
              "      <td>-0.176104</td>\n",
              "      <td>-0.028833</td>\n",
              "      <td>0.078017</td>\n",
              "      <td>0.220847</td>\n",
              "      <td>-0.117926</td>\n",
              "      <td>0.114121</td>\n",
              "      <td>-0.443539</td>\n",
              "      <td>-0.188164</td>\n",
              "      <td>0.407045</td>\n",
              "      <td>-0.393615</td>\n",
              "      <td>-0.321504</td>\n",
              "      <td>0.097480</td>\n",
              "      <td>-0.020805</td>\n",
              "      <td>0.162481</td>\n",
              "      <td>0.160263</td>\n",
              "      <td>0.188611</td>\n",
              "      <td>-0.147338</td>\n",
              "      <td>-0.053784</td>\n",
              "      <td>-0.221023</td>\n",
              "      <td>-0.078269</td>\n",
              "      <td>-0.267916</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.192396</td>\n",
              "      <td>0.061374</td>\n",
              "      <td>0.120222</td>\n",
              "      <td>-0.170988</td>\n",
              "      <td>0.146375</td>\n",
              "      <td>0.068990</td>\n",
              "      <td>0.214128</td>\n",
              "      <td>0.228603</td>\n",
              "      <td>-0.137125</td>\n",
              "      <td>-0.112431</td>\n",
              "      <td>0.112022</td>\n",
              "      <td>-0.254033</td>\n",
              "      <td>0.059680</td>\n",
              "      <td>0.076065</td>\n",
              "      <td>0.177638</td>\n",
              "      <td>-0.007747</td>\n",
              "      <td>-0.150234</td>\n",
              "      <td>-0.363383</td>\n",
              "      <td>0.018109</td>\n",
              "      <td>-0.398737</td>\n",
              "      <td>0.147097</td>\n",
              "      <td>0.122917</td>\n",
              "      <td>0.095047</td>\n",
              "      <td>-0.180004</td>\n",
              "      <td>-0.063449</td>\n",
              "      <td>0.086215</td>\n",
              "      <td>0.088548</td>\n",
              "      <td>0.243279</td>\n",
              "      <td>-0.273001</td>\n",
              "      <td>0.033934</td>\n",
              "      <td>0.079413</td>\n",
              "      <td>0.268510</td>\n",
              "      <td>0.173485</td>\n",
              "      <td>-0.303344</td>\n",
              "      <td>0.329121</td>\n",
              "      <td>-0.507702</td>\n",
              "      <td>0.070279</td>\n",
              "      <td>-0.100671</td>\n",
              "      <td>0.060253</td>\n",
              "      <td>-0.044321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.110808</td>\n",
              "      <td>0.041104</td>\n",
              "      <td>-0.143596</td>\n",
              "      <td>-0.053431</td>\n",
              "      <td>-0.055825</td>\n",
              "      <td>-0.376483</td>\n",
              "      <td>-0.021834</td>\n",
              "      <td>-0.277442</td>\n",
              "      <td>0.104628</td>\n",
              "      <td>0.036571</td>\n",
              "      <td>0.214796</td>\n",
              "      <td>-0.057866</td>\n",
              "      <td>0.288494</td>\n",
              "      <td>-0.298031</td>\n",
              "      <td>0.025167</td>\n",
              "      <td>0.099179</td>\n",
              "      <td>-0.189288</td>\n",
              "      <td>-0.253182</td>\n",
              "      <td>0.019785</td>\n",
              "      <td>-0.151442</td>\n",
              "      <td>0.268963</td>\n",
              "      <td>-0.141968</td>\n",
              "      <td>-0.017026</td>\n",
              "      <td>0.117701</td>\n",
              "      <td>-0.118254</td>\n",
              "      <td>-0.193303</td>\n",
              "      <td>-0.125025</td>\n",
              "      <td>0.248044</td>\n",
              "      <td>-0.311525</td>\n",
              "      <td>-0.401477</td>\n",
              "      <td>0.290709</td>\n",
              "      <td>-0.045641</td>\n",
              "      <td>0.128149</td>\n",
              "      <td>-0.106277</td>\n",
              "      <td>0.101558</td>\n",
              "      <td>0.146965</td>\n",
              "      <td>-0.232411</td>\n",
              "      <td>-0.186435</td>\n",
              "      <td>-0.115108</td>\n",
              "      <td>-0.068216</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.036062</td>\n",
              "      <td>-0.034322</td>\n",
              "      <td>0.069803</td>\n",
              "      <td>0.305122</td>\n",
              "      <td>-0.045578</td>\n",
              "      <td>0.189871</td>\n",
              "      <td>-0.199453</td>\n",
              "      <td>-0.029439</td>\n",
              "      <td>-0.007228</td>\n",
              "      <td>0.036327</td>\n",
              "      <td>0.119150</td>\n",
              "      <td>-0.169882</td>\n",
              "      <td>0.184618</td>\n",
              "      <td>-0.217499</td>\n",
              "      <td>0.002028</td>\n",
              "      <td>0.178557</td>\n",
              "      <td>-0.154135</td>\n",
              "      <td>0.166701</td>\n",
              "      <td>0.039162</td>\n",
              "      <td>0.104517</td>\n",
              "      <td>0.267010</td>\n",
              "      <td>-0.005421</td>\n",
              "      <td>-0.251370</td>\n",
              "      <td>0.037221</td>\n",
              "      <td>-0.099736</td>\n",
              "      <td>0.145982</td>\n",
              "      <td>-0.411280</td>\n",
              "      <td>-0.015347</td>\n",
              "      <td>-0.197373</td>\n",
              "      <td>-0.017954</td>\n",
              "      <td>0.019048</td>\n",
              "      <td>-0.243436</td>\n",
              "      <td>0.159880</td>\n",
              "      <td>-0.078384</td>\n",
              "      <td>0.309679</td>\n",
              "      <td>-0.327902</td>\n",
              "      <td>-0.129552</td>\n",
              "      <td>0.091035</td>\n",
              "      <td>-0.031570</td>\n",
              "      <td>-0.154814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>-0.068173</td>\n",
              "      <td>0.144498</td>\n",
              "      <td>-0.127387</td>\n",
              "      <td>-0.017183</td>\n",
              "      <td>-0.206138</td>\n",
              "      <td>0.204374</td>\n",
              "      <td>-0.061652</td>\n",
              "      <td>-0.182682</td>\n",
              "      <td>-0.036301</td>\n",
              "      <td>-0.315479</td>\n",
              "      <td>0.164668</td>\n",
              "      <td>-0.300729</td>\n",
              "      <td>0.500727</td>\n",
              "      <td>0.097377</td>\n",
              "      <td>0.325669</td>\n",
              "      <td>-0.190172</td>\n",
              "      <td>0.118865</td>\n",
              "      <td>-0.569685</td>\n",
              "      <td>-0.077602</td>\n",
              "      <td>-0.459839</td>\n",
              "      <td>0.309329</td>\n",
              "      <td>0.088728</td>\n",
              "      <td>0.245339</td>\n",
              "      <td>-0.088745</td>\n",
              "      <td>0.019336</td>\n",
              "      <td>-0.146546</td>\n",
              "      <td>-0.372060</td>\n",
              "      <td>0.196858</td>\n",
              "      <td>-0.116513</td>\n",
              "      <td>-0.038078</td>\n",
              "      <td>0.098877</td>\n",
              "      <td>-0.271280</td>\n",
              "      <td>-0.264568</td>\n",
              "      <td>0.171489</td>\n",
              "      <td>0.443395</td>\n",
              "      <td>-0.035700</td>\n",
              "      <td>0.005319</td>\n",
              "      <td>-0.371371</td>\n",
              "      <td>-0.119543</td>\n",
              "      <td>0.030106</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.100279</td>\n",
              "      <td>0.155123</td>\n",
              "      <td>0.037446</td>\n",
              "      <td>0.042833</td>\n",
              "      <td>-0.257759</td>\n",
              "      <td>0.100260</td>\n",
              "      <td>0.143259</td>\n",
              "      <td>-0.109179</td>\n",
              "      <td>-0.213660</td>\n",
              "      <td>-0.338551</td>\n",
              "      <td>0.023482</td>\n",
              "      <td>0.232263</td>\n",
              "      <td>-0.040805</td>\n",
              "      <td>0.047948</td>\n",
              "      <td>0.126735</td>\n",
              "      <td>0.177121</td>\n",
              "      <td>0.492273</td>\n",
              "      <td>-0.620637</td>\n",
              "      <td>0.064286</td>\n",
              "      <td>-0.210461</td>\n",
              "      <td>0.349383</td>\n",
              "      <td>-0.362351</td>\n",
              "      <td>-0.089587</td>\n",
              "      <td>-0.057020</td>\n",
              "      <td>-0.278520</td>\n",
              "      <td>0.092917</td>\n",
              "      <td>0.364490</td>\n",
              "      <td>0.212597</td>\n",
              "      <td>0.096228</td>\n",
              "      <td>-0.396235</td>\n",
              "      <td>0.399755</td>\n",
              "      <td>0.102016</td>\n",
              "      <td>-0.191376</td>\n",
              "      <td>0.020132</td>\n",
              "      <td>-0.003250</td>\n",
              "      <td>-0.734186</td>\n",
              "      <td>-0.155077</td>\n",
              "      <td>-0.004746</td>\n",
              "      <td>0.226838</td>\n",
              "      <td>-0.082503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.079781</td>\n",
              "      <td>-0.025519</td>\n",
              "      <td>-0.243857</td>\n",
              "      <td>0.481250</td>\n",
              "      <td>-0.097796</td>\n",
              "      <td>-0.025103</td>\n",
              "      <td>0.096601</td>\n",
              "      <td>0.291724</td>\n",
              "      <td>-0.456119</td>\n",
              "      <td>-0.527140</td>\n",
              "      <td>-0.492613</td>\n",
              "      <td>-0.523470</td>\n",
              "      <td>0.057695</td>\n",
              "      <td>0.069989</td>\n",
              "      <td>0.291863</td>\n",
              "      <td>-0.085822</td>\n",
              "      <td>-0.160219</td>\n",
              "      <td>0.104416</td>\n",
              "      <td>-0.224287</td>\n",
              "      <td>-0.249879</td>\n",
              "      <td>-0.227970</td>\n",
              "      <td>0.352441</td>\n",
              "      <td>0.137310</td>\n",
              "      <td>-0.031105</td>\n",
              "      <td>-0.292824</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>0.384589</td>\n",
              "      <td>-0.171379</td>\n",
              "      <td>0.141584</td>\n",
              "      <td>0.191231</td>\n",
              "      <td>-0.029099</td>\n",
              "      <td>-0.054023</td>\n",
              "      <td>0.066428</td>\n",
              "      <td>-0.333136</td>\n",
              "      <td>0.065857</td>\n",
              "      <td>-0.119944</td>\n",
              "      <td>0.190828</td>\n",
              "      <td>0.419122</td>\n",
              "      <td>-0.147303</td>\n",
              "      <td>0.160678</td>\n",
              "      <td>...</td>\n",
              "      <td>0.491943</td>\n",
              "      <td>-0.233385</td>\n",
              "      <td>-0.110467</td>\n",
              "      <td>0.176024</td>\n",
              "      <td>-0.132378</td>\n",
              "      <td>0.034769</td>\n",
              "      <td>-0.170813</td>\n",
              "      <td>-0.419283</td>\n",
              "      <td>0.432286</td>\n",
              "      <td>0.342213</td>\n",
              "      <td>-0.521197</td>\n",
              "      <td>-0.300880</td>\n",
              "      <td>-0.256072</td>\n",
              "      <td>0.147677</td>\n",
              "      <td>0.017774</td>\n",
              "      <td>-0.079317</td>\n",
              "      <td>0.233280</td>\n",
              "      <td>-0.723025</td>\n",
              "      <td>0.320899</td>\n",
              "      <td>0.387058</td>\n",
              "      <td>-0.136161</td>\n",
              "      <td>-0.100076</td>\n",
              "      <td>-0.115502</td>\n",
              "      <td>-0.366601</td>\n",
              "      <td>-0.481600</td>\n",
              "      <td>0.230335</td>\n",
              "      <td>-0.186191</td>\n",
              "      <td>0.341697</td>\n",
              "      <td>-0.063077</td>\n",
              "      <td>0.236464</td>\n",
              "      <td>0.179565</td>\n",
              "      <td>0.499097</td>\n",
              "      <td>0.384646</td>\n",
              "      <td>0.061515</td>\n",
              "      <td>0.026558</td>\n",
              "      <td>-0.441899</td>\n",
              "      <td>0.105285</td>\n",
              "      <td>-0.091680</td>\n",
              "      <td>0.157746</td>\n",
              "      <td>0.151333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2291</th>\n",
              "      <td>-0.334936</td>\n",
              "      <td>-0.237400</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>0.307774</td>\n",
              "      <td>0.552991</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>-0.128793</td>\n",
              "      <td>0.184903</td>\n",
              "      <td>-0.300067</td>\n",
              "      <td>-0.160469</td>\n",
              "      <td>-0.137007</td>\n",
              "      <td>-0.380960</td>\n",
              "      <td>0.067295</td>\n",
              "      <td>-0.350619</td>\n",
              "      <td>0.319733</td>\n",
              "      <td>0.312155</td>\n",
              "      <td>0.234408</td>\n",
              "      <td>0.456366</td>\n",
              "      <td>0.103505</td>\n",
              "      <td>-0.163476</td>\n",
              "      <td>-0.112946</td>\n",
              "      <td>0.273597</td>\n",
              "      <td>0.274887</td>\n",
              "      <td>-0.008497</td>\n",
              "      <td>-0.404606</td>\n",
              "      <td>-0.219477</td>\n",
              "      <td>0.200002</td>\n",
              "      <td>0.470362</td>\n",
              "      <td>0.067487</td>\n",
              "      <td>-0.013588</td>\n",
              "      <td>-0.049962</td>\n",
              "      <td>-0.066518</td>\n",
              "      <td>-0.108149</td>\n",
              "      <td>-0.090050</td>\n",
              "      <td>0.477854</td>\n",
              "      <td>-0.432016</td>\n",
              "      <td>0.279654</td>\n",
              "      <td>0.297045</td>\n",
              "      <td>-0.167063</td>\n",
              "      <td>0.094208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>-0.071417</td>\n",
              "      <td>-0.103228</td>\n",
              "      <td>-0.008193</td>\n",
              "      <td>-0.482496</td>\n",
              "      <td>-0.107093</td>\n",
              "      <td>0.380227</td>\n",
              "      <td>-0.081455</td>\n",
              "      <td>0.418951</td>\n",
              "      <td>-0.213351</td>\n",
              "      <td>-0.182586</td>\n",
              "      <td>-0.167677</td>\n",
              "      <td>0.183418</td>\n",
              "      <td>-0.053785</td>\n",
              "      <td>0.092943</td>\n",
              "      <td>-0.330301</td>\n",
              "      <td>-0.024515</td>\n",
              "      <td>-0.559753</td>\n",
              "      <td>0.022932</td>\n",
              "      <td>0.180525</td>\n",
              "      <td>0.188712</td>\n",
              "      <td>0.027331</td>\n",
              "      <td>-0.235138</td>\n",
              "      <td>-0.330035</td>\n",
              "      <td>0.122914</td>\n",
              "      <td>0.102582</td>\n",
              "      <td>-0.103969</td>\n",
              "      <td>-0.070550</td>\n",
              "      <td>-0.079660</td>\n",
              "      <td>0.035513</td>\n",
              "      <td>-0.149414</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>-0.103845</td>\n",
              "      <td>0.242430</td>\n",
              "      <td>0.017625</td>\n",
              "      <td>-0.328206</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.093238</td>\n",
              "      <td>0.037537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2292</th>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.100156</td>\n",
              "      <td>-0.181406</td>\n",
              "      <td>0.123134</td>\n",
              "      <td>-0.248711</td>\n",
              "      <td>0.386225</td>\n",
              "      <td>0.071953</td>\n",
              "      <td>0.316884</td>\n",
              "      <td>-0.297754</td>\n",
              "      <td>-0.585618</td>\n",
              "      <td>-0.599487</td>\n",
              "      <td>-0.883622</td>\n",
              "      <td>0.226984</td>\n",
              "      <td>-0.302107</td>\n",
              "      <td>0.742923</td>\n",
              "      <td>-0.127922</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.163219</td>\n",
              "      <td>0.103186</td>\n",
              "      <td>-0.484405</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.024954</td>\n",
              "      <td>0.405841</td>\n",
              "      <td>-0.307482</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.075125</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.205681</td>\n",
              "      <td>-0.225701</td>\n",
              "      <td>0.155992</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>0.079980</td>\n",
              "      <td>-0.199730</td>\n",
              "      <td>0.141558</td>\n",
              "      <td>-0.142644</td>\n",
              "      <td>0.390152</td>\n",
              "      <td>0.426615</td>\n",
              "      <td>0.088414</td>\n",
              "      <td>0.210211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120282</td>\n",
              "      <td>-0.229974</td>\n",
              "      <td>-0.054204</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>-0.093858</td>\n",
              "      <td>-0.182911</td>\n",
              "      <td>-0.011829</td>\n",
              "      <td>-0.233442</td>\n",
              "      <td>0.685782</td>\n",
              "      <td>-0.358191</td>\n",
              "      <td>0.020692</td>\n",
              "      <td>0.152990</td>\n",
              "      <td>0.288014</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>-0.129584</td>\n",
              "      <td>-0.258241</td>\n",
              "      <td>0.386515</td>\n",
              "      <td>-0.658014</td>\n",
              "      <td>0.211520</td>\n",
              "      <td>0.296892</td>\n",
              "      <td>-0.153062</td>\n",
              "      <td>-0.045540</td>\n",
              "      <td>-0.337411</td>\n",
              "      <td>-0.140582</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>0.045885</td>\n",
              "      <td>0.116038</td>\n",
              "      <td>0.095674</td>\n",
              "      <td>-0.101839</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.513150</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.316020</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>-0.380363</td>\n",
              "      <td>-0.108683</td>\n",
              "      <td>-0.100425</td>\n",
              "      <td>-0.040597</td>\n",
              "      <td>0.013379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2293</th>\n",
              "      <td>0.292988</td>\n",
              "      <td>0.007353</td>\n",
              "      <td>-0.141794</td>\n",
              "      <td>-0.217709</td>\n",
              "      <td>0.061340</td>\n",
              "      <td>0.356941</td>\n",
              "      <td>0.128595</td>\n",
              "      <td>-0.399345</td>\n",
              "      <td>-0.079264</td>\n",
              "      <td>-0.041962</td>\n",
              "      <td>-0.098025</td>\n",
              "      <td>-0.324808</td>\n",
              "      <td>-0.056163</td>\n",
              "      <td>0.149594</td>\n",
              "      <td>0.111448</td>\n",
              "      <td>-0.165758</td>\n",
              "      <td>0.249520</td>\n",
              "      <td>0.274554</td>\n",
              "      <td>-0.139133</td>\n",
              "      <td>0.333623</td>\n",
              "      <td>-0.155837</td>\n",
              "      <td>-0.045190</td>\n",
              "      <td>0.285358</td>\n",
              "      <td>-0.003968</td>\n",
              "      <td>-0.303356</td>\n",
              "      <td>-0.190002</td>\n",
              "      <td>-0.266731</td>\n",
              "      <td>-0.428568</td>\n",
              "      <td>-0.096448</td>\n",
              "      <td>0.275077</td>\n",
              "      <td>-0.134497</td>\n",
              "      <td>-0.168020</td>\n",
              "      <td>-0.280440</td>\n",
              "      <td>-0.245803</td>\n",
              "      <td>0.097271</td>\n",
              "      <td>-0.328880</td>\n",
              "      <td>0.022581</td>\n",
              "      <td>0.364288</td>\n",
              "      <td>0.049610</td>\n",
              "      <td>-0.399424</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099421</td>\n",
              "      <td>-0.262445</td>\n",
              "      <td>-0.107570</td>\n",
              "      <td>-0.016850</td>\n",
              "      <td>-0.126997</td>\n",
              "      <td>0.310287</td>\n",
              "      <td>0.147301</td>\n",
              "      <td>-0.402322</td>\n",
              "      <td>-0.075155</td>\n",
              "      <td>-0.019988</td>\n",
              "      <td>-0.218327</td>\n",
              "      <td>0.175955</td>\n",
              "      <td>-0.169838</td>\n",
              "      <td>-0.140395</td>\n",
              "      <td>0.015053</td>\n",
              "      <td>0.103077</td>\n",
              "      <td>0.181871</td>\n",
              "      <td>0.007587</td>\n",
              "      <td>-0.198375</td>\n",
              "      <td>0.177774</td>\n",
              "      <td>-0.052815</td>\n",
              "      <td>-0.007001</td>\n",
              "      <td>0.203554</td>\n",
              "      <td>0.026453</td>\n",
              "      <td>-0.423742</td>\n",
              "      <td>-0.350420</td>\n",
              "      <td>0.132284</td>\n",
              "      <td>0.103796</td>\n",
              "      <td>0.007285</td>\n",
              "      <td>0.278350</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>-0.169350</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>-0.181834</td>\n",
              "      <td>-0.238829</td>\n",
              "      <td>-0.275099</td>\n",
              "      <td>0.104271</td>\n",
              "      <td>-0.520282</td>\n",
              "      <td>-0.120962</td>\n",
              "      <td>-0.147879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2294</th>\n",
              "      <td>-0.370119</td>\n",
              "      <td>0.031962</td>\n",
              "      <td>-0.109865</td>\n",
              "      <td>0.297458</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0.209004</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.354349</td>\n",
              "      <td>-0.222928</td>\n",
              "      <td>-0.514638</td>\n",
              "      <td>-0.079176</td>\n",
              "      <td>-0.609773</td>\n",
              "      <td>0.321759</td>\n",
              "      <td>0.013534</td>\n",
              "      <td>0.503136</td>\n",
              "      <td>0.060016</td>\n",
              "      <td>0.346563</td>\n",
              "      <td>-0.142549</td>\n",
              "      <td>0.012023</td>\n",
              "      <td>-0.335389</td>\n",
              "      <td>0.003859</td>\n",
              "      <td>0.402099</td>\n",
              "      <td>0.549898</td>\n",
              "      <td>-0.341390</td>\n",
              "      <td>0.185277</td>\n",
              "      <td>-0.151288</td>\n",
              "      <td>-0.055421</td>\n",
              "      <td>-0.028700</td>\n",
              "      <td>0.322586</td>\n",
              "      <td>0.197591</td>\n",
              "      <td>0.097427</td>\n",
              "      <td>0.141152</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.265539</td>\n",
              "      <td>0.178179</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>0.419388</td>\n",
              "      <td>0.485513</td>\n",
              "      <td>0.311476</td>\n",
              "      <td>0.252392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384510</td>\n",
              "      <td>-0.010529</td>\n",
              "      <td>0.119058</td>\n",
              "      <td>-0.078039</td>\n",
              "      <td>-0.113407</td>\n",
              "      <td>-0.148094</td>\n",
              "      <td>-0.258990</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>0.387888</td>\n",
              "      <td>-0.143700</td>\n",
              "      <td>-0.021616</td>\n",
              "      <td>-0.141920</td>\n",
              "      <td>-0.128254</td>\n",
              "      <td>0.189747</td>\n",
              "      <td>-0.066199</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>0.360275</td>\n",
              "      <td>-0.723010</td>\n",
              "      <td>0.422365</td>\n",
              "      <td>-0.061265</td>\n",
              "      <td>-0.131536</td>\n",
              "      <td>-0.150126</td>\n",
              "      <td>0.009457</td>\n",
              "      <td>-0.218707</td>\n",
              "      <td>-0.077923</td>\n",
              "      <td>0.323542</td>\n",
              "      <td>0.353583</td>\n",
              "      <td>0.331252</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.217525</td>\n",
              "      <td>-0.138142</td>\n",
              "      <td>0.515318</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>0.140498</td>\n",
              "      <td>-0.040132</td>\n",
              "      <td>-0.220662</td>\n",
              "      <td>-0.382914</td>\n",
              "      <td>0.380720</td>\n",
              "      <td>-0.014164</td>\n",
              "      <td>0.303776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2295</th>\n",
              "      <td>-0.334936</td>\n",
              "      <td>-0.237400</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>0.307774</td>\n",
              "      <td>0.552991</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>-0.128793</td>\n",
              "      <td>0.184903</td>\n",
              "      <td>-0.300067</td>\n",
              "      <td>-0.160469</td>\n",
              "      <td>-0.137007</td>\n",
              "      <td>-0.380960</td>\n",
              "      <td>0.067295</td>\n",
              "      <td>-0.350619</td>\n",
              "      <td>0.319733</td>\n",
              "      <td>0.312155</td>\n",
              "      <td>0.234408</td>\n",
              "      <td>0.456366</td>\n",
              "      <td>0.103505</td>\n",
              "      <td>-0.163476</td>\n",
              "      <td>-0.112946</td>\n",
              "      <td>0.273597</td>\n",
              "      <td>0.274887</td>\n",
              "      <td>-0.008497</td>\n",
              "      <td>-0.404606</td>\n",
              "      <td>-0.219477</td>\n",
              "      <td>0.200002</td>\n",
              "      <td>0.470362</td>\n",
              "      <td>0.067487</td>\n",
              "      <td>-0.013588</td>\n",
              "      <td>-0.049962</td>\n",
              "      <td>-0.066518</td>\n",
              "      <td>-0.108149</td>\n",
              "      <td>-0.090050</td>\n",
              "      <td>0.477854</td>\n",
              "      <td>-0.432016</td>\n",
              "      <td>0.279654</td>\n",
              "      <td>0.297045</td>\n",
              "      <td>-0.167063</td>\n",
              "      <td>0.094208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>-0.071417</td>\n",
              "      <td>-0.103228</td>\n",
              "      <td>-0.008193</td>\n",
              "      <td>-0.482496</td>\n",
              "      <td>-0.107093</td>\n",
              "      <td>0.380227</td>\n",
              "      <td>-0.081455</td>\n",
              "      <td>0.418951</td>\n",
              "      <td>-0.213351</td>\n",
              "      <td>-0.182586</td>\n",
              "      <td>-0.167677</td>\n",
              "      <td>0.183418</td>\n",
              "      <td>-0.053785</td>\n",
              "      <td>0.092943</td>\n",
              "      <td>-0.330301</td>\n",
              "      <td>-0.024515</td>\n",
              "      <td>-0.559753</td>\n",
              "      <td>0.022932</td>\n",
              "      <td>0.180525</td>\n",
              "      <td>0.188712</td>\n",
              "      <td>0.027331</td>\n",
              "      <td>-0.235138</td>\n",
              "      <td>-0.330035</td>\n",
              "      <td>0.122914</td>\n",
              "      <td>0.102582</td>\n",
              "      <td>-0.103969</td>\n",
              "      <td>-0.070550</td>\n",
              "      <td>-0.079660</td>\n",
              "      <td>0.035513</td>\n",
              "      <td>-0.149414</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>-0.103845</td>\n",
              "      <td>0.242430</td>\n",
              "      <td>0.017625</td>\n",
              "      <td>-0.328206</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.093238</td>\n",
              "      <td>0.037537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2296</th>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.100156</td>\n",
              "      <td>-0.181406</td>\n",
              "      <td>0.123134</td>\n",
              "      <td>-0.248711</td>\n",
              "      <td>0.386225</td>\n",
              "      <td>0.071953</td>\n",
              "      <td>0.316884</td>\n",
              "      <td>-0.297754</td>\n",
              "      <td>-0.585618</td>\n",
              "      <td>-0.599487</td>\n",
              "      <td>-0.883622</td>\n",
              "      <td>0.226984</td>\n",
              "      <td>-0.302107</td>\n",
              "      <td>0.742923</td>\n",
              "      <td>-0.127922</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.163219</td>\n",
              "      <td>0.103186</td>\n",
              "      <td>-0.484405</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.024954</td>\n",
              "      <td>0.405841</td>\n",
              "      <td>-0.307482</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.075125</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.205681</td>\n",
              "      <td>-0.225701</td>\n",
              "      <td>0.155992</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>0.079980</td>\n",
              "      <td>-0.199730</td>\n",
              "      <td>0.141558</td>\n",
              "      <td>-0.142644</td>\n",
              "      <td>0.390152</td>\n",
              "      <td>0.426615</td>\n",
              "      <td>0.088414</td>\n",
              "      <td>0.210211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120282</td>\n",
              "      <td>-0.229974</td>\n",
              "      <td>-0.054204</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>-0.093858</td>\n",
              "      <td>-0.182911</td>\n",
              "      <td>-0.011829</td>\n",
              "      <td>-0.233442</td>\n",
              "      <td>0.685782</td>\n",
              "      <td>-0.358191</td>\n",
              "      <td>0.020692</td>\n",
              "      <td>0.152990</td>\n",
              "      <td>0.288014</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>-0.129584</td>\n",
              "      <td>-0.258241</td>\n",
              "      <td>0.386515</td>\n",
              "      <td>-0.658014</td>\n",
              "      <td>0.211520</td>\n",
              "      <td>0.296892</td>\n",
              "      <td>-0.153062</td>\n",
              "      <td>-0.045540</td>\n",
              "      <td>-0.337411</td>\n",
              "      <td>-0.140582</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>0.045885</td>\n",
              "      <td>0.116038</td>\n",
              "      <td>0.095674</td>\n",
              "      <td>-0.101839</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.513150</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.316020</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>-0.380363</td>\n",
              "      <td>-0.108683</td>\n",
              "      <td>-0.100425</td>\n",
              "      <td>-0.040597</td>\n",
              "      <td>0.013379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2297</th>\n",
              "      <td>0.292988</td>\n",
              "      <td>0.007353</td>\n",
              "      <td>-0.141794</td>\n",
              "      <td>-0.217709</td>\n",
              "      <td>0.061340</td>\n",
              "      <td>0.356941</td>\n",
              "      <td>0.128595</td>\n",
              "      <td>-0.399345</td>\n",
              "      <td>-0.079264</td>\n",
              "      <td>-0.041962</td>\n",
              "      <td>-0.098025</td>\n",
              "      <td>-0.324808</td>\n",
              "      <td>-0.056163</td>\n",
              "      <td>0.149594</td>\n",
              "      <td>0.111448</td>\n",
              "      <td>-0.165758</td>\n",
              "      <td>0.249520</td>\n",
              "      <td>0.274554</td>\n",
              "      <td>-0.139133</td>\n",
              "      <td>0.333623</td>\n",
              "      <td>-0.155837</td>\n",
              "      <td>-0.045190</td>\n",
              "      <td>0.285358</td>\n",
              "      <td>-0.003968</td>\n",
              "      <td>-0.303356</td>\n",
              "      <td>-0.190002</td>\n",
              "      <td>-0.266731</td>\n",
              "      <td>-0.428568</td>\n",
              "      <td>-0.096448</td>\n",
              "      <td>0.275077</td>\n",
              "      <td>-0.134497</td>\n",
              "      <td>-0.168020</td>\n",
              "      <td>-0.280440</td>\n",
              "      <td>-0.245803</td>\n",
              "      <td>0.097271</td>\n",
              "      <td>-0.328880</td>\n",
              "      <td>0.022581</td>\n",
              "      <td>0.364288</td>\n",
              "      <td>0.049610</td>\n",
              "      <td>-0.399424</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099421</td>\n",
              "      <td>-0.262445</td>\n",
              "      <td>-0.107570</td>\n",
              "      <td>-0.016850</td>\n",
              "      <td>-0.126997</td>\n",
              "      <td>0.310287</td>\n",
              "      <td>0.147301</td>\n",
              "      <td>-0.402322</td>\n",
              "      <td>-0.075155</td>\n",
              "      <td>-0.019988</td>\n",
              "      <td>-0.218327</td>\n",
              "      <td>0.175955</td>\n",
              "      <td>-0.169838</td>\n",
              "      <td>-0.140395</td>\n",
              "      <td>0.015053</td>\n",
              "      <td>0.103077</td>\n",
              "      <td>0.181871</td>\n",
              "      <td>0.007587</td>\n",
              "      <td>-0.198375</td>\n",
              "      <td>0.177774</td>\n",
              "      <td>-0.052815</td>\n",
              "      <td>-0.007001</td>\n",
              "      <td>0.203554</td>\n",
              "      <td>0.026453</td>\n",
              "      <td>-0.423742</td>\n",
              "      <td>-0.350420</td>\n",
              "      <td>0.132284</td>\n",
              "      <td>0.103796</td>\n",
              "      <td>0.007285</td>\n",
              "      <td>0.278350</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>-0.169350</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>-0.181834</td>\n",
              "      <td>-0.238829</td>\n",
              "      <td>-0.275099</td>\n",
              "      <td>0.104271</td>\n",
              "      <td>-0.520282</td>\n",
              "      <td>-0.120962</td>\n",
              "      <td>-0.147879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2298</th>\n",
              "      <td>-0.370119</td>\n",
              "      <td>0.031962</td>\n",
              "      <td>-0.109865</td>\n",
              "      <td>0.297458</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0.209004</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.354349</td>\n",
              "      <td>-0.222928</td>\n",
              "      <td>-0.514638</td>\n",
              "      <td>-0.079176</td>\n",
              "      <td>-0.609773</td>\n",
              "      <td>0.321759</td>\n",
              "      <td>0.013534</td>\n",
              "      <td>0.503136</td>\n",
              "      <td>0.060016</td>\n",
              "      <td>0.346563</td>\n",
              "      <td>-0.142549</td>\n",
              "      <td>0.012023</td>\n",
              "      <td>-0.335389</td>\n",
              "      <td>0.003859</td>\n",
              "      <td>0.402099</td>\n",
              "      <td>0.549898</td>\n",
              "      <td>-0.341390</td>\n",
              "      <td>0.185277</td>\n",
              "      <td>-0.151288</td>\n",
              "      <td>-0.055421</td>\n",
              "      <td>-0.028700</td>\n",
              "      <td>0.322586</td>\n",
              "      <td>0.197591</td>\n",
              "      <td>0.097427</td>\n",
              "      <td>0.141152</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.265539</td>\n",
              "      <td>0.178179</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>0.419388</td>\n",
              "      <td>0.485513</td>\n",
              "      <td>0.311476</td>\n",
              "      <td>0.252392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384510</td>\n",
              "      <td>-0.010529</td>\n",
              "      <td>0.119058</td>\n",
              "      <td>-0.078039</td>\n",
              "      <td>-0.113407</td>\n",
              "      <td>-0.148094</td>\n",
              "      <td>-0.258990</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>0.387888</td>\n",
              "      <td>-0.143700</td>\n",
              "      <td>-0.021616</td>\n",
              "      <td>-0.141920</td>\n",
              "      <td>-0.128254</td>\n",
              "      <td>0.189747</td>\n",
              "      <td>-0.066199</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>0.360275</td>\n",
              "      <td>-0.723010</td>\n",
              "      <td>0.422365</td>\n",
              "      <td>-0.061265</td>\n",
              "      <td>-0.131536</td>\n",
              "      <td>-0.150126</td>\n",
              "      <td>0.009457</td>\n",
              "      <td>-0.218707</td>\n",
              "      <td>-0.077923</td>\n",
              "      <td>0.323542</td>\n",
              "      <td>0.353583</td>\n",
              "      <td>0.331252</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.217525</td>\n",
              "      <td>-0.138142</td>\n",
              "      <td>0.515318</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>0.140498</td>\n",
              "      <td>-0.040132</td>\n",
              "      <td>-0.220662</td>\n",
              "      <td>-0.382914</td>\n",
              "      <td>0.380720</td>\n",
              "      <td>-0.014164</td>\n",
              "      <td>0.303776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2299</th>\n",
              "      <td>-0.334936</td>\n",
              "      <td>-0.237400</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>0.307774</td>\n",
              "      <td>0.552991</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>-0.128793</td>\n",
              "      <td>0.184903</td>\n",
              "      <td>-0.300067</td>\n",
              "      <td>-0.160469</td>\n",
              "      <td>-0.137007</td>\n",
              "      <td>-0.380960</td>\n",
              "      <td>0.067295</td>\n",
              "      <td>-0.350619</td>\n",
              "      <td>0.319733</td>\n",
              "      <td>0.312155</td>\n",
              "      <td>0.234408</td>\n",
              "      <td>0.456366</td>\n",
              "      <td>0.103505</td>\n",
              "      <td>-0.163476</td>\n",
              "      <td>-0.112946</td>\n",
              "      <td>0.273597</td>\n",
              "      <td>0.274887</td>\n",
              "      <td>-0.008497</td>\n",
              "      <td>-0.404606</td>\n",
              "      <td>-0.219477</td>\n",
              "      <td>0.200002</td>\n",
              "      <td>0.470362</td>\n",
              "      <td>0.067487</td>\n",
              "      <td>-0.013588</td>\n",
              "      <td>-0.049962</td>\n",
              "      <td>-0.066518</td>\n",
              "      <td>-0.108149</td>\n",
              "      <td>-0.090050</td>\n",
              "      <td>0.477854</td>\n",
              "      <td>-0.432016</td>\n",
              "      <td>0.279654</td>\n",
              "      <td>0.297045</td>\n",
              "      <td>-0.167063</td>\n",
              "      <td>0.094208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>-0.071417</td>\n",
              "      <td>-0.103228</td>\n",
              "      <td>-0.008193</td>\n",
              "      <td>-0.482496</td>\n",
              "      <td>-0.107093</td>\n",
              "      <td>0.380227</td>\n",
              "      <td>-0.081455</td>\n",
              "      <td>0.418951</td>\n",
              "      <td>-0.213351</td>\n",
              "      <td>-0.182586</td>\n",
              "      <td>-0.167677</td>\n",
              "      <td>0.183418</td>\n",
              "      <td>-0.053785</td>\n",
              "      <td>0.092943</td>\n",
              "      <td>-0.330301</td>\n",
              "      <td>-0.024515</td>\n",
              "      <td>-0.559753</td>\n",
              "      <td>0.022932</td>\n",
              "      <td>0.180525</td>\n",
              "      <td>0.188712</td>\n",
              "      <td>0.027331</td>\n",
              "      <td>-0.235138</td>\n",
              "      <td>-0.330035</td>\n",
              "      <td>0.122914</td>\n",
              "      <td>0.102582</td>\n",
              "      <td>-0.103969</td>\n",
              "      <td>-0.070550</td>\n",
              "      <td>-0.079660</td>\n",
              "      <td>0.035513</td>\n",
              "      <td>-0.149414</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>-0.103845</td>\n",
              "      <td>0.242430</td>\n",
              "      <td>0.017625</td>\n",
              "      <td>-0.328206</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.093238</td>\n",
              "      <td>0.037537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2300</th>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.100156</td>\n",
              "      <td>-0.181406</td>\n",
              "      <td>0.123134</td>\n",
              "      <td>-0.248711</td>\n",
              "      <td>0.386225</td>\n",
              "      <td>0.071953</td>\n",
              "      <td>0.316884</td>\n",
              "      <td>-0.297754</td>\n",
              "      <td>-0.585618</td>\n",
              "      <td>-0.599487</td>\n",
              "      <td>-0.883622</td>\n",
              "      <td>0.226984</td>\n",
              "      <td>-0.302107</td>\n",
              "      <td>0.742923</td>\n",
              "      <td>-0.127922</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.163219</td>\n",
              "      <td>0.103186</td>\n",
              "      <td>-0.484405</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.024954</td>\n",
              "      <td>0.405841</td>\n",
              "      <td>-0.307482</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.075125</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.205681</td>\n",
              "      <td>-0.225701</td>\n",
              "      <td>0.155992</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>0.079980</td>\n",
              "      <td>-0.199730</td>\n",
              "      <td>0.141558</td>\n",
              "      <td>-0.142644</td>\n",
              "      <td>0.390152</td>\n",
              "      <td>0.426615</td>\n",
              "      <td>0.088414</td>\n",
              "      <td>0.210211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120282</td>\n",
              "      <td>-0.229974</td>\n",
              "      <td>-0.054204</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>-0.093858</td>\n",
              "      <td>-0.182911</td>\n",
              "      <td>-0.011829</td>\n",
              "      <td>-0.233442</td>\n",
              "      <td>0.685782</td>\n",
              "      <td>-0.358191</td>\n",
              "      <td>0.020692</td>\n",
              "      <td>0.152990</td>\n",
              "      <td>0.288014</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>-0.129584</td>\n",
              "      <td>-0.258241</td>\n",
              "      <td>0.386515</td>\n",
              "      <td>-0.658014</td>\n",
              "      <td>0.211520</td>\n",
              "      <td>0.296892</td>\n",
              "      <td>-0.153062</td>\n",
              "      <td>-0.045540</td>\n",
              "      <td>-0.337411</td>\n",
              "      <td>-0.140582</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>0.045885</td>\n",
              "      <td>0.116038</td>\n",
              "      <td>0.095674</td>\n",
              "      <td>-0.101839</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.513150</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.316020</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>-0.380363</td>\n",
              "      <td>-0.108683</td>\n",
              "      <td>-0.100425</td>\n",
              "      <td>-0.040597</td>\n",
              "      <td>0.013379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2301</th>\n",
              "      <td>0.292988</td>\n",
              "      <td>0.007353</td>\n",
              "      <td>-0.141794</td>\n",
              "      <td>-0.217709</td>\n",
              "      <td>0.061340</td>\n",
              "      <td>0.356941</td>\n",
              "      <td>0.128595</td>\n",
              "      <td>-0.399345</td>\n",
              "      <td>-0.079264</td>\n",
              "      <td>-0.041962</td>\n",
              "      <td>-0.098025</td>\n",
              "      <td>-0.324808</td>\n",
              "      <td>-0.056163</td>\n",
              "      <td>0.149594</td>\n",
              "      <td>0.111448</td>\n",
              "      <td>-0.165758</td>\n",
              "      <td>0.249520</td>\n",
              "      <td>0.274554</td>\n",
              "      <td>-0.139133</td>\n",
              "      <td>0.333623</td>\n",
              "      <td>-0.155837</td>\n",
              "      <td>-0.045190</td>\n",
              "      <td>0.285358</td>\n",
              "      <td>-0.003968</td>\n",
              "      <td>-0.303356</td>\n",
              "      <td>-0.190002</td>\n",
              "      <td>-0.266731</td>\n",
              "      <td>-0.428568</td>\n",
              "      <td>-0.096448</td>\n",
              "      <td>0.275077</td>\n",
              "      <td>-0.134497</td>\n",
              "      <td>-0.168020</td>\n",
              "      <td>-0.280440</td>\n",
              "      <td>-0.245803</td>\n",
              "      <td>0.097271</td>\n",
              "      <td>-0.328880</td>\n",
              "      <td>0.022581</td>\n",
              "      <td>0.364288</td>\n",
              "      <td>0.049610</td>\n",
              "      <td>-0.399424</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099421</td>\n",
              "      <td>-0.262445</td>\n",
              "      <td>-0.107570</td>\n",
              "      <td>-0.016850</td>\n",
              "      <td>-0.126997</td>\n",
              "      <td>0.310287</td>\n",
              "      <td>0.147301</td>\n",
              "      <td>-0.402322</td>\n",
              "      <td>-0.075155</td>\n",
              "      <td>-0.019988</td>\n",
              "      <td>-0.218327</td>\n",
              "      <td>0.175955</td>\n",
              "      <td>-0.169838</td>\n",
              "      <td>-0.140395</td>\n",
              "      <td>0.015053</td>\n",
              "      <td>0.103077</td>\n",
              "      <td>0.181871</td>\n",
              "      <td>0.007587</td>\n",
              "      <td>-0.198375</td>\n",
              "      <td>0.177774</td>\n",
              "      <td>-0.052815</td>\n",
              "      <td>-0.007001</td>\n",
              "      <td>0.203554</td>\n",
              "      <td>0.026453</td>\n",
              "      <td>-0.423742</td>\n",
              "      <td>-0.350420</td>\n",
              "      <td>0.132284</td>\n",
              "      <td>0.103796</td>\n",
              "      <td>0.007285</td>\n",
              "      <td>0.278350</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>-0.169350</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>-0.181834</td>\n",
              "      <td>-0.238829</td>\n",
              "      <td>-0.275099</td>\n",
              "      <td>0.104271</td>\n",
              "      <td>-0.520282</td>\n",
              "      <td>-0.120962</td>\n",
              "      <td>-0.147879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2302</th>\n",
              "      <td>-0.370119</td>\n",
              "      <td>0.031962</td>\n",
              "      <td>-0.109865</td>\n",
              "      <td>0.297458</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0.209004</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.354349</td>\n",
              "      <td>-0.222928</td>\n",
              "      <td>-0.514638</td>\n",
              "      <td>-0.079176</td>\n",
              "      <td>-0.609773</td>\n",
              "      <td>0.321759</td>\n",
              "      <td>0.013534</td>\n",
              "      <td>0.503136</td>\n",
              "      <td>0.060016</td>\n",
              "      <td>0.346563</td>\n",
              "      <td>-0.142549</td>\n",
              "      <td>0.012023</td>\n",
              "      <td>-0.335389</td>\n",
              "      <td>0.003859</td>\n",
              "      <td>0.402099</td>\n",
              "      <td>0.549898</td>\n",
              "      <td>-0.341390</td>\n",
              "      <td>0.185277</td>\n",
              "      <td>-0.151288</td>\n",
              "      <td>-0.055421</td>\n",
              "      <td>-0.028700</td>\n",
              "      <td>0.322586</td>\n",
              "      <td>0.197591</td>\n",
              "      <td>0.097427</td>\n",
              "      <td>0.141152</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.265539</td>\n",
              "      <td>0.178179</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>0.419388</td>\n",
              "      <td>0.485513</td>\n",
              "      <td>0.311476</td>\n",
              "      <td>0.252392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384510</td>\n",
              "      <td>-0.010529</td>\n",
              "      <td>0.119058</td>\n",
              "      <td>-0.078039</td>\n",
              "      <td>-0.113407</td>\n",
              "      <td>-0.148094</td>\n",
              "      <td>-0.258990</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>0.387888</td>\n",
              "      <td>-0.143700</td>\n",
              "      <td>-0.021616</td>\n",
              "      <td>-0.141920</td>\n",
              "      <td>-0.128254</td>\n",
              "      <td>0.189747</td>\n",
              "      <td>-0.066199</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>0.360275</td>\n",
              "      <td>-0.723010</td>\n",
              "      <td>0.422365</td>\n",
              "      <td>-0.061265</td>\n",
              "      <td>-0.131536</td>\n",
              "      <td>-0.150126</td>\n",
              "      <td>0.009457</td>\n",
              "      <td>-0.218707</td>\n",
              "      <td>-0.077923</td>\n",
              "      <td>0.323542</td>\n",
              "      <td>0.353583</td>\n",
              "      <td>0.331252</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.217525</td>\n",
              "      <td>-0.138142</td>\n",
              "      <td>0.515318</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>0.140498</td>\n",
              "      <td>-0.040132</td>\n",
              "      <td>-0.220662</td>\n",
              "      <td>-0.382914</td>\n",
              "      <td>0.380720</td>\n",
              "      <td>-0.014164</td>\n",
              "      <td>0.303776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2303</th>\n",
              "      <td>-0.334936</td>\n",
              "      <td>-0.237400</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>0.307774</td>\n",
              "      <td>0.552991</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>-0.128793</td>\n",
              "      <td>0.184903</td>\n",
              "      <td>-0.300067</td>\n",
              "      <td>-0.160469</td>\n",
              "      <td>-0.137007</td>\n",
              "      <td>-0.380960</td>\n",
              "      <td>0.067295</td>\n",
              "      <td>-0.350619</td>\n",
              "      <td>0.319733</td>\n",
              "      <td>0.312155</td>\n",
              "      <td>0.234408</td>\n",
              "      <td>0.456366</td>\n",
              "      <td>0.103505</td>\n",
              "      <td>-0.163476</td>\n",
              "      <td>-0.112946</td>\n",
              "      <td>0.273597</td>\n",
              "      <td>0.274887</td>\n",
              "      <td>-0.008497</td>\n",
              "      <td>-0.404606</td>\n",
              "      <td>-0.219477</td>\n",
              "      <td>0.200002</td>\n",
              "      <td>0.470362</td>\n",
              "      <td>0.067487</td>\n",
              "      <td>-0.013588</td>\n",
              "      <td>-0.049962</td>\n",
              "      <td>-0.066518</td>\n",
              "      <td>-0.108149</td>\n",
              "      <td>-0.090050</td>\n",
              "      <td>0.477854</td>\n",
              "      <td>-0.432016</td>\n",
              "      <td>0.279654</td>\n",
              "      <td>0.297045</td>\n",
              "      <td>-0.167063</td>\n",
              "      <td>0.094208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>-0.071417</td>\n",
              "      <td>-0.103228</td>\n",
              "      <td>-0.008193</td>\n",
              "      <td>-0.482496</td>\n",
              "      <td>-0.107093</td>\n",
              "      <td>0.380227</td>\n",
              "      <td>-0.081455</td>\n",
              "      <td>0.418951</td>\n",
              "      <td>-0.213351</td>\n",
              "      <td>-0.182586</td>\n",
              "      <td>-0.167677</td>\n",
              "      <td>0.183418</td>\n",
              "      <td>-0.053785</td>\n",
              "      <td>0.092943</td>\n",
              "      <td>-0.330301</td>\n",
              "      <td>-0.024515</td>\n",
              "      <td>-0.559753</td>\n",
              "      <td>0.022932</td>\n",
              "      <td>0.180525</td>\n",
              "      <td>0.188712</td>\n",
              "      <td>0.027331</td>\n",
              "      <td>-0.235138</td>\n",
              "      <td>-0.330035</td>\n",
              "      <td>0.122914</td>\n",
              "      <td>0.102582</td>\n",
              "      <td>-0.103969</td>\n",
              "      <td>-0.070550</td>\n",
              "      <td>-0.079660</td>\n",
              "      <td>0.035513</td>\n",
              "      <td>-0.149414</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>-0.103845</td>\n",
              "      <td>0.242430</td>\n",
              "      <td>0.017625</td>\n",
              "      <td>-0.328206</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.093238</td>\n",
              "      <td>0.037537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2304</th>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.100156</td>\n",
              "      <td>-0.181406</td>\n",
              "      <td>0.123134</td>\n",
              "      <td>-0.248711</td>\n",
              "      <td>0.386225</td>\n",
              "      <td>0.071953</td>\n",
              "      <td>0.316884</td>\n",
              "      <td>-0.297754</td>\n",
              "      <td>-0.585618</td>\n",
              "      <td>-0.599487</td>\n",
              "      <td>-0.883622</td>\n",
              "      <td>0.226984</td>\n",
              "      <td>-0.302107</td>\n",
              "      <td>0.742923</td>\n",
              "      <td>-0.127922</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.163219</td>\n",
              "      <td>0.103186</td>\n",
              "      <td>-0.484405</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.024954</td>\n",
              "      <td>0.405841</td>\n",
              "      <td>-0.307482</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.075125</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.205681</td>\n",
              "      <td>-0.225701</td>\n",
              "      <td>0.155992</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>0.079980</td>\n",
              "      <td>-0.199730</td>\n",
              "      <td>0.141558</td>\n",
              "      <td>-0.142644</td>\n",
              "      <td>0.390152</td>\n",
              "      <td>0.426615</td>\n",
              "      <td>0.088414</td>\n",
              "      <td>0.210211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120282</td>\n",
              "      <td>-0.229974</td>\n",
              "      <td>-0.054204</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>-0.093858</td>\n",
              "      <td>-0.182911</td>\n",
              "      <td>-0.011829</td>\n",
              "      <td>-0.233442</td>\n",
              "      <td>0.685782</td>\n",
              "      <td>-0.358191</td>\n",
              "      <td>0.020692</td>\n",
              "      <td>0.152990</td>\n",
              "      <td>0.288014</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>-0.129584</td>\n",
              "      <td>-0.258241</td>\n",
              "      <td>0.386515</td>\n",
              "      <td>-0.658014</td>\n",
              "      <td>0.211520</td>\n",
              "      <td>0.296892</td>\n",
              "      <td>-0.153062</td>\n",
              "      <td>-0.045540</td>\n",
              "      <td>-0.337411</td>\n",
              "      <td>-0.140582</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>0.045885</td>\n",
              "      <td>0.116038</td>\n",
              "      <td>0.095674</td>\n",
              "      <td>-0.101839</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.513150</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.316020</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>-0.380363</td>\n",
              "      <td>-0.108683</td>\n",
              "      <td>-0.100425</td>\n",
              "      <td>-0.040597</td>\n",
              "      <td>0.013379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2305</th>\n",
              "      <td>-0.035378</td>\n",
              "      <td>0.171331</td>\n",
              "      <td>0.132767</td>\n",
              "      <td>-0.233001</td>\n",
              "      <td>0.136293</td>\n",
              "      <td>0.175659</td>\n",
              "      <td>0.116257</td>\n",
              "      <td>0.348660</td>\n",
              "      <td>-0.024250</td>\n",
              "      <td>-0.343592</td>\n",
              "      <td>-0.130428</td>\n",
              "      <td>-0.068458</td>\n",
              "      <td>0.115720</td>\n",
              "      <td>-0.451281</td>\n",
              "      <td>0.357894</td>\n",
              "      <td>-0.360599</td>\n",
              "      <td>0.486356</td>\n",
              "      <td>-0.267105</td>\n",
              "      <td>0.283124</td>\n",
              "      <td>-0.736278</td>\n",
              "      <td>-0.313726</td>\n",
              "      <td>0.487883</td>\n",
              "      <td>-0.033683</td>\n",
              "      <td>-0.150038</td>\n",
              "      <td>-0.070887</td>\n",
              "      <td>-0.083686</td>\n",
              "      <td>-0.156398</td>\n",
              "      <td>0.176278</td>\n",
              "      <td>0.059152</td>\n",
              "      <td>0.075023</td>\n",
              "      <td>-0.080019</td>\n",
              "      <td>-0.392358</td>\n",
              "      <td>-0.256684</td>\n",
              "      <td>-0.303789</td>\n",
              "      <td>0.266952</td>\n",
              "      <td>-0.323793</td>\n",
              "      <td>-0.065364</td>\n",
              "      <td>0.473862</td>\n",
              "      <td>-0.395860</td>\n",
              "      <td>-0.117914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023888</td>\n",
              "      <td>-0.153655</td>\n",
              "      <td>0.055894</td>\n",
              "      <td>0.323206</td>\n",
              "      <td>-0.214055</td>\n",
              "      <td>-0.472063</td>\n",
              "      <td>0.134280</td>\n",
              "      <td>-0.200878</td>\n",
              "      <td>0.110387</td>\n",
              "      <td>0.226219</td>\n",
              "      <td>-0.067288</td>\n",
              "      <td>-0.569574</td>\n",
              "      <td>-0.140889</td>\n",
              "      <td>0.422617</td>\n",
              "      <td>-0.350821</td>\n",
              "      <td>-0.007644</td>\n",
              "      <td>0.485076</td>\n",
              "      <td>0.062592</td>\n",
              "      <td>-0.321722</td>\n",
              "      <td>0.456189</td>\n",
              "      <td>0.188972</td>\n",
              "      <td>0.144965</td>\n",
              "      <td>-0.302025</td>\n",
              "      <td>-0.226508</td>\n",
              "      <td>0.122920</td>\n",
              "      <td>-0.037280</td>\n",
              "      <td>-0.070248</td>\n",
              "      <td>-0.060841</td>\n",
              "      <td>-0.180645</td>\n",
              "      <td>0.281859</td>\n",
              "      <td>0.529464</td>\n",
              "      <td>0.165989</td>\n",
              "      <td>0.430295</td>\n",
              "      <td>-0.263375</td>\n",
              "      <td>-0.021098</td>\n",
              "      <td>-0.565196</td>\n",
              "      <td>0.280726</td>\n",
              "      <td>0.143810</td>\n",
              "      <td>-0.022290</td>\n",
              "      <td>0.427308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2306</th>\n",
              "      <td>-0.370119</td>\n",
              "      <td>0.031962</td>\n",
              "      <td>-0.109865</td>\n",
              "      <td>0.297458</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0.209004</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.354349</td>\n",
              "      <td>-0.222928</td>\n",
              "      <td>-0.514638</td>\n",
              "      <td>-0.079176</td>\n",
              "      <td>-0.609773</td>\n",
              "      <td>0.321759</td>\n",
              "      <td>0.013534</td>\n",
              "      <td>0.503136</td>\n",
              "      <td>0.060016</td>\n",
              "      <td>0.346563</td>\n",
              "      <td>-0.142549</td>\n",
              "      <td>0.012023</td>\n",
              "      <td>-0.335389</td>\n",
              "      <td>0.003859</td>\n",
              "      <td>0.402099</td>\n",
              "      <td>0.549898</td>\n",
              "      <td>-0.341390</td>\n",
              "      <td>0.185277</td>\n",
              "      <td>-0.151288</td>\n",
              "      <td>-0.055421</td>\n",
              "      <td>-0.028700</td>\n",
              "      <td>0.322586</td>\n",
              "      <td>0.197591</td>\n",
              "      <td>0.097427</td>\n",
              "      <td>0.141152</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.265539</td>\n",
              "      <td>0.178179</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>0.419388</td>\n",
              "      <td>0.485513</td>\n",
              "      <td>0.311476</td>\n",
              "      <td>0.252392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384510</td>\n",
              "      <td>-0.010529</td>\n",
              "      <td>0.119058</td>\n",
              "      <td>-0.078039</td>\n",
              "      <td>-0.113407</td>\n",
              "      <td>-0.148094</td>\n",
              "      <td>-0.258990</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>0.387888</td>\n",
              "      <td>-0.143700</td>\n",
              "      <td>-0.021616</td>\n",
              "      <td>-0.141920</td>\n",
              "      <td>-0.128254</td>\n",
              "      <td>0.189747</td>\n",
              "      <td>-0.066199</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>0.360275</td>\n",
              "      <td>-0.723010</td>\n",
              "      <td>0.422365</td>\n",
              "      <td>-0.061265</td>\n",
              "      <td>-0.131536</td>\n",
              "      <td>-0.150126</td>\n",
              "      <td>0.009457</td>\n",
              "      <td>-0.218707</td>\n",
              "      <td>-0.077923</td>\n",
              "      <td>0.323542</td>\n",
              "      <td>0.353583</td>\n",
              "      <td>0.331252</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.217525</td>\n",
              "      <td>-0.138142</td>\n",
              "      <td>0.515318</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>0.140498</td>\n",
              "      <td>-0.040132</td>\n",
              "      <td>-0.220662</td>\n",
              "      <td>-0.382914</td>\n",
              "      <td>0.380720</td>\n",
              "      <td>-0.014164</td>\n",
              "      <td>0.303776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2307</th>\n",
              "      <td>0.102415</td>\n",
              "      <td>0.042386</td>\n",
              "      <td>0.310881</td>\n",
              "      <td>-0.172202</td>\n",
              "      <td>0.041934</td>\n",
              "      <td>-0.037599</td>\n",
              "      <td>-0.017747</td>\n",
              "      <td>-0.101974</td>\n",
              "      <td>0.221890</td>\n",
              "      <td>-0.121221</td>\n",
              "      <td>-0.045917</td>\n",
              "      <td>-0.217697</td>\n",
              "      <td>0.043612</td>\n",
              "      <td>-0.419584</td>\n",
              "      <td>0.110066</td>\n",
              "      <td>-0.393416</td>\n",
              "      <td>0.156480</td>\n",
              "      <td>-0.222948</td>\n",
              "      <td>0.380319</td>\n",
              "      <td>-0.092568</td>\n",
              "      <td>-0.166542</td>\n",
              "      <td>0.273399</td>\n",
              "      <td>-0.303653</td>\n",
              "      <td>0.120441</td>\n",
              "      <td>0.100493</td>\n",
              "      <td>-0.402442</td>\n",
              "      <td>0.030782</td>\n",
              "      <td>0.344840</td>\n",
              "      <td>0.001193</td>\n",
              "      <td>0.105918</td>\n",
              "      <td>-0.154641</td>\n",
              "      <td>-0.241585</td>\n",
              "      <td>0.032094</td>\n",
              "      <td>-0.291548</td>\n",
              "      <td>-0.053396</td>\n",
              "      <td>-0.125002</td>\n",
              "      <td>-0.058767</td>\n",
              "      <td>0.282575</td>\n",
              "      <td>-0.307751</td>\n",
              "      <td>0.011007</td>\n",
              "      <td>...</td>\n",
              "      <td>0.309844</td>\n",
              "      <td>-0.104676</td>\n",
              "      <td>-0.128538</td>\n",
              "      <td>0.445901</td>\n",
              "      <td>0.021368</td>\n",
              "      <td>-0.382101</td>\n",
              "      <td>-0.051052</td>\n",
              "      <td>-0.105399</td>\n",
              "      <td>0.208992</td>\n",
              "      <td>0.157963</td>\n",
              "      <td>-0.211057</td>\n",
              "      <td>-0.459729</td>\n",
              "      <td>-0.082860</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>-0.086988</td>\n",
              "      <td>0.292095</td>\n",
              "      <td>0.307081</td>\n",
              "      <td>-0.095683</td>\n",
              "      <td>-0.306939</td>\n",
              "      <td>0.406865</td>\n",
              "      <td>-0.038280</td>\n",
              "      <td>0.121701</td>\n",
              "      <td>-0.117689</td>\n",
              "      <td>-0.274301</td>\n",
              "      <td>0.018526</td>\n",
              "      <td>0.156622</td>\n",
              "      <td>0.061364</td>\n",
              "      <td>0.264608</td>\n",
              "      <td>-0.256757</td>\n",
              "      <td>0.068713</td>\n",
              "      <td>0.340284</td>\n",
              "      <td>0.171523</td>\n",
              "      <td>0.473499</td>\n",
              "      <td>-0.086825</td>\n",
              "      <td>0.559150</td>\n",
              "      <td>-0.581624</td>\n",
              "      <td>0.376166</td>\n",
              "      <td>0.204096</td>\n",
              "      <td>0.127397</td>\n",
              "      <td>0.518637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2308</th>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.100156</td>\n",
              "      <td>-0.181406</td>\n",
              "      <td>0.123134</td>\n",
              "      <td>-0.248711</td>\n",
              "      <td>0.386225</td>\n",
              "      <td>0.071953</td>\n",
              "      <td>0.316884</td>\n",
              "      <td>-0.297754</td>\n",
              "      <td>-0.585618</td>\n",
              "      <td>-0.599487</td>\n",
              "      <td>-0.883622</td>\n",
              "      <td>0.226984</td>\n",
              "      <td>-0.302107</td>\n",
              "      <td>0.742923</td>\n",
              "      <td>-0.127922</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.163219</td>\n",
              "      <td>0.103186</td>\n",
              "      <td>-0.484405</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.024954</td>\n",
              "      <td>0.405841</td>\n",
              "      <td>-0.307482</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.075125</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.205681</td>\n",
              "      <td>-0.225701</td>\n",
              "      <td>0.155992</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>0.079980</td>\n",
              "      <td>-0.199730</td>\n",
              "      <td>0.141558</td>\n",
              "      <td>-0.142644</td>\n",
              "      <td>0.390152</td>\n",
              "      <td>0.426615</td>\n",
              "      <td>0.088414</td>\n",
              "      <td>0.210211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120282</td>\n",
              "      <td>-0.229974</td>\n",
              "      <td>-0.054204</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>-0.093858</td>\n",
              "      <td>-0.182911</td>\n",
              "      <td>-0.011829</td>\n",
              "      <td>-0.233442</td>\n",
              "      <td>0.685782</td>\n",
              "      <td>-0.358191</td>\n",
              "      <td>0.020692</td>\n",
              "      <td>0.152990</td>\n",
              "      <td>0.288014</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>-0.129584</td>\n",
              "      <td>-0.258241</td>\n",
              "      <td>0.386515</td>\n",
              "      <td>-0.658014</td>\n",
              "      <td>0.211520</td>\n",
              "      <td>0.296892</td>\n",
              "      <td>-0.153062</td>\n",
              "      <td>-0.045540</td>\n",
              "      <td>-0.337411</td>\n",
              "      <td>-0.140582</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>0.045885</td>\n",
              "      <td>0.116038</td>\n",
              "      <td>0.095674</td>\n",
              "      <td>-0.101839</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.513150</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.316020</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>-0.380363</td>\n",
              "      <td>-0.108683</td>\n",
              "      <td>-0.100425</td>\n",
              "      <td>-0.040597</td>\n",
              "      <td>0.013379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2309</th>\n",
              "      <td>-0.035378</td>\n",
              "      <td>0.171331</td>\n",
              "      <td>0.132767</td>\n",
              "      <td>-0.233001</td>\n",
              "      <td>0.136293</td>\n",
              "      <td>0.175659</td>\n",
              "      <td>0.116257</td>\n",
              "      <td>0.348660</td>\n",
              "      <td>-0.024250</td>\n",
              "      <td>-0.343592</td>\n",
              "      <td>-0.130428</td>\n",
              "      <td>-0.068458</td>\n",
              "      <td>0.115720</td>\n",
              "      <td>-0.451281</td>\n",
              "      <td>0.357894</td>\n",
              "      <td>-0.360599</td>\n",
              "      <td>0.486356</td>\n",
              "      <td>-0.267105</td>\n",
              "      <td>0.283124</td>\n",
              "      <td>-0.736278</td>\n",
              "      <td>-0.313726</td>\n",
              "      <td>0.487883</td>\n",
              "      <td>-0.033683</td>\n",
              "      <td>-0.150038</td>\n",
              "      <td>-0.070887</td>\n",
              "      <td>-0.083686</td>\n",
              "      <td>-0.156398</td>\n",
              "      <td>0.176278</td>\n",
              "      <td>0.059152</td>\n",
              "      <td>0.075023</td>\n",
              "      <td>-0.080019</td>\n",
              "      <td>-0.392358</td>\n",
              "      <td>-0.256684</td>\n",
              "      <td>-0.303789</td>\n",
              "      <td>0.266952</td>\n",
              "      <td>-0.323793</td>\n",
              "      <td>-0.065364</td>\n",
              "      <td>0.473862</td>\n",
              "      <td>-0.395860</td>\n",
              "      <td>-0.117914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023888</td>\n",
              "      <td>-0.153655</td>\n",
              "      <td>0.055894</td>\n",
              "      <td>0.323206</td>\n",
              "      <td>-0.214055</td>\n",
              "      <td>-0.472063</td>\n",
              "      <td>0.134280</td>\n",
              "      <td>-0.200878</td>\n",
              "      <td>0.110387</td>\n",
              "      <td>0.226219</td>\n",
              "      <td>-0.067288</td>\n",
              "      <td>-0.569574</td>\n",
              "      <td>-0.140889</td>\n",
              "      <td>0.422617</td>\n",
              "      <td>-0.350821</td>\n",
              "      <td>-0.007644</td>\n",
              "      <td>0.485076</td>\n",
              "      <td>0.062592</td>\n",
              "      <td>-0.321722</td>\n",
              "      <td>0.456189</td>\n",
              "      <td>0.188972</td>\n",
              "      <td>0.144965</td>\n",
              "      <td>-0.302025</td>\n",
              "      <td>-0.226508</td>\n",
              "      <td>0.122920</td>\n",
              "      <td>-0.037280</td>\n",
              "      <td>-0.070248</td>\n",
              "      <td>-0.060841</td>\n",
              "      <td>-0.180645</td>\n",
              "      <td>0.281859</td>\n",
              "      <td>0.529464</td>\n",
              "      <td>0.165989</td>\n",
              "      <td>0.430295</td>\n",
              "      <td>-0.263375</td>\n",
              "      <td>-0.021098</td>\n",
              "      <td>-0.565196</td>\n",
              "      <td>0.280726</td>\n",
              "      <td>0.143810</td>\n",
              "      <td>-0.022290</td>\n",
              "      <td>0.427308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2310</th>\n",
              "      <td>-0.370119</td>\n",
              "      <td>0.031962</td>\n",
              "      <td>-0.109865</td>\n",
              "      <td>0.297458</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0.209004</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.354349</td>\n",
              "      <td>-0.222928</td>\n",
              "      <td>-0.514638</td>\n",
              "      <td>-0.079176</td>\n",
              "      <td>-0.609773</td>\n",
              "      <td>0.321759</td>\n",
              "      <td>0.013534</td>\n",
              "      <td>0.503136</td>\n",
              "      <td>0.060016</td>\n",
              "      <td>0.346563</td>\n",
              "      <td>-0.142549</td>\n",
              "      <td>0.012023</td>\n",
              "      <td>-0.335389</td>\n",
              "      <td>0.003859</td>\n",
              "      <td>0.402099</td>\n",
              "      <td>0.549898</td>\n",
              "      <td>-0.341390</td>\n",
              "      <td>0.185277</td>\n",
              "      <td>-0.151288</td>\n",
              "      <td>-0.055421</td>\n",
              "      <td>-0.028700</td>\n",
              "      <td>0.322586</td>\n",
              "      <td>0.197591</td>\n",
              "      <td>0.097427</td>\n",
              "      <td>0.141152</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.265539</td>\n",
              "      <td>0.178179</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>0.419388</td>\n",
              "      <td>0.485513</td>\n",
              "      <td>0.311476</td>\n",
              "      <td>0.252392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384510</td>\n",
              "      <td>-0.010529</td>\n",
              "      <td>0.119058</td>\n",
              "      <td>-0.078039</td>\n",
              "      <td>-0.113407</td>\n",
              "      <td>-0.148094</td>\n",
              "      <td>-0.258990</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>0.387888</td>\n",
              "      <td>-0.143700</td>\n",
              "      <td>-0.021616</td>\n",
              "      <td>-0.141920</td>\n",
              "      <td>-0.128254</td>\n",
              "      <td>0.189747</td>\n",
              "      <td>-0.066199</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>0.360275</td>\n",
              "      <td>-0.723010</td>\n",
              "      <td>0.422365</td>\n",
              "      <td>-0.061265</td>\n",
              "      <td>-0.131536</td>\n",
              "      <td>-0.150126</td>\n",
              "      <td>0.009457</td>\n",
              "      <td>-0.218707</td>\n",
              "      <td>-0.077923</td>\n",
              "      <td>0.323542</td>\n",
              "      <td>0.353583</td>\n",
              "      <td>0.331252</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.217525</td>\n",
              "      <td>-0.138142</td>\n",
              "      <td>0.515318</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>0.140498</td>\n",
              "      <td>-0.040132</td>\n",
              "      <td>-0.220662</td>\n",
              "      <td>-0.382914</td>\n",
              "      <td>0.380720</td>\n",
              "      <td>-0.014164</td>\n",
              "      <td>0.303776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2311</th>\n",
              "      <td>0.102415</td>\n",
              "      <td>0.042386</td>\n",
              "      <td>0.310881</td>\n",
              "      <td>-0.172202</td>\n",
              "      <td>0.041934</td>\n",
              "      <td>-0.037599</td>\n",
              "      <td>-0.017747</td>\n",
              "      <td>-0.101974</td>\n",
              "      <td>0.221890</td>\n",
              "      <td>-0.121221</td>\n",
              "      <td>-0.045917</td>\n",
              "      <td>-0.217697</td>\n",
              "      <td>0.043612</td>\n",
              "      <td>-0.419584</td>\n",
              "      <td>0.110066</td>\n",
              "      <td>-0.393416</td>\n",
              "      <td>0.156480</td>\n",
              "      <td>-0.222948</td>\n",
              "      <td>0.380319</td>\n",
              "      <td>-0.092568</td>\n",
              "      <td>-0.166542</td>\n",
              "      <td>0.273399</td>\n",
              "      <td>-0.303653</td>\n",
              "      <td>0.120441</td>\n",
              "      <td>0.100493</td>\n",
              "      <td>-0.402442</td>\n",
              "      <td>0.030782</td>\n",
              "      <td>0.344840</td>\n",
              "      <td>0.001193</td>\n",
              "      <td>0.105918</td>\n",
              "      <td>-0.154641</td>\n",
              "      <td>-0.241585</td>\n",
              "      <td>0.032094</td>\n",
              "      <td>-0.291548</td>\n",
              "      <td>-0.053396</td>\n",
              "      <td>-0.125002</td>\n",
              "      <td>-0.058767</td>\n",
              "      <td>0.282575</td>\n",
              "      <td>-0.307751</td>\n",
              "      <td>0.011007</td>\n",
              "      <td>...</td>\n",
              "      <td>0.309844</td>\n",
              "      <td>-0.104676</td>\n",
              "      <td>-0.128538</td>\n",
              "      <td>0.445901</td>\n",
              "      <td>0.021368</td>\n",
              "      <td>-0.382101</td>\n",
              "      <td>-0.051052</td>\n",
              "      <td>-0.105399</td>\n",
              "      <td>0.208992</td>\n",
              "      <td>0.157963</td>\n",
              "      <td>-0.211057</td>\n",
              "      <td>-0.459729</td>\n",
              "      <td>-0.082860</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>-0.086988</td>\n",
              "      <td>0.292095</td>\n",
              "      <td>0.307081</td>\n",
              "      <td>-0.095683</td>\n",
              "      <td>-0.306939</td>\n",
              "      <td>0.406865</td>\n",
              "      <td>-0.038280</td>\n",
              "      <td>0.121701</td>\n",
              "      <td>-0.117689</td>\n",
              "      <td>-0.274301</td>\n",
              "      <td>0.018526</td>\n",
              "      <td>0.156622</td>\n",
              "      <td>0.061364</td>\n",
              "      <td>0.264608</td>\n",
              "      <td>-0.256757</td>\n",
              "      <td>0.068713</td>\n",
              "      <td>0.340284</td>\n",
              "      <td>0.171523</td>\n",
              "      <td>0.473499</td>\n",
              "      <td>-0.086825</td>\n",
              "      <td>0.559150</td>\n",
              "      <td>-0.581624</td>\n",
              "      <td>0.376166</td>\n",
              "      <td>0.204096</td>\n",
              "      <td>0.127397</td>\n",
              "      <td>0.518637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2312</th>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.100156</td>\n",
              "      <td>-0.181406</td>\n",
              "      <td>0.123134</td>\n",
              "      <td>-0.248711</td>\n",
              "      <td>0.386225</td>\n",
              "      <td>0.071953</td>\n",
              "      <td>0.316884</td>\n",
              "      <td>-0.297754</td>\n",
              "      <td>-0.585618</td>\n",
              "      <td>-0.599487</td>\n",
              "      <td>-0.883622</td>\n",
              "      <td>0.226984</td>\n",
              "      <td>-0.302107</td>\n",
              "      <td>0.742923</td>\n",
              "      <td>-0.127922</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.163219</td>\n",
              "      <td>0.103186</td>\n",
              "      <td>-0.484405</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.024954</td>\n",
              "      <td>0.405841</td>\n",
              "      <td>-0.307482</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.075125</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.205681</td>\n",
              "      <td>-0.225701</td>\n",
              "      <td>0.155992</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>0.079980</td>\n",
              "      <td>-0.199730</td>\n",
              "      <td>0.141558</td>\n",
              "      <td>-0.142644</td>\n",
              "      <td>0.390152</td>\n",
              "      <td>0.426615</td>\n",
              "      <td>0.088414</td>\n",
              "      <td>0.210211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120282</td>\n",
              "      <td>-0.229974</td>\n",
              "      <td>-0.054204</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>-0.093858</td>\n",
              "      <td>-0.182911</td>\n",
              "      <td>-0.011829</td>\n",
              "      <td>-0.233442</td>\n",
              "      <td>0.685782</td>\n",
              "      <td>-0.358191</td>\n",
              "      <td>0.020692</td>\n",
              "      <td>0.152990</td>\n",
              "      <td>0.288014</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>-0.129584</td>\n",
              "      <td>-0.258241</td>\n",
              "      <td>0.386515</td>\n",
              "      <td>-0.658014</td>\n",
              "      <td>0.211520</td>\n",
              "      <td>0.296892</td>\n",
              "      <td>-0.153062</td>\n",
              "      <td>-0.045540</td>\n",
              "      <td>-0.337411</td>\n",
              "      <td>-0.140582</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>0.045885</td>\n",
              "      <td>0.116038</td>\n",
              "      <td>0.095674</td>\n",
              "      <td>-0.101839</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.513150</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.316020</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>-0.380363</td>\n",
              "      <td>-0.108683</td>\n",
              "      <td>-0.100425</td>\n",
              "      <td>-0.040597</td>\n",
              "      <td>0.013379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2313</th>\n",
              "      <td>0.292988</td>\n",
              "      <td>0.007353</td>\n",
              "      <td>-0.141794</td>\n",
              "      <td>-0.217709</td>\n",
              "      <td>0.061340</td>\n",
              "      <td>0.356941</td>\n",
              "      <td>0.128595</td>\n",
              "      <td>-0.399345</td>\n",
              "      <td>-0.079264</td>\n",
              "      <td>-0.041962</td>\n",
              "      <td>-0.098025</td>\n",
              "      <td>-0.324808</td>\n",
              "      <td>-0.056163</td>\n",
              "      <td>0.149594</td>\n",
              "      <td>0.111448</td>\n",
              "      <td>-0.165758</td>\n",
              "      <td>0.249520</td>\n",
              "      <td>0.274554</td>\n",
              "      <td>-0.139133</td>\n",
              "      <td>0.333623</td>\n",
              "      <td>-0.155837</td>\n",
              "      <td>-0.045190</td>\n",
              "      <td>0.285358</td>\n",
              "      <td>-0.003968</td>\n",
              "      <td>-0.303356</td>\n",
              "      <td>-0.190002</td>\n",
              "      <td>-0.266731</td>\n",
              "      <td>-0.428568</td>\n",
              "      <td>-0.096448</td>\n",
              "      <td>0.275077</td>\n",
              "      <td>-0.134497</td>\n",
              "      <td>-0.168020</td>\n",
              "      <td>-0.280440</td>\n",
              "      <td>-0.245803</td>\n",
              "      <td>0.097271</td>\n",
              "      <td>-0.328880</td>\n",
              "      <td>0.022581</td>\n",
              "      <td>0.364288</td>\n",
              "      <td>0.049610</td>\n",
              "      <td>-0.399424</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099421</td>\n",
              "      <td>-0.262445</td>\n",
              "      <td>-0.107570</td>\n",
              "      <td>-0.016850</td>\n",
              "      <td>-0.126997</td>\n",
              "      <td>0.310287</td>\n",
              "      <td>0.147301</td>\n",
              "      <td>-0.402322</td>\n",
              "      <td>-0.075155</td>\n",
              "      <td>-0.019988</td>\n",
              "      <td>-0.218327</td>\n",
              "      <td>0.175955</td>\n",
              "      <td>-0.169838</td>\n",
              "      <td>-0.140395</td>\n",
              "      <td>0.015053</td>\n",
              "      <td>0.103077</td>\n",
              "      <td>0.181871</td>\n",
              "      <td>0.007587</td>\n",
              "      <td>-0.198375</td>\n",
              "      <td>0.177774</td>\n",
              "      <td>-0.052815</td>\n",
              "      <td>-0.007001</td>\n",
              "      <td>0.203554</td>\n",
              "      <td>0.026453</td>\n",
              "      <td>-0.423742</td>\n",
              "      <td>-0.350420</td>\n",
              "      <td>0.132284</td>\n",
              "      <td>0.103796</td>\n",
              "      <td>0.007285</td>\n",
              "      <td>0.278350</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>-0.169350</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>-0.181834</td>\n",
              "      <td>-0.238829</td>\n",
              "      <td>-0.275099</td>\n",
              "      <td>0.104271</td>\n",
              "      <td>-0.520282</td>\n",
              "      <td>-0.120962</td>\n",
              "      <td>-0.147879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2314</th>\n",
              "      <td>-0.370119</td>\n",
              "      <td>0.031962</td>\n",
              "      <td>-0.109865</td>\n",
              "      <td>0.297458</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0.209004</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.354349</td>\n",
              "      <td>-0.222928</td>\n",
              "      <td>-0.514638</td>\n",
              "      <td>-0.079176</td>\n",
              "      <td>-0.609773</td>\n",
              "      <td>0.321759</td>\n",
              "      <td>0.013534</td>\n",
              "      <td>0.503136</td>\n",
              "      <td>0.060016</td>\n",
              "      <td>0.346563</td>\n",
              "      <td>-0.142549</td>\n",
              "      <td>0.012023</td>\n",
              "      <td>-0.335389</td>\n",
              "      <td>0.003859</td>\n",
              "      <td>0.402099</td>\n",
              "      <td>0.549898</td>\n",
              "      <td>-0.341390</td>\n",
              "      <td>0.185277</td>\n",
              "      <td>-0.151288</td>\n",
              "      <td>-0.055421</td>\n",
              "      <td>-0.028700</td>\n",
              "      <td>0.322586</td>\n",
              "      <td>0.197591</td>\n",
              "      <td>0.097427</td>\n",
              "      <td>0.141152</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.265539</td>\n",
              "      <td>0.178179</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>0.419388</td>\n",
              "      <td>0.485513</td>\n",
              "      <td>0.311476</td>\n",
              "      <td>0.252392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384510</td>\n",
              "      <td>-0.010529</td>\n",
              "      <td>0.119058</td>\n",
              "      <td>-0.078039</td>\n",
              "      <td>-0.113407</td>\n",
              "      <td>-0.148094</td>\n",
              "      <td>-0.258990</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>0.387888</td>\n",
              "      <td>-0.143700</td>\n",
              "      <td>-0.021616</td>\n",
              "      <td>-0.141920</td>\n",
              "      <td>-0.128254</td>\n",
              "      <td>0.189747</td>\n",
              "      <td>-0.066199</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>0.360275</td>\n",
              "      <td>-0.723010</td>\n",
              "      <td>0.422365</td>\n",
              "      <td>-0.061265</td>\n",
              "      <td>-0.131536</td>\n",
              "      <td>-0.150126</td>\n",
              "      <td>0.009457</td>\n",
              "      <td>-0.218707</td>\n",
              "      <td>-0.077923</td>\n",
              "      <td>0.323542</td>\n",
              "      <td>0.353583</td>\n",
              "      <td>0.331252</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.217525</td>\n",
              "      <td>-0.138142</td>\n",
              "      <td>0.515318</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>0.140498</td>\n",
              "      <td>-0.040132</td>\n",
              "      <td>-0.220662</td>\n",
              "      <td>-0.382914</td>\n",
              "      <td>0.380720</td>\n",
              "      <td>-0.014164</td>\n",
              "      <td>0.303776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2315</th>\n",
              "      <td>-0.334936</td>\n",
              "      <td>-0.237400</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>0.307774</td>\n",
              "      <td>0.552991</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>-0.128793</td>\n",
              "      <td>0.184903</td>\n",
              "      <td>-0.300067</td>\n",
              "      <td>-0.160469</td>\n",
              "      <td>-0.137007</td>\n",
              "      <td>-0.380960</td>\n",
              "      <td>0.067295</td>\n",
              "      <td>-0.350619</td>\n",
              "      <td>0.319733</td>\n",
              "      <td>0.312155</td>\n",
              "      <td>0.234408</td>\n",
              "      <td>0.456366</td>\n",
              "      <td>0.103505</td>\n",
              "      <td>-0.163476</td>\n",
              "      <td>-0.112946</td>\n",
              "      <td>0.273597</td>\n",
              "      <td>0.274887</td>\n",
              "      <td>-0.008497</td>\n",
              "      <td>-0.404606</td>\n",
              "      <td>-0.219477</td>\n",
              "      <td>0.200002</td>\n",
              "      <td>0.470362</td>\n",
              "      <td>0.067487</td>\n",
              "      <td>-0.013588</td>\n",
              "      <td>-0.049962</td>\n",
              "      <td>-0.066518</td>\n",
              "      <td>-0.108149</td>\n",
              "      <td>-0.090050</td>\n",
              "      <td>0.477854</td>\n",
              "      <td>-0.432016</td>\n",
              "      <td>0.279654</td>\n",
              "      <td>0.297045</td>\n",
              "      <td>-0.167063</td>\n",
              "      <td>0.094208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>-0.071417</td>\n",
              "      <td>-0.103228</td>\n",
              "      <td>-0.008193</td>\n",
              "      <td>-0.482496</td>\n",
              "      <td>-0.107093</td>\n",
              "      <td>0.380227</td>\n",
              "      <td>-0.081455</td>\n",
              "      <td>0.418951</td>\n",
              "      <td>-0.213351</td>\n",
              "      <td>-0.182586</td>\n",
              "      <td>-0.167677</td>\n",
              "      <td>0.183418</td>\n",
              "      <td>-0.053785</td>\n",
              "      <td>0.092943</td>\n",
              "      <td>-0.330301</td>\n",
              "      <td>-0.024515</td>\n",
              "      <td>-0.559753</td>\n",
              "      <td>0.022932</td>\n",
              "      <td>0.180525</td>\n",
              "      <td>0.188712</td>\n",
              "      <td>0.027331</td>\n",
              "      <td>-0.235138</td>\n",
              "      <td>-0.330035</td>\n",
              "      <td>0.122914</td>\n",
              "      <td>0.102582</td>\n",
              "      <td>-0.103969</td>\n",
              "      <td>-0.070550</td>\n",
              "      <td>-0.079660</td>\n",
              "      <td>0.035513</td>\n",
              "      <td>-0.149414</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>-0.103845</td>\n",
              "      <td>0.242430</td>\n",
              "      <td>0.017625</td>\n",
              "      <td>-0.328206</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.093238</td>\n",
              "      <td>0.037537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2316</th>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.100156</td>\n",
              "      <td>-0.181406</td>\n",
              "      <td>0.123134</td>\n",
              "      <td>-0.248711</td>\n",
              "      <td>0.386225</td>\n",
              "      <td>0.071953</td>\n",
              "      <td>0.316884</td>\n",
              "      <td>-0.297754</td>\n",
              "      <td>-0.585618</td>\n",
              "      <td>-0.599487</td>\n",
              "      <td>-0.883622</td>\n",
              "      <td>0.226984</td>\n",
              "      <td>-0.302107</td>\n",
              "      <td>0.742923</td>\n",
              "      <td>-0.127922</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.163219</td>\n",
              "      <td>0.103186</td>\n",
              "      <td>-0.484405</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.024954</td>\n",
              "      <td>0.405841</td>\n",
              "      <td>-0.307482</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.075125</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.205681</td>\n",
              "      <td>-0.225701</td>\n",
              "      <td>0.155992</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>0.079980</td>\n",
              "      <td>-0.199730</td>\n",
              "      <td>0.141558</td>\n",
              "      <td>-0.142644</td>\n",
              "      <td>0.390152</td>\n",
              "      <td>0.426615</td>\n",
              "      <td>0.088414</td>\n",
              "      <td>0.210211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120282</td>\n",
              "      <td>-0.229974</td>\n",
              "      <td>-0.054204</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>-0.093858</td>\n",
              "      <td>-0.182911</td>\n",
              "      <td>-0.011829</td>\n",
              "      <td>-0.233442</td>\n",
              "      <td>0.685782</td>\n",
              "      <td>-0.358191</td>\n",
              "      <td>0.020692</td>\n",
              "      <td>0.152990</td>\n",
              "      <td>0.288014</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>-0.129584</td>\n",
              "      <td>-0.258241</td>\n",
              "      <td>0.386515</td>\n",
              "      <td>-0.658014</td>\n",
              "      <td>0.211520</td>\n",
              "      <td>0.296892</td>\n",
              "      <td>-0.153062</td>\n",
              "      <td>-0.045540</td>\n",
              "      <td>-0.337411</td>\n",
              "      <td>-0.140582</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>0.045885</td>\n",
              "      <td>0.116038</td>\n",
              "      <td>0.095674</td>\n",
              "      <td>-0.101839</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.513150</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.316020</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>-0.380363</td>\n",
              "      <td>-0.108683</td>\n",
              "      <td>-0.100425</td>\n",
              "      <td>-0.040597</td>\n",
              "      <td>0.013379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2317</th>\n",
              "      <td>0.292988</td>\n",
              "      <td>0.007353</td>\n",
              "      <td>-0.141794</td>\n",
              "      <td>-0.217709</td>\n",
              "      <td>0.061340</td>\n",
              "      <td>0.356941</td>\n",
              "      <td>0.128595</td>\n",
              "      <td>-0.399345</td>\n",
              "      <td>-0.079264</td>\n",
              "      <td>-0.041962</td>\n",
              "      <td>-0.098025</td>\n",
              "      <td>-0.324808</td>\n",
              "      <td>-0.056163</td>\n",
              "      <td>0.149594</td>\n",
              "      <td>0.111448</td>\n",
              "      <td>-0.165758</td>\n",
              "      <td>0.249520</td>\n",
              "      <td>0.274554</td>\n",
              "      <td>-0.139133</td>\n",
              "      <td>0.333623</td>\n",
              "      <td>-0.155837</td>\n",
              "      <td>-0.045190</td>\n",
              "      <td>0.285358</td>\n",
              "      <td>-0.003968</td>\n",
              "      <td>-0.303356</td>\n",
              "      <td>-0.190002</td>\n",
              "      <td>-0.266731</td>\n",
              "      <td>-0.428568</td>\n",
              "      <td>-0.096448</td>\n",
              "      <td>0.275077</td>\n",
              "      <td>-0.134497</td>\n",
              "      <td>-0.168020</td>\n",
              "      <td>-0.280440</td>\n",
              "      <td>-0.245803</td>\n",
              "      <td>0.097271</td>\n",
              "      <td>-0.328880</td>\n",
              "      <td>0.022581</td>\n",
              "      <td>0.364288</td>\n",
              "      <td>0.049610</td>\n",
              "      <td>-0.399424</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099421</td>\n",
              "      <td>-0.262445</td>\n",
              "      <td>-0.107570</td>\n",
              "      <td>-0.016850</td>\n",
              "      <td>-0.126997</td>\n",
              "      <td>0.310287</td>\n",
              "      <td>0.147301</td>\n",
              "      <td>-0.402322</td>\n",
              "      <td>-0.075155</td>\n",
              "      <td>-0.019988</td>\n",
              "      <td>-0.218327</td>\n",
              "      <td>0.175955</td>\n",
              "      <td>-0.169838</td>\n",
              "      <td>-0.140395</td>\n",
              "      <td>0.015053</td>\n",
              "      <td>0.103077</td>\n",
              "      <td>0.181871</td>\n",
              "      <td>0.007587</td>\n",
              "      <td>-0.198375</td>\n",
              "      <td>0.177774</td>\n",
              "      <td>-0.052815</td>\n",
              "      <td>-0.007001</td>\n",
              "      <td>0.203554</td>\n",
              "      <td>0.026453</td>\n",
              "      <td>-0.423742</td>\n",
              "      <td>-0.350420</td>\n",
              "      <td>0.132284</td>\n",
              "      <td>0.103796</td>\n",
              "      <td>0.007285</td>\n",
              "      <td>0.278350</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>-0.169350</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>-0.181834</td>\n",
              "      <td>-0.238829</td>\n",
              "      <td>-0.275099</td>\n",
              "      <td>0.104271</td>\n",
              "      <td>-0.520282</td>\n",
              "      <td>-0.120962</td>\n",
              "      <td>-0.147879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2318</th>\n",
              "      <td>-0.370119</td>\n",
              "      <td>0.031962</td>\n",
              "      <td>-0.109865</td>\n",
              "      <td>0.297458</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0.209004</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.354349</td>\n",
              "      <td>-0.222928</td>\n",
              "      <td>-0.514638</td>\n",
              "      <td>-0.079176</td>\n",
              "      <td>-0.609773</td>\n",
              "      <td>0.321759</td>\n",
              "      <td>0.013534</td>\n",
              "      <td>0.503136</td>\n",
              "      <td>0.060016</td>\n",
              "      <td>0.346563</td>\n",
              "      <td>-0.142549</td>\n",
              "      <td>0.012023</td>\n",
              "      <td>-0.335389</td>\n",
              "      <td>0.003859</td>\n",
              "      <td>0.402099</td>\n",
              "      <td>0.549898</td>\n",
              "      <td>-0.341390</td>\n",
              "      <td>0.185277</td>\n",
              "      <td>-0.151288</td>\n",
              "      <td>-0.055421</td>\n",
              "      <td>-0.028700</td>\n",
              "      <td>0.322586</td>\n",
              "      <td>0.197591</td>\n",
              "      <td>0.097427</td>\n",
              "      <td>0.141152</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.265539</td>\n",
              "      <td>0.178179</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>0.419388</td>\n",
              "      <td>0.485513</td>\n",
              "      <td>0.311476</td>\n",
              "      <td>0.252392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384510</td>\n",
              "      <td>-0.010529</td>\n",
              "      <td>0.119058</td>\n",
              "      <td>-0.078039</td>\n",
              "      <td>-0.113407</td>\n",
              "      <td>-0.148094</td>\n",
              "      <td>-0.258990</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>0.387888</td>\n",
              "      <td>-0.143700</td>\n",
              "      <td>-0.021616</td>\n",
              "      <td>-0.141920</td>\n",
              "      <td>-0.128254</td>\n",
              "      <td>0.189747</td>\n",
              "      <td>-0.066199</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>0.360275</td>\n",
              "      <td>-0.723010</td>\n",
              "      <td>0.422365</td>\n",
              "      <td>-0.061265</td>\n",
              "      <td>-0.131536</td>\n",
              "      <td>-0.150126</td>\n",
              "      <td>0.009457</td>\n",
              "      <td>-0.218707</td>\n",
              "      <td>-0.077923</td>\n",
              "      <td>0.323542</td>\n",
              "      <td>0.353583</td>\n",
              "      <td>0.331252</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.217525</td>\n",
              "      <td>-0.138142</td>\n",
              "      <td>0.515318</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>0.140498</td>\n",
              "      <td>-0.040132</td>\n",
              "      <td>-0.220662</td>\n",
              "      <td>-0.382914</td>\n",
              "      <td>0.380720</td>\n",
              "      <td>-0.014164</td>\n",
              "      <td>0.303776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2319</th>\n",
              "      <td>-0.334936</td>\n",
              "      <td>-0.237400</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>0.307774</td>\n",
              "      <td>0.552991</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>-0.128793</td>\n",
              "      <td>0.184903</td>\n",
              "      <td>-0.300067</td>\n",
              "      <td>-0.160469</td>\n",
              "      <td>-0.137007</td>\n",
              "      <td>-0.380960</td>\n",
              "      <td>0.067295</td>\n",
              "      <td>-0.350619</td>\n",
              "      <td>0.319733</td>\n",
              "      <td>0.312155</td>\n",
              "      <td>0.234408</td>\n",
              "      <td>0.456366</td>\n",
              "      <td>0.103505</td>\n",
              "      <td>-0.163476</td>\n",
              "      <td>-0.112946</td>\n",
              "      <td>0.273597</td>\n",
              "      <td>0.274887</td>\n",
              "      <td>-0.008497</td>\n",
              "      <td>-0.404606</td>\n",
              "      <td>-0.219477</td>\n",
              "      <td>0.200002</td>\n",
              "      <td>0.470362</td>\n",
              "      <td>0.067487</td>\n",
              "      <td>-0.013588</td>\n",
              "      <td>-0.049962</td>\n",
              "      <td>-0.066518</td>\n",
              "      <td>-0.108149</td>\n",
              "      <td>-0.090050</td>\n",
              "      <td>0.477854</td>\n",
              "      <td>-0.432016</td>\n",
              "      <td>0.279654</td>\n",
              "      <td>0.297045</td>\n",
              "      <td>-0.167063</td>\n",
              "      <td>0.094208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>-0.071417</td>\n",
              "      <td>-0.103228</td>\n",
              "      <td>-0.008193</td>\n",
              "      <td>-0.482496</td>\n",
              "      <td>-0.107093</td>\n",
              "      <td>0.380227</td>\n",
              "      <td>-0.081455</td>\n",
              "      <td>0.418951</td>\n",
              "      <td>-0.213351</td>\n",
              "      <td>-0.182586</td>\n",
              "      <td>-0.167677</td>\n",
              "      <td>0.183418</td>\n",
              "      <td>-0.053785</td>\n",
              "      <td>0.092943</td>\n",
              "      <td>-0.330301</td>\n",
              "      <td>-0.024515</td>\n",
              "      <td>-0.559753</td>\n",
              "      <td>0.022932</td>\n",
              "      <td>0.180525</td>\n",
              "      <td>0.188712</td>\n",
              "      <td>0.027331</td>\n",
              "      <td>-0.235138</td>\n",
              "      <td>-0.330035</td>\n",
              "      <td>0.122914</td>\n",
              "      <td>0.102582</td>\n",
              "      <td>-0.103969</td>\n",
              "      <td>-0.070550</td>\n",
              "      <td>-0.079660</td>\n",
              "      <td>0.035513</td>\n",
              "      <td>-0.149414</td>\n",
              "      <td>0.560538</td>\n",
              "      <td>-0.103845</td>\n",
              "      <td>0.242430</td>\n",
              "      <td>0.017625</td>\n",
              "      <td>-0.328206</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.093238</td>\n",
              "      <td>0.037537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2320</th>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.100156</td>\n",
              "      <td>-0.181406</td>\n",
              "      <td>0.123134</td>\n",
              "      <td>-0.248711</td>\n",
              "      <td>0.386225</td>\n",
              "      <td>0.071953</td>\n",
              "      <td>0.316884</td>\n",
              "      <td>-0.297754</td>\n",
              "      <td>-0.585618</td>\n",
              "      <td>-0.599487</td>\n",
              "      <td>-0.883622</td>\n",
              "      <td>0.226984</td>\n",
              "      <td>-0.302107</td>\n",
              "      <td>0.742923</td>\n",
              "      <td>-0.127922</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.163219</td>\n",
              "      <td>0.103186</td>\n",
              "      <td>-0.484405</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.024954</td>\n",
              "      <td>0.405841</td>\n",
              "      <td>-0.307482</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.075125</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.205681</td>\n",
              "      <td>-0.225701</td>\n",
              "      <td>0.155992</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>0.079980</td>\n",
              "      <td>-0.199730</td>\n",
              "      <td>0.141558</td>\n",
              "      <td>-0.142644</td>\n",
              "      <td>0.390152</td>\n",
              "      <td>0.426615</td>\n",
              "      <td>0.088414</td>\n",
              "      <td>0.210211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120282</td>\n",
              "      <td>-0.229974</td>\n",
              "      <td>-0.054204</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>-0.093858</td>\n",
              "      <td>-0.182911</td>\n",
              "      <td>-0.011829</td>\n",
              "      <td>-0.233442</td>\n",
              "      <td>0.685782</td>\n",
              "      <td>-0.358191</td>\n",
              "      <td>0.020692</td>\n",
              "      <td>0.152990</td>\n",
              "      <td>0.288014</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>-0.129584</td>\n",
              "      <td>-0.258241</td>\n",
              "      <td>0.386515</td>\n",
              "      <td>-0.658014</td>\n",
              "      <td>0.211520</td>\n",
              "      <td>0.296892</td>\n",
              "      <td>-0.153062</td>\n",
              "      <td>-0.045540</td>\n",
              "      <td>-0.337411</td>\n",
              "      <td>-0.140582</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>0.045885</td>\n",
              "      <td>0.116038</td>\n",
              "      <td>0.095674</td>\n",
              "      <td>-0.101839</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.513150</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.316020</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>-0.380363</td>\n",
              "      <td>-0.108683</td>\n",
              "      <td>-0.100425</td>\n",
              "      <td>-0.040597</td>\n",
              "      <td>0.013379</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2321 rows  1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Dim1      Dim2      Dim3  ...    Dim998    Dim999   Dim1000\n",
              "0     0.079781 -0.025519 -0.243857  ... -0.091680  0.157746  0.151333\n",
              "1    -0.183910 -0.061212  0.129800  ...  0.234740  0.307678  0.253161\n",
              "2    -0.271267  0.124715  0.024563  ... -0.373614  0.108963  0.042342\n",
              "3    -0.334936 -0.237400 -0.167446  ...  0.019417  0.093238  0.037537\n",
              "4    -0.127603  0.146247 -0.090662  ... -0.870611  0.122402 -0.205108\n",
              "5     0.034763 -0.161011  0.140570  ... -0.027659  0.158659  0.315700\n",
              "6     0.110494  0.263056  0.020745  ... -0.034440  0.027490 -0.012786\n",
              "7    -0.268107  0.011173  0.048714  ... -0.718208  0.211355 -0.037011\n",
              "8     0.151989  0.100551  0.126916  ... -0.323329  0.060081 -0.062461\n",
              "9     0.174452 -0.107560  0.257954  ...  0.088473 -0.113517 -0.400128\n",
              "10    0.091684  0.030425  0.088823  ... -0.142532  0.015970 -0.062013\n",
              "11    0.034763 -0.161011  0.140570  ... -0.027659  0.158659  0.315700\n",
              "12    0.131177  0.011852  0.343895  ... -0.018110 -0.223994  0.098030\n",
              "13    0.109272  0.282584 -0.408413  ... -0.062762  0.424503  0.235132\n",
              "14    0.079781 -0.025519 -0.243857  ... -0.091680  0.157746  0.151333\n",
              "15   -0.183910 -0.061212  0.129800  ...  0.234740  0.307678  0.253161\n",
              "16    0.038220 -0.046820  0.220528  ... -0.108797  0.307164  0.134890\n",
              "17   -0.280344 -0.029469 -0.116329  ...  0.176493  0.130165 -0.017426\n",
              "18    0.038220 -0.046820  0.220528  ... -0.108797  0.307164  0.134890\n",
              "19    0.109272  0.282584 -0.408413  ... -0.062762  0.424503  0.235132\n",
              "20   -0.024214 -0.118902  0.111218  ...  0.232870  0.383704  0.589763\n",
              "21   -0.145896  0.208463 -0.022059  ... -0.054786 -0.035667  0.016383\n",
              "22    0.071846  0.259861  0.375056  ...  0.361547  0.179145  0.253851\n",
              "23    0.221306  0.258792  0.032510  ...  0.472145 -0.243705 -0.244137\n",
              "24    0.221306  0.258792  0.032510  ...  0.472145 -0.243705 -0.244137\n",
              "25   -0.047195 -0.020316  0.065144  ...  0.140653  0.142219  0.289036\n",
              "26    0.159736 -0.249732  0.032930  ... -0.100671  0.060253 -0.044321\n",
              "27    0.110808  0.041104 -0.143596  ...  0.091035 -0.031570 -0.154814\n",
              "28   -0.068173  0.144498 -0.127387  ... -0.004746  0.226838 -0.082503\n",
              "29    0.079781 -0.025519 -0.243857  ... -0.091680  0.157746  0.151333\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "2291 -0.334936 -0.237400 -0.167446  ...  0.019417  0.093238  0.037537\n",
              "2292 -0.282897 -0.100156 -0.181406  ... -0.100425 -0.040597  0.013379\n",
              "2293  0.292988  0.007353 -0.141794  ... -0.520282 -0.120962 -0.147879\n",
              "2294 -0.370119  0.031962 -0.109865  ...  0.380720 -0.014164  0.303776\n",
              "2295 -0.334936 -0.237400 -0.167446  ...  0.019417  0.093238  0.037537\n",
              "2296 -0.282897 -0.100156 -0.181406  ... -0.100425 -0.040597  0.013379\n",
              "2297  0.292988  0.007353 -0.141794  ... -0.520282 -0.120962 -0.147879\n",
              "2298 -0.370119  0.031962 -0.109865  ...  0.380720 -0.014164  0.303776\n",
              "2299 -0.334936 -0.237400 -0.167446  ...  0.019417  0.093238  0.037537\n",
              "2300 -0.282897 -0.100156 -0.181406  ... -0.100425 -0.040597  0.013379\n",
              "2301  0.292988  0.007353 -0.141794  ... -0.520282 -0.120962 -0.147879\n",
              "2302 -0.370119  0.031962 -0.109865  ...  0.380720 -0.014164  0.303776\n",
              "2303 -0.334936 -0.237400 -0.167446  ...  0.019417  0.093238  0.037537\n",
              "2304 -0.282897 -0.100156 -0.181406  ... -0.100425 -0.040597  0.013379\n",
              "2305 -0.035378  0.171331  0.132767  ...  0.143810 -0.022290  0.427308\n",
              "2306 -0.370119  0.031962 -0.109865  ...  0.380720 -0.014164  0.303776\n",
              "2307  0.102415  0.042386  0.310881  ...  0.204096  0.127397  0.518637\n",
              "2308 -0.282897 -0.100156 -0.181406  ... -0.100425 -0.040597  0.013379\n",
              "2309 -0.035378  0.171331  0.132767  ...  0.143810 -0.022290  0.427308\n",
              "2310 -0.370119  0.031962 -0.109865  ...  0.380720 -0.014164  0.303776\n",
              "2311  0.102415  0.042386  0.310881  ...  0.204096  0.127397  0.518637\n",
              "2312 -0.282897 -0.100156 -0.181406  ... -0.100425 -0.040597  0.013379\n",
              "2313  0.292988  0.007353 -0.141794  ... -0.520282 -0.120962 -0.147879\n",
              "2314 -0.370119  0.031962 -0.109865  ...  0.380720 -0.014164  0.303776\n",
              "2315 -0.334936 -0.237400 -0.167446  ...  0.019417  0.093238  0.037537\n",
              "2316 -0.282897 -0.100156 -0.181406  ... -0.100425 -0.040597  0.013379\n",
              "2317  0.292988  0.007353 -0.141794  ... -0.520282 -0.120962 -0.147879\n",
              "2318 -0.370119  0.031962 -0.109865  ...  0.380720 -0.014164  0.303776\n",
              "2319 -0.334936 -0.237400 -0.167446  ...  0.019417  0.093238  0.037537\n",
              "2320 -0.282897 -0.100156 -0.181406  ... -0.100425 -0.040597  0.013379\n",
              "\n",
              "[2321 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wX4Fh4uUBTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
        "\n",
        "\n",
        "GBmodel = lgb.LGBMClassifier(boosting_type='gbdt', objective='binary', num_iterations=5000,\n",
        "                            learning_rate=0.001, num_leaves=50, max_depth=-1, random_state=42,\n",
        "                            min_data_in_leaf=10, class_weight='balanced', verbose=0,\n",
        "                            lambda_l1=0.1, lambda_l2=0.01)\n",
        "\n",
        "def make_train_test(x, y, model):\n",
        "  dataframe = pd.concat([x, y], axis=1)\n",
        "  skf = StratifiedKFold(n_splits=4, random_state=42)\n",
        "  train_x, test_x, train_y, test_y = train_test_split(dataframe.iloc[:,0:x.shape[1]], \n",
        "                                                      dataframe.iloc[:,-(y.shape[1]):], \n",
        "                                                      test_size=0.2, shuffle=True, random_state=42,\n",
        "                                                      stratify=dataframe.iloc[:,-(y.shape[1]):])\n",
        "  \n",
        "  performance = []\n",
        "  feature_importance = []\n",
        "  predicted_prob = []\n",
        "  \n",
        "  for i in range(y.shape[1]):\n",
        "    for train_index, test_index in skf.split(train_x, train_y.iloc[:,i]):\n",
        "      X_train, X_val = train_x.iloc[train_index], train_x.iloc[test_index]\n",
        "      Y_train, Y_val = train_y.iloc[train_index, i], train_y.iloc[test_index, i]\n",
        "\n",
        "      m = model.fit(X_train, Y_train, eval_metric=['binary_error', 'binary_logloss'],\n",
        "                         eval_set=[(X_val, Y_val)], verbose=0)\n",
        "\n",
        "    pred = m.predict(test_x)\n",
        "    pred_prob = m.predict_proba(test_x)\n",
        "\n",
        "    performance.append(\"balanced_accuracy_score : \" + str(balanced_accuracy_score(test_y.iloc[:,i], pred)))\n",
        "    performance.append(\"cohen_kappa_score : \" + str(cohen_kappa_score(test_y.iloc[:,i], pred, weights='quadratic')))\n",
        "    performance.append(classification_report(test_y.iloc[:,i], pred))\n",
        "    performance.append(confusion_matrix(test_y.iloc[:,i], pred))\n",
        "    performance.append(\"roc_auc_score : \" + str(roc_auc_score(pd.get_dummies(test_y.iloc[:,i]), pred_prob)))\n",
        "    performance.append(\"brier_score_loss : \" + str(brier_score_loss(test_y.iloc[:,i], pred_prob[:,1])))\n",
        "\n",
        "    feature_importance.append(pd.DataFrame(sorted(zip(m.feature_importances_, train_x.columns)), \n",
        "                                           columns=['Value','Feature']))\n",
        "\n",
        "    predicted_prob.append(pred_prob)\n",
        "  \n",
        "  return performance, feature_importance, predicted_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8IeB8qWVnCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keyword_pf, keyword_imp, keyword_prob = make_train_test(word_vec_df, vocab_df[['Critical Word Indicator']], GBmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSTVqgNl1CJs",
        "colab_type": "code",
        "outputId": "bf2ed163-8fe6-4b44-d7e1-01509a42eb48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "for p in range(len(keyword_pf)):\n",
        "  print(keyword_pf[p])\n",
        "  print('')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "balanced_accuracy_score : 0.9204169708421008\n",
            "\n",
            "cohen_kappa_score : 0.8361749602314583\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89       146\n",
            "           1       0.95      0.94      0.95       319\n",
            "\n",
            "    accuracy                           0.93       465\n",
            "   macro avg       0.92      0.92      0.92       465\n",
            "weighted avg       0.93      0.93      0.93       465\n",
            "\n",
            "\n",
            "[[131  15]\n",
            " [ 18 301]]\n",
            "\n",
            "roc_auc_score : 0.9762206381242753\n",
            "\n",
            "brier_score_loss : 0.05620281118875214\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HwXT7PDIuxR",
        "colab_type": "text"
      },
      "source": [
        "### Solving the abbreviation problem searching its reference entities by self-defined function:\n",
        "\n",
        "The word2vec model using cosine similarity as demonstrated above could not guanrantee a fully accurate matching to the reference words in full-form. I had to design a calculating function to ensure it was corresponding to the right names of factory. Beforehand, the abbreviation tokens were extracted and populated into lists, with their indices in the dataframe for identification.\n",
        "\n",
        "Jaccard similarity was intuitively working in this abbreviation referencing context, because it measures the number of elements co-occurred in both tokens. For counting the number of unique tokens, the abbreviation token would be set as target, because this could eliminate the effect of the lengths of referred factory names. Given 2 names have been found some letter from the abbreviation token, longer name tends to have greater number of union items and hence diminishing its jaccard similarity score even though it may be the correct reference name.\n",
        "\n",
        "<img src='https://i.ytimg.com/vi/Ah_4xqvS1WU/maxresdefault.jpg' width=\"400\"/>\n",
        "\n",
        "Yet, another problem would appear if the full form of the referred words contains some repeated letters of the short form, those words would tend to be scoring higher. Therefore, I added bonus points to the jaccard score if the sequence of the matched letters appeared in the referred words was exactly the same as the sequence of letters in the abbreviation token.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "banGTqIPkJkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## for conversion of classified abbreviation\n",
        "## extract a list of abbreviations\n",
        "abbr = []\n",
        "abbr_index = []\n",
        "w_name = []\n",
        "w_index = []\n",
        "y_label = []\n",
        "\n",
        "for r in range(len(vocab_df['Token'])):\n",
        "  y_label.append(vocab_df['Abbreviation Token Indicator'][r])\n",
        "y_label = np.array(y_label)\n",
        "\n",
        "n = 0\n",
        "kk = 1\n",
        "for d in range(1, len(vocab_df)):\n",
        "  if vocab_df['Item'][d]!=vocab_df['Item'][d-1]:\n",
        "    kk += 1\n",
        "\n",
        "for d2 in range(kk):\n",
        "  start = 0\n",
        "  while (start == 0) or (vocab_df['Item'][n]==vocab_df['Item'][n-1]):\n",
        "    if y_label[n]==1:\n",
        "      w_name.append(vocab_df['Token'][n])\n",
        "      w_index.append(n)\n",
        "    n += 1\n",
        "    start += 1\n",
        "    if n >= len(vocab_df):\n",
        "      break\n",
        "  \n",
        "  abbr.append(w_name)\n",
        "  abbr_index.append(w_index)\n",
        "  w_name = []\n",
        "  w_index = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g-MjfvzA3vS",
        "colab_type": "code",
        "outputId": "b2540237-af4a-43b4-9964-97b4492da93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(abbr[0:10])\n",
        "print(abbr_index[0:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['jp'], ['kh'], ['fw', 'kh'], [], ['cw', 'mp'], ['cw', 'mp'], ['cw', 'mp'], ['gs', 'gs'], ['wf', 'gm'], ['gs', 'gs']]\n",
            "[[3], [13], [17, 19], [], [31, 36], [40, 45], [49, 54], [58, 65], [68, 69], [73, 80]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul0Rm9_cLqd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## use character-by-character matching and jaccard similarity\n",
        "def get_jacc_score(abbreviation, abbreviation_index, entity_list):\n",
        "  \n",
        "  def jaccard_similarity(abbr_w, ent_w):\n",
        "    ## for characters in entity token; extract all intersected digits from the entity\n",
        "    intersection = [value for value in ent_w if value in abbr_w]\n",
        "    ## extract unique characters from the abbreviation expression; \n",
        "    ## not from the entity token; thus not considering the lengths of the entity strings\n",
        "    union = [value for value in abbr_w if value not in ent_w]\n",
        "    if len(union)==0:\n",
        "        jacc_index_basic = len(intersection) / (len(union) + 1)\n",
        "    else:\n",
        "        jacc_index_basic = len(intersection) / len(union)\n",
        "    \n",
        "    return intersection, jacc_index_basic\n",
        "  \n",
        "  def intersect_sequence_generator(dictionary, intersect_list):                    \n",
        "    intersect_idx = []\n",
        "    for x2 in range(len(intersect_list)):\n",
        "      idx = dictionary.get(intersect_list[x2])  \n",
        "      intersect_idx.append(idx)\n",
        "      \n",
        "    return intersect_idx\n",
        "  \n",
        "  def jaccard_similarity_for_seq(abbr_s, ent_s):\n",
        "    score = 0\n",
        "    if len(ent_s)>0:\n",
        "      for d in range(min(len(abbr_s), len(ent_s))):\n",
        "        if ent_s[d]==abbr_s[d]:\n",
        "          score += 1\n",
        "    ## bonus point for all matches\n",
        "    if score == min(len(abbr_s), len(ent_s)):\n",
        "        score += 1\n",
        "    \n",
        "    return score\n",
        "  \n",
        "  jacc_sim = []\n",
        "  jacc_sim_seq = []\n",
        "  jacc_adjusted = []\n",
        "  vdr_reference = []\n",
        "  \n",
        "  char_list_abbr = []\n",
        "  for ca in abbreviation:\n",
        "    char_list_abbr.append(ca)\n",
        "    \n",
        "  abbr_dict = {i:v for i,v in enumerate(char_list_abbr)}\n",
        "  abbr_dict = {y:x for x,y in abbr_dict.items()}\n",
        "  jacc_abbr_idx = []\n",
        "  for x1 in range(len(abbreviation)):\n",
        "    jacc_abbr_idx.append(abbr_dict.get(abbreviation[x1]))\n",
        "  \n",
        "  if vocab_df['Abbr_Name'][abbreviation_index]==1:\n",
        "    start = 0\n",
        "  elif vocab_df['Abbr_Class'][abbreviation_index]==1:\n",
        "    start = 1\n",
        "\n",
        "  if not (vocab_df['Abbreviation Token Indicator'][abbreviation_index]==0):\n",
        "    for entity in range(start, len(entity_list), 2):\n",
        "      char_list_entity = []\n",
        "      for cb in entity_list[entity]:\n",
        "        char_list_entity.append(cb)\n",
        "      \n",
        "      jacc_entity_matched_idx = []\n",
        "      output_intersect, output_jacc_sim = jaccard_similarity(char_list_abbr, char_list_entity)\n",
        "      output_entity_intersect_idx = intersect_sequence_generator(abbr_dict, output_intersect)\n",
        "      jacc_entity_matched_idx.append(output_entity_intersect_idx)\n",
        "      jacc_sim.append(output_jacc_sim)\n",
        "      vdr_reference.append(entity_list[entity])\n",
        "\n",
        "      jacc_score_seq = jaccard_similarity_for_seq(jacc_abbr_idx, output_entity_intersect_idx)\n",
        "      jacc_sim_seq.append(jacc_score_seq)\n",
        "\n",
        "      jacc_adjusted_score = output_jacc_sim + jacc_score_seq\n",
        "      jacc_adjusted.append(jacc_adjusted_score)\n",
        "  \n",
        "  return abbr_dict, output_intersect, jacc_abbr_idx, jacc_entity_matched_idx, jacc_sim, jacc_sim_seq, jacc_adjusted, vdr_reference"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oINcjX2QeTUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abbr2entity_char2v = []\n",
        "\n",
        "for v in range(kk):\n",
        "  if len(abbr[v]) > 0:\n",
        "    matched_entity_list = []\n",
        "    for abb in range(len(abbr[v])):\n",
        "      abbr_dict, intersection, jacc_abbr_idx, jacc_entity_matched_idx, jacc_sim, jacc_sim_seq, jacc_adjusted, vdr_reference \\\n",
        "          = get_jacc_score(abbr[v][abb], abbr_index[v][abb], combined_text[v]) \n",
        "      max_jacc = max(jacc_adjusted)\n",
        "      arg_max_jacc = jacc_adjusted.index(max(jacc_adjusted))\n",
        "      matched_entity = vdr_reference[arg_max_jacc]\n",
        "      matched_entity_list.append(matched_entity)\n",
        "    abbr2entity_char2v.append(matched_entity_list)\n",
        "  else:\n",
        "    abbr2entity_char2v.append([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wV9D3TUTkN-",
        "colab_type": "code",
        "outputId": "47744345-5dcb-4d0f-8bd1-937a82ade1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## some of matching results\n",
        "print(abbr[0:3])\n",
        "print(abbr2entity_char2v[0:3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['cw', 'mp'], ['lb', 'el'], ['mppl']]\n",
            "[['combine will (indonesia)', 'micro plastics'], ['lucky bell', 'early light'], ['micro plastics']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wokBzX8nFMKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## substitute the abbreviations in the tokenized text\n",
        "vocab_df['Rev_Token'] = vocab_df['Token']\n",
        "for v in range(len(abbr_index)):\n",
        "    for u in range(len(abbr_index[v])):\n",
        "        vocab_df['Rev_Token'][abbr_index[v][u]] = abbr2entity_char2v[v][u]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N64UEoT-cbzR",
        "colab_type": "text"
      },
      "source": [
        "### Learning to decode a sequence with the order of name entities + allocated percentages:\n",
        "\n",
        "The short texts of instruction from production managers were treated as an encoder sequence, and artificially I would like the machine to be able to decode a sequence forcing it to follow an order of:\n",
        "> factory name A, factory class A, percentage A, factory name B, factory class B, percentage B, ...\n",
        "\n",
        "Inferring the percenatge attributed to the right factory purely from the instruction texts was challenging. Seq2Seq has been mainly applied in neural machine translations of different lanaguages. It may not be the best solution here to generate a fixed style of decision-indicating sequences for all kinds of encoded instructions, but as a scope for exploring data science approach to automate the process, it consumes less domain expertise and supervision in advance. \n",
        "\n",
        "The pre-processing steps included creating encoder and decoder texts, loading the tokens in the corpus into a key-index paired dictionary object separately for encoder and decoder, and transfer the string sequences to numerical indices readable to the model.\n",
        "\n",
        "For trainning a seq2seq model, we delay the decoder input sequence by one time step by inserting a tag of \"BOS\" indicating the start of sequence with reference to the decoder output. Meanwhile, a \"EOS\" tag could indicate the end of sequence such that the model will learn to predict a \"EOS\" tag at certain time point, by not repeating sampling from the token pool. To maintain unique shape for the inputting array, maximum length of sequneces in the training samples would serve as a dimension, and all samples with a shorter sequence length than this maximum length would be padded with all zeros until reaching the maximum length. \n",
        "\n",
        "<img src='http://opennmt.net/OpenNMT/img/input_feed.png' width=\"300\" align=\"center\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT9W5jUie8e3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## generate encoder text\n",
        "encoder = []\n",
        "k = 0\n",
        "n = 0\n",
        "for i in range(0, len(tokenized_text)):\n",
        "  k = n\n",
        "  item_keyword = []\n",
        "  while vocab_df['Item'][k]==vocab_df['Item'][k+1]:\n",
        "    if vocab_df['Critical Word Indicator'][k]==1:\n",
        "      item_keyword.append(vocab_df['Rev_Token'][k])\n",
        "    k += 1\n",
        "    n += 1\n",
        "    if k >= len(vocab_df) - 1:\n",
        "      break\n",
        "  if vocab_df['Critical Word Indicator'][k]==1:\n",
        "    item_keyword.append(vocab_df['Rev_Token'][k])\n",
        "  n += 1\n",
        "  for t in combined_text[i]:\n",
        "      item_keyword.append(t)\n",
        "  encoder.append(item_keyword)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbOB0H3xe_kX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## import decoder text (targeted output strings)\n",
        "## we got 2 sets of instruction texts:\n",
        "###  - one for allocation before finishing product development and first delivery\n",
        "###  - one for allocation after finishing product development and first delivery\n",
        "\n",
        "before_exfty = pd.read_excel('keyword_encode_2.xlsx', sheet_name=3)\n",
        "after_exfty = pd.read_excel('keyword_encode_2.xlsx', sheet_name=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hoe4AP7UfC76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## generate decoder target sequence of words\n",
        "def generate_decode_string(df, num_doc):\n",
        "    _item = df['Item']\n",
        "    _name = df['Name']\n",
        "    _class = df['Class']\n",
        "    _percent = df.iloc[:,-1]\n",
        "    decode_list = []\n",
        "    m = 0\n",
        "    n = 0\n",
        "    for g in range(num_doc):\n",
        "        m = n\n",
        "        decode_sublist = []\n",
        "        while _item[m]==_item[m+1]:\n",
        "            vdr_name = _name[m].lower()\n",
        "            vdr_class = _class[m].lower()\n",
        "            percent = _percent[m].lower()\n",
        "            decode_sublist.append(vdr_name)\n",
        "            decode_sublist.append(vdr_class)\n",
        "            decode_sublist.append(percent)\n",
        "            m += 1\n",
        "            n += 1\n",
        "            if m >= len(df) - 1:\n",
        "                break\n",
        "        vdr_name = _name[m].lower()\n",
        "        vdr_class = _class[m].lower()\n",
        "        percent = _percent[m].lower()\n",
        "        decode_sublist.append(vdr_name)\n",
        "        decode_sublist.append(vdr_class)\n",
        "        decode_sublist.append(percent)\n",
        "        n += 1\n",
        "        decode_list.append(decode_sublist)\n",
        "    return decode_list\n",
        "\n",
        "decoder_before_exfty = generate_decode_string(before_exfty, len(encoder))\n",
        "decoder_after_exfty = generate_decode_string(before_exfty, len(encoder))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgPcgbDufF49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## convert encoder & decoder dictionary\n",
        "def process_seq2seq_encoder_input(encoder):\n",
        "    reserved = {'<PAD>': 0, '<UNK>': 1}\n",
        "    enc_list = [w for i in encoder for w in i]\n",
        "    enc_dict = {e:i+2 for i,e in enumerate(set(enc_list))}\n",
        "    enc_dict = {**reserved, **enc_dict}\n",
        "    enc_seq = []\n",
        "    ## reserved key-index for padding sequence length, out-of-dictionary words\n",
        "    for e in range(len(encoder)):\n",
        "      enc_sub_seq = []\n",
        "      for se in encoder[e]:\n",
        "        enc_sub_seq.append(enc_dict.get(se))\n",
        "      enc_seq.append(enc_sub_seq)\n",
        "    return enc_dict, enc_seq\n",
        "    \n",
        "def process_seq2seq_decoder_input(decoder):\n",
        "    reserved = {'<PAD>': 0, '<UNK>': 1, '<BOS>':2, '<EOS>':3}\n",
        "    dec_list = [w for i in decoder for w in i]\n",
        "    dec_dict = {e:i+4 for i,e in enumerate(set(dec_list))}\n",
        "    dec_dict = {**reserved, **dec_dict}\n",
        "    dec_seq= []\n",
        "    ## pad <BOS> and <EOS> at the beginning and ending of decoder inputs as indicator for teacher forcing in 3-D outputs\n",
        "    ## (normally only applied to sentence level tokenization, i.e. multiple phrases in one list element)\n",
        "    for f in range(len(decoder)):\n",
        "      dec_sub_seq = []\n",
        "      dec_sub_seq.append(dec_dict.get('<BOS>'))\n",
        "      for sf in decoder[f]:\n",
        "        dec_sub_seq.append(dec_dict.get(sf))\n",
        "      dec_sub_seq.append(dec_dict.get('<EOS>'))\n",
        "      dec_seq.append(dec_sub_seq)\n",
        "    return dec_dict, dec_seq\n",
        "\n",
        "## create an one-hot encoded vector for each token in positions of the sequence length \n",
        "def process_seq2seq_decoder_y(decoder_text, decoder_dict):\n",
        "  max_length_de = max([len(x) for x in decoder_text])\n",
        "  len_de = len(decoder_dict)\n",
        "  decoder_output_label = np.zeros((len(decoder_text), max_length_de, len_de), dtype=\"float32\")\n",
        "  ## decoder output data would be ahead of decoder input data by one timestep\n",
        "  for i, s1 in enumerate(decoder_text):\n",
        "    for j, s2 in enumerate(s1):\n",
        "      if j > 0:\n",
        "        decoder_output_label[i][j-1][s2] = 1\n",
        "  return decoder_output_label\n",
        "  \n",
        "encoder_dict, encoder_seq = process_seq2seq_encoder_input(encoder)\n",
        "decoder_before_exfty_dict, decoder_before_exfty_seq = process_seq2seq_decoder_input(decoder_before_exfty)\n",
        "decoder_after_exfty_dict, decoder_after_exfty_seq = process_seq2seq_decoder_input(decoder_after_exfty)\n",
        "decoder_before_exfty_seq_y = process_seq2seq_decoder_y(decoder_before_exfty_seq, decoder_before_exfty_dict)\n",
        "decoder_after_exfty_seq_y = process_seq2seq_decoder_y(decoder_after_exfty_seq, decoder_after_exfty_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVMbluJOiTHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "## fill up to max length by zero (padding)\n",
        "def padding(sequences, MAX_LEN):\n",
        "  padded_seq = pad_sequences(sequences, maxlen=MAX_LEN, padding='post')\n",
        "  return padded_seq\n",
        "\n",
        "encoder_seq = padding(encoder_seq, max([len(x) for x in encoder_seq]))\n",
        "decoder_before_exfty_seq = padding(decoder_before_exfty_seq, max([len(x) for x in decoder_before_exfty_seq]))\n",
        "decoder_after_exfty_seq = padding(decoder_after_exfty_seq, max([len(x) for x in decoder_after_exfty_seq]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyl_lKVW0p5o",
        "colab_type": "code",
        "outputId": "b7829a9f-064e-447a-fb39-cd2c0012ecb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "print(encoder_seq[0:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 34  49 122 124  91  54  54  95  49  95 124  95   0   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [129 116  83  25 116  25   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [ 79  83  79 116  83  25 116  25   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [107  35   7  85  85  83 116  83  25 116  25 107  95   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [ 11 110   5 127  12  48  72  11  95 127  25  48  95   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [ 11 110   5 127  12  48  72  11  95 127  25  48  95   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [ 11 110   5 127  12  48  72  11  95 127  25  48  95   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [129  95 102  71  13  37  95  74  37 124  95  62  25   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [ 92  99  79  99  25  92  25   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [129  95 102  71  13  37  95  74  37 131  25 124  95   0   0   0   0   0\n",
            "    0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_uD2vCG0uY2",
        "colab_type": "code",
        "outputId": "da52f712-157a-4148-9ffa-9b3f7e294905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "print(decoder_before_exfty_seq[0:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2 68 76 37 47 76 37 54 76 20  3  0  0  0  0  0  0]\n",
            " [ 2 48 63 20 38 63 62  3  0  0  0  0  0  0  0  0  0]\n",
            " [ 2 48 63 37 38 63 37  3  0  0  0  0  0  0  0  0  0]\n",
            " [ 2 48 63 37 38 63 37 24 76 20  3  0  0  0  0  0  0]\n",
            " [ 2 30 76 18 58 63 32 45 76 25  3  0  0  0  0  0  0]\n",
            " [ 2 30 76 18 58 63 32 45 76 25  3  0  0  0  0  0  0]\n",
            " [ 2 30 76 18 58 63 32 45 76 25  3  0  0  0  0  0  0]\n",
            " [ 2 54 76 20 14 63 62  3  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  8 63 37 69 63 37  3  0  0  0  0  0  0  0  0  0]\n",
            " [ 2 71 63 37 54 76 37  3  0  0  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwJp7w1nwL-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## generate 3-D vectors of encoder inputs and decoder inputs\n",
        "from keras.utils import to_categorical\n",
        "encoder_seq_cat = to_categorical(encoder_seq, num_classes=len(encoder_dict))\n",
        "decoder_before_exfty_seq_cat = to_categorical(decoder_before_exfty_seq, num_classes=len(decoder_before_exfty_dict))\n",
        "decoder_after_exfty_seq_cat = to_categorical(decoder_after_exfty_seq, num_classes=len(decoder_after_exfty_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKxZuW4ACEWh",
        "colab_type": "code",
        "outputId": "fa62bdbe-e735-4c51-e9ff-663b3e53e4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(decoder_before_exfty_seq_y.shape)\n",
        "print(decoder_after_exfty_seq_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(370, 17, 79)\n",
            "(370, 17, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAYY2SSPzBal",
        "colab_type": "code",
        "outputId": "b2ff8b22-b03e-4326-f28a-3cf413a6e505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "print('decoder inputs at time t0')\n",
        "print(decoder_before_exfty_seq_cat[0][0])\n",
        "print('decoder outputs at time t0')\n",
        "print(decoder_before_exfty_seq_y[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decoder inputs at time t0\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n",
            "decoder outputs at time t0\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1EKITSQzZ0H",
        "colab_type": "code",
        "outputId": "59607e3a-b72b-434a-a58d-596329d11900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "print('decoder inputs at time t1')\n",
        "print(decoder_before_exfty_seq_cat[0][1])\n",
        "print('decoder outputs at time t1')\n",
        "print(decoder_before_exfty_seq_y[0][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decoder inputs at time t1\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n",
            "decoder outputs at time t1\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB8yAc9wiGNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import sample, seed\n",
        "from sklearn.utils import resample\n",
        "\n",
        "len_sentence = len(tokenized_text)\n",
        "_index = list(range(0, len_sentence))\n",
        "seed(42)\n",
        "train_idx = sample(range(0, len_sentence), int(len_sentence*0.96))\n",
        "\n",
        "encoder_train = [encoder[re] for re in train_idx]\n",
        "encoder_seq_train = [encoder_seq[re] for re in train_idx]\n",
        "encoder_seq_cat_train = [encoder_seq_cat[re] for re in train_idx]\n",
        "decoder_before_exfty_train = [decoder_before_exfty[re] for re in train_idx]\n",
        "decoder_before_exfty_seq_train = [decoder_before_exfty_seq[re] for re in train_idx]\n",
        "decoder_before_exfty_seq_cat_train = [decoder_before_exfty_seq_cat[re] for re in train_idx]\n",
        "decoder_before_exfty_seq_y_train = [decoder_before_exfty_seq_y[re] for re in train_idx]\n",
        "decoder_after_exfty_train = [decoder_after_exfty[re] for re in train_idx]\n",
        "decoder_after_exfty_seq_train = [decoder_after_exfty_seq[re] for re in train_idx]\n",
        "decoder_after_exfty_seq_cat_train = [decoder_after_exfty_seq_cat[re] for re in train_idx]\n",
        "decoder_after_exfty_seq_y_train = [decoder_after_exfty_seq_y[re] for re in train_idx]\n",
        "\n",
        "encoder_test = [encoder[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "encoder_seq_test = [encoder_seq[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "encoder_seq_cat_test = [encoder_seq_cat[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "decoder_before_exfty_test = [decoder_before_exfty[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "decoder_before_exfty_seq_test = [decoder_before_exfty_seq[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "decoder_before_exfty_seq_cat_test = [decoder_before_exfty_seq_cat[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "decoder_before_exfty_seq_y_test = [decoder_before_exfty_seq_y[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "decoder_after_exfty_test = [decoder_after_exfty[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "decoder_after_exfty_seq_test = [decoder_after_exfty_seq[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "decoder_after_exfty_seq_cat_test = [decoder_after_exfty_seq_cat[re] for re in range(0, len_sentence) if re not in train_idx]\n",
        "decoder_after_exfty_seq_y_test = [decoder_after_exfty_seq_y[re] for re in range(0, len_sentence) if re not in train_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev0fYjk0DdLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_seq_train = np.array(encoder_seq_train)\n",
        "encoder_seq_cat_train = np.array(encoder_seq_cat_train)\n",
        "decoder_before_exfty_seq_train = np.array(decoder_before_exfty_seq_train)\n",
        "decoder_before_exfty_seq_cat_train = np.array(decoder_before_exfty_seq_cat_train)\n",
        "decoder_before_exfty_seq_y_train = np.array(decoder_before_exfty_seq_y_train)\n",
        "decoder_after_exfty_seq_train = np.array(decoder_after_exfty_seq_train)\n",
        "decoder_after_exfty_seq_cat_train = np.array(decoder_after_exfty_seq_cat_train)\n",
        "decoder_after_exfty_seq_y_train = np.array(decoder_after_exfty_seq_y_train)\n",
        "\n",
        "encoder_seq_test = np.array(encoder_seq_test)\n",
        "encoder_seq_cat_test = np.array(encoder_seq_cat_test)\n",
        "decoder_before_exfty_seq_test = np.array(decoder_before_exfty_seq_test)\n",
        "decoder_before_exfty_seq_cat_test = np.array(decoder_before_exfty_seq_cat_test)\n",
        "decoder_before_exfty_seq_y_test = np.array(decoder_before_exfty_seq_y_test)\n",
        "decoder_after_exfty_seq_test = np.array(decoder_after_exfty_seq_test)\n",
        "decoder_after_exfty_seq_cat_test = np.array(decoder_after_exfty_seq_cat_test)\n",
        "decoder_after_exfty_seq_y_test = np.array(decoder_after_exfty_seq_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj1SkGT57UP4",
        "colab_type": "code",
        "outputId": "fec11f89-271c-41b9-f540-3469a3f74d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(encoder_seq_train.shape)\n",
        "print(encoder_seq_cat_train.shape)\n",
        "print(decoder_before_exfty_seq_train.shape)\n",
        "print(decoder_before_exfty_seq_cat_train.shape)\n",
        "print(decoder_after_exfty_seq_train.shape)\n",
        "print(decoder_after_exfty_seq_cat_train.shape)\n",
        "print(decoder_before_exfty_seq_y_train.shape)\n",
        "print(decoder_after_exfty_seq_y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(355, 21)\n",
            "(355, 21, 135)\n",
            "(355, 17)\n",
            "(355, 17, 79)\n",
            "(355, 17)\n",
            "(355, 17, 79)\n",
            "(355, 17, 79)\n",
            "(355, 17, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOUCzF8foTX8",
        "colab_type": "text"
      },
      "source": [
        "### Seq2Seq model settings:\n",
        "\n",
        "Small sample size and bootstrapping:\n",
        "> My dataset was small containing only 370 instruction short texts, and upon splitting, 96% (355) would be used for training. I created 10 bootstrap samples here to repeat the training batches validating on 15 samples for each, but for reproducibility, I specified the random states.\n",
        "\n",
        "Word Embedding:\n",
        "> The embedding layer was found to be critical in boosting the performance of the seq2seq model, probably because the one-hot encoded arrays had the problem of suffering sparsity that was not easily regularized. Word embedding created latent dimensions to represent the features of the words, same as the concepts adopted in the word2vec model. Both encoder and decoder sequences were trained with 500-dimension embeddings.\n",
        "\n",
        "Encoder structure:\n",
        "> Bi-direcional LSTM structure was used with 250 units of cells, outputting in total 500 dimensions of hidden state vectors by setting *return_sequence = True*.\n",
        "> The forward-propagating and backward-propagating encoder hidden state vectors would be concatenated, and passed to be the initial hidden state for decoder.\n",
        "\n",
        "<img src='http://opennmt.net/OpenNMT/img/brnn.png'/>\n",
        "\n",
        "Decoder structure:\n",
        "> Two-layer stacked LSTM was used as the decoder. The initial decoder input was set to be the \"BOS\" tag. Teacher forcing was implemented by outputting one token index with highest probability at current time step, and passing this token as the input for next token prediction, recursively throughout the maximum equence length.\n",
        "\n",
        "Attention mechanism (Luong Attention):\n",
        "> Attention has been invented in the researches of seq2seq models. The basic idea resembling the behaviour of human reading a sentence is that people would recognize the context from each of the words in encoder, rather than simply read through all words at one time to memorize it, and decode a sentence. Since during decoding, only the hidden states of the previous LSTM output would be used to predict the next token, this could sacrifice some of the information conveyed in the encoder. \n",
        "\n",
        "> Against this problem, a weighted score was calculated for each encoder hidden state dotted on the current decoder hidden state. A context vector would be produced on the softmax-activated attention scores. Eventually the context vector would be concatenated with the current decoder hidden state, performing tanh and softmax activation to get a probability for each token in the corpus of decoder dictionary.\n",
        "\n",
        "<img src='http://opennmt.net/OpenNMT/img/global-attention-model.png'/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhN5u-wNa0gw",
        "colab_type": "code",
        "outputId": "abd23329-5719-470a-a097-1e25bd9cc3f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Activation, Concatenate, Dot\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEVPnyjmVXsh",
        "colab_type": "code",
        "outputId": "fae0b93a-5599-478c-a055-b58f2aeab585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "## Encoder structure with Bi-directional LSTM\n",
        "## return only states from encoder to pass to decoder\n",
        "\n",
        "encoder_inputs = Input(shape=(None, ))\n",
        "encoder_embed = Embedding(input_dim=135, output_dim=500)(encoder_inputs)\n",
        "encoder_LSTM = Bidirectional(LSTM(250, return_state=True, return_sequences=True))\n",
        "encoder_hidden_vec, forward_last_h, forward_last_c, backward_last_h, backward_last_c = encoder_LSTM(encoder_embed)\n",
        "enc_state_last_h = Concatenate()([forward_last_h, backward_last_h])\n",
        "enc_state_last_c = Concatenate()([forward_last_c, backward_last_c])\n",
        "encoder_states = [enc_state_last_h, enc_state_last_c]\n",
        "\n",
        "## Decoder structure with 2-layer stacked LSTM\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "decoder_embed = Embedding(input_dim=79, output_dim=500)(decoder_inputs)\n",
        "decoder_LSTM = LSTM(units=500, return_state=True, return_sequences=True)\n",
        "decoder_LSTM_layer = decoder_LSTM(decoder_embed, initial_state = encoder_states)\n",
        "decoder_LSTM2 = LSTM(units=500, return_state=True, return_sequences=True)\n",
        "decoder_hidden_vec, dec_state_last_h, dec_state_last_c = decoder_LSTM2(decoder_LSTM_layer)\n",
        "    \n",
        "## Attention mechanism\n",
        "attention_score = Dot([2,2])([decoder_hidden_vec, encoder_hidden_vec])\n",
        "attention_weight = Activation('softmax')(attention_score)\n",
        "context = Dot([2,1])([attention_weight, encoder_hidden_vec])\n",
        "decoder_outputs_combined_context = Concatenate()([context, decoder_hidden_vec])\n",
        "hidden_state_outputs = TimeDistributed(Dense(500, activation='tanh'))(decoder_outputs_combined_context)\n",
        "outputs = TimeDistributed(Dense(79, activation='softmax'))(hidden_state_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, None, 500)    67500       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) [(None, None, 500),  1502000     embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, None, 500)    39500       input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 500)          0           bidirectional_5[0][1]            \n",
            "                                                                 bidirectional_5[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 500)          0           bidirectional_5[0][2]            \n",
            "                                                                 bidirectional_5[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_14 (LSTM)                  [(None, None, 500),  2002000     embedding_10[0][0]               \n",
            "                                                                 concatenate_13[0][0]             \n",
            "                                                                 concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lstm_15 (LSTM)                  [(None, None, 500),  2002000     lstm_14[0][0]                    \n",
            "                                                                 lstm_14[0][1]                    \n",
            "                                                                 lstm_14[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_9 (Dot)                     (None, None, None)   0           lstm_15[0][0]                    \n",
            "                                                                 bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None)   0           dot_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dot_10 (Dot)                    (None, None, 500)    0           activation_5[0][0]               \n",
            "                                                                 bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, None, 1000)   0           dot_10[0][0]                     \n",
            "                                                                 lstm_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistrib (None, None, 500)    500500      concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_10 (TimeDistri (None, None, 79)     39579       time_distributed_9[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 6,153,079\n",
            "Trainable params: 6,153,079\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Im2csQr5Dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Seq2Seq Model - number-of-sample-sequence-length 2D inputs with embedding layer\n",
        "def seq2seq_2D_embedding_one_hot_seq_attention(encoder_seq_train, \n",
        "                                               decoder_input_seq_train, decoder_output_seq_train, \n",
        "                                               encoder_seq_test, \n",
        "                                               decoder_input_seq_test, decoder_output_seq_test,\n",
        "                                               encoder_dict, decoder_dict,\n",
        "                                               batch_size, num_epochs):\n",
        "  \n",
        "  ## fitting with 10 bootstrap samples\n",
        "  random_state = [1, 4, 20, 21, 42, 99, 101, 111, 231, 999]\n",
        "\n",
        "  def bootstrap_samples(num_training_samples, self_defined_random_state, \n",
        "                        encoder_training_samples, \n",
        "                        decoder_training_samples, decoder_training_samples_output):\n",
        "    sample_index = list(range(0, num_training_samples))\n",
        "    boot = resample(sample_index, replace=False, \n",
        "                    n_samples = int(num_training_samples*0.96), \n",
        "                    random_state = self_defined_random_state)\n",
        "    \n",
        "    enc_train = [encoder_training_samples[ref] for ref in boot]\n",
        "    enc_val = [encoder_training_samples[ref] for ref in range(0, len(encoder_training_samples)) if ref not in boot]\n",
        "    \n",
        "    dec_train_in = [decoder_training_samples[ref] for ref in boot]\n",
        "    dec_val_in = [decoder_training_samples[ref] for ref in range(0, len(decoder_training_samples)) if ref not in boot]\n",
        "    \n",
        "    dec_train_out = [decoder_training_samples_output[ref] for ref in boot]\n",
        "    dec_val_out = [decoder_training_samples_output[ref] for ref in range(0, len(decoder_training_samples_output)) if ref not in boot]\n",
        "    \n",
        "    enc_train = np.array(enc_train)\n",
        "    enc_val = np.array(enc_val)\n",
        "    dec_train_in = np.array(dec_train_in)\n",
        "    dec_val_in = np.array(dec_val_in)\n",
        "    dec_train_out = np.array(dec_train_out)\n",
        "    dec_val_out = np.array(dec_val_out)\n",
        "    \n",
        "    return enc_train, enc_val, dec_train_in, dec_val_in, dec_train_out, dec_val_out\n",
        "  \n",
        "  ## Using 2D array inputs (arrays of max sequence length) WITH Embedding\n",
        "\n",
        "  def define_seq2seq_model_embedding(encoder_dict, decoder_dict, encoder, decoder):\n",
        "\n",
        "    ## embedding layer shape => number of unique words in the dictionary\n",
        "    ## a) Training part\n",
        "    ## b) Inference part\n",
        "\n",
        "    len_en = len(encoder_dict)\n",
        "    len_de = len(decoder_dict)\n",
        "    max_length_en = max([len(x) for x in encoder])\n",
        "    max_length_de = max([len(x) for x in decoder])\n",
        "\n",
        "    ## Encoder structure with Bi-directional LSTM\n",
        "    ## return only states from encoder to pass to decoder\n",
        "\n",
        "    encoder_inputs = Input(shape=(None, ))\n",
        "    encoder_embed = Embedding(input_dim=len_en, output_dim=500)(encoder_inputs)\n",
        "    encoder_LSTM = Bidirectional(LSTM(250, return_state=True, return_sequences=True))\n",
        "    encoder_hidden_vec, forward_last_h, forward_last_c, backward_last_h, backward_last_c = encoder_LSTM(encoder_embed)\n",
        "    enc_state_last_h = Concatenate()([forward_last_h, backward_last_h])\n",
        "    enc_state_last_c = Concatenate()([forward_last_c, backward_last_c])\n",
        "    encoder_states = [enc_state_last_h, enc_state_last_c]\n",
        "\n",
        "    ## Decoder structure with 2-layer stacked LSTM\n",
        "    decoder_inputs = Input(shape=(None, ))\n",
        "    decoder_embed = Embedding(input_dim=len_de, output_dim=500)(decoder_inputs)\n",
        "    decoder_LSTM = LSTM(units=500, return_state=True, return_sequences=True)\n",
        "    decoder_LSTM_layer = decoder_LSTM(decoder_embed, initial_state = encoder_states)\n",
        "    decoder_LSTM2 = LSTM(units=500, return_state=True, return_sequences=True)\n",
        "    decoder_hidden_vec, dec_state_last_h, dec_state_last_c = decoder_LSTM2(decoder_LSTM_layer)\n",
        "\n",
        "    ## Attention mechanism\n",
        "    attention_score = Dot([2,2])([decoder_hidden_vec, encoder_hidden_vec])\n",
        "    attention_weight = Activation('softmax')(attention_score)\n",
        "    context = Dot([2,1])([attention_weight, encoder_hidden_vec])\n",
        "    decoder_outputs_combined_context = Concatenate()([context, decoder_hidden_vec])\n",
        "    hidden_state_outputs = TimeDistributed(Dense(500, activation='tanh'))(decoder_outputs_combined_context)\n",
        "    outputs = TimeDistributed(Dense(len_de, activation='softmax'))(hidden_state_outputs)\n",
        "    \n",
        "    model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "    \n",
        "    return model\n",
        "\n",
        "  ## function to generate target given source sequence\n",
        "  def predict_sequence_embedding(model, input_encoder_seq, n_steps_in_seq):\n",
        "    # set zero for the start of the target sequence\n",
        "    dec_input = np.zeros((1, n_steps_in_seq))\n",
        "    # populate the <BOS> tag of the targeted generated sequence\n",
        "    dec_input[0, 0] = 2\n",
        "    # initializations\n",
        "    output = []\n",
        "    for t in range(n_steps_in_seq):\n",
        "      # predict next element (token) from decoder model\n",
        "      dec_output = model.predict([input_encoder_seq, dec_input])\n",
        "      output.append(dec_output[0,t,:])\n",
        "      # update target sequence recurrently\n",
        "      # with teacher forcing: search for the activated index and update the sequence positions as the next input\n",
        "      # without teacher forcing: use its own prediction probability as the next input\n",
        "      activated_index = np.argmax(dec_output[0,t,:])\n",
        "      if t+1 < n_steps_in_seq:\n",
        "        dec_input[0, t+1] = activated_index\n",
        "      \n",
        "    return np.array(output)\n",
        "    \n",
        "  ## main part operations\n",
        "  predicted_seq = []\n",
        "  validated_seq = []\n",
        "  bleu = []\n",
        "  bleu_sample = []\n",
        "  avg_acc = []\n",
        "  avg_acc_positive = []\n",
        "  accuracy_per_run = []\n",
        "  accuracy_per_run_positive = []\n",
        "  training_history = []\n",
        "\n",
        "  # call model for training\n",
        "  model = define_seq2seq_model_embedding(encoder_dict, decoder_dict, \n",
        "                                         encoder_seq_train, decoder_input_seq_train)\n",
        "  model.compile(optimizer=RMSprop(lr=0.00001), loss='categorical_crossentropy', metrics=['acc'])\n",
        "  \n",
        "  for b in range(len(random_state)):\n",
        "    enc_train, enc_val, dec_train_in, dec_val_in, dec_train_out, dec_val_out = \\\n",
        "    bootstrap_samples(len(encoder_seq_train), random_state[b], \n",
        "                      encoder_seq_train, decoder_input_seq_train, decoder_output_seq_train)\n",
        "    # training the main model\n",
        "    model.fit([enc_train, dec_train_in], dec_train_out, \n",
        "              batch_size=10, epochs=40, validation_data=([enc_val, dec_val_in], dec_val_out))\n",
        "\n",
        "    # make predictions using the inference models\n",
        "    n_steps_in_seq = len(decoder_output_seq_train[0])\n",
        "    inference_seq = []\n",
        "    for t in range(len(encoder_seq_test)):\n",
        "      y_estimated = predict_sequence_embedding(model, encoder_seq_test[t].reshape(1, encoder_seq_test[t].shape[0]), n_steps_in_seq)\n",
        "      inference_seq.append(y_estimated)\n",
        "\n",
        "    acc_score = 0\n",
        "    total = 0\n",
        "\n",
        "    for samples in range(len(inference_seq)):\n",
        "      pred = []\n",
        "      actual = []\n",
        "      for p in range(len(inference_seq[samples])):\n",
        "        total += 1\n",
        "        predicted_token_index = np.argmax(inference_seq[samples][p])\n",
        "        validated_token_index = np.argmax(decoder_output_seq_test[samples][p])\n",
        "        predicted_token = list(decoder_dict.keys())[list(decoder_dict.values()).index(predicted_token_index)]\n",
        "        validated_token = list(decoder_dict.keys())[list(decoder_dict.values()).index(validated_token_index)]\n",
        "        if predicted_token_index==validated_token_index:\n",
        "          acc_score += 1\n",
        "        pred.append(predicted_token)\n",
        "        actual.append(validated_token)\n",
        "      predicted_seq.append(pred)\n",
        "      validated_seq.append(actual)\n",
        "      bleu_sample.append(sentence_bleu([pred], actual))\n",
        "      accuracy = acc_score / total\n",
        "      accuracy_per_run.append(accuracy)\n",
        "      \n",
        "    avg_acc.append(np.mean(np.array(accuracy_per_run)))\n",
        "    bleu.append(np.mean(np.array(bleu_sample)))\n",
        "    \n",
        "  return model, inference_seq, accuracy_per_run, avg_acc, bleu_sample, bleu, predicted_seq, validated_seq, training_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlV3KJoRKWRJ",
        "colab_type": "text"
      },
      "source": [
        "### Model evaluation:\n",
        "\n",
        "Accuracy was measured on each token predicted. It turned out to be fairly good close to 0.2, since \"PAD\" tags were placed after the \"EOS\" tag in the actual output, while the model kept giving \"EOS\" tag as observed in below test samples. The real accuracy score should be higher than shown here as \"PAD\" and \"EOS\" contextually made no difference. BLEU score is generally a better metric for quantifying the performance of seq2seq model, which depends on the the counts of matched n-gram tokens in the predicted sequence. The results attained over 0.4 for BLEU.\n",
        "\n",
        "For the first comparison of predicted sequence and the actual validated sequence below, the model predicted correctly after training with 2 bootstrap samples. Over-fitting probably occurred as it continued training with the remaining bootstrap samples. The second comparison quoted successfully predicted the target allocation percentage after training with the bootstrap samples at the 5th, 6th and 7th run.\n",
        "\n",
        "It showed seq2seq had potentials in sequential relationship learning problems, given one did not want to manually investigate each instruction texts, but definitely more data would be required to feed the model to learn with a more robust performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOkxsijvGmJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_before_exfty_2, infer_seq_before_exfty_2, accuracy_per_run_before_exfty_2, \\\n",
        "avg_acc_before_exfty_2, bleu_sample_before_exfty_2, bleu_before_exfty_2, \\\n",
        "pred_before_exfty_2, val_before_exfty_2, hist_before_exfty_2 \\\n",
        "= seq2seq_2D_embedding_one_hot_seq_attention(encoder_seq_train, \n",
        "                                             decoder_before_exfty_seq_train, \n",
        "                                             decoder_before_exfty_seq_y_train,\n",
        "                                             encoder_seq_test, \n",
        "                                             decoder_before_exfty_seq_test, \n",
        "                                             decoder_before_exfty_seq_y_test,\n",
        "                                             encoder_dict, decoder_before_exfty_dict, \n",
        "                                             batch_size=10, num_epochs=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ_RSPYWCNZ4",
        "colab_type": "code",
        "outputId": "b26ed466-919f-4716-889a-32255767aece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print([\"%.4f\" % d for d in avg_acc_before_exfty_2])\n",
        "print([\"%.4f\" % d for d in bleu_before_exfty_2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0.1653', '0.1680', '0.1723', '0.1734', '0.1784', '0.1784', '0.2070', '0.2064', '0.2029', '0.2037']\n",
            "['0.4337', '0.4198', '0.4300', '0.4242', '0.4222', '0.4280', '0.4214', '0.4132', '0.4140', '0.4114']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUPJKcS64jsh",
        "colab_type": "code",
        "outputId": "36be41aa-c9f6-450c-e111-85783775b040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_after_exfty_2, infer_seq_after_exfty_2, accuracy_per_run_after_exfty_2, \\\n",
        "avg_acc_after_exfty_2, bleu_sample_after_exfty_2, bleu_after_exfty_2, \\\n",
        "pred_after_exfty_2, val_after_exfty_2, hist_after_exfty_2 \\\n",
        "= seq2seq_2D_embedding_one_hot_seq_attention(encoder_seq_train, \n",
        "                                             decoder_after_exfty_seq_train, \n",
        "                                             decoder_after_exfty_seq_y_train,\n",
        "                                             encoder_seq_test, \n",
        "                                             decoder_after_exfty_seq_test, \n",
        "                                             decoder_after_exfty_seq_y_test,\n",
        "                                             encoder_dict, decoder_after_exfty_dict, \n",
        "                                             batch_size=10, num_epochs=40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 11s 34ms/step - loss: 1.8692 - acc: 0.0497 - val_loss: 1.9278 - val_acc: 0.0745\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.8404 - acc: 0.0792 - val_loss: 1.8962 - val_acc: 0.0824\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.7967 - acc: 0.0813 - val_loss: 1.8441 - val_acc: 0.0745\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.7221 - acc: 0.0810 - val_loss: 1.7536 - val_acc: 0.0745\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.5988 - acc: 0.0810 - val_loss: 1.6136 - val_acc: 0.0745\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.4469 - acc: 0.0827 - val_loss: 1.4947 - val_acc: 0.0824\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.3576 - acc: 0.1275 - val_loss: 1.4426 - val_acc: 0.1255\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.3115 - acc: 0.1107 - val_loss: 1.4105 - val_acc: 0.0941\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.2790 - acc: 0.0990 - val_loss: 1.3970 - val_acc: 0.0980\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.2529 - acc: 0.1246 - val_loss: 1.3844 - val_acc: 0.1294\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.2306 - acc: 0.1374 - val_loss: 1.3718 - val_acc: 0.1294\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.2124 - acc: 0.1374 - val_loss: 1.3677 - val_acc: 0.1294\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1977 - acc: 0.1374 - val_loss: 1.3563 - val_acc: 0.1294\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1850 - acc: 0.1374 - val_loss: 1.3493 - val_acc: 0.1294\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1739 - acc: 0.1374 - val_loss: 1.3489 - val_acc: 0.1294\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1645 - acc: 0.1374 - val_loss: 1.3394 - val_acc: 0.1294\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1550 - acc: 0.1374 - val_loss: 1.3326 - val_acc: 0.1294\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1460 - acc: 0.1374 - val_loss: 1.3211 - val_acc: 0.1294\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1374 - acc: 0.1374 - val_loss: 1.3180 - val_acc: 0.1294\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1282 - acc: 0.1374 - val_loss: 1.3075 - val_acc: 0.1294\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1195 - acc: 0.1375 - val_loss: 1.3025 - val_acc: 0.1294\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1104 - acc: 0.1434 - val_loss: 1.2941 - val_acc: 0.1333\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.1018 - acc: 0.1471 - val_loss: 1.2865 - val_acc: 0.1333\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0929 - acc: 0.1471 - val_loss: 1.2812 - val_acc: 0.1333\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0834 - acc: 0.1478 - val_loss: 1.2748 - val_acc: 0.1333\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0737 - acc: 0.1486 - val_loss: 1.2629 - val_acc: 0.1333\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0638 - acc: 0.1488 - val_loss: 1.2586 - val_acc: 0.1333\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0525 - acc: 0.1512 - val_loss: 1.2498 - val_acc: 0.1373\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0410 - acc: 0.1574 - val_loss: 1.2358 - val_acc: 0.1451\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0294 - acc: 0.1623 - val_loss: 1.2256 - val_acc: 0.1490\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0175 - acc: 0.1664 - val_loss: 1.2170 - val_acc: 0.1490\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 1.0059 - acc: 0.1708 - val_loss: 1.2041 - val_acc: 0.1529\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.9921 - acc: 0.1735 - val_loss: 1.1977 - val_acc: 0.1529\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.9795 - acc: 0.1751 - val_loss: 1.1884 - val_acc: 0.1529\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.9673 - acc: 0.1775 - val_loss: 1.1756 - val_acc: 0.1529\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.9538 - acc: 0.1799 - val_loss: 1.1623 - val_acc: 0.1529\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.9402 - acc: 0.1844 - val_loss: 1.1453 - val_acc: 0.1647\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.9265 - acc: 0.1952 - val_loss: 1.1306 - val_acc: 0.1765\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.9120 - acc: 0.2038 - val_loss: 1.1167 - val_acc: 0.1765\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.8952 - acc: 0.2116 - val_loss: 1.1029 - val_acc: 0.1922\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            " 10/340 [..............................] - ETA: 5s - loss: 0.9289 - acc: 0.2000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "340/340 [==============================] - 5s 15ms/step - loss: 0.8797 - acc: 0.2157 - val_loss: 1.1091 - val_acc: 0.1882\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.8659 - acc: 0.2199 - val_loss: 1.0960 - val_acc: 0.2000\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.8509 - acc: 0.2234 - val_loss: 1.0836 - val_acc: 0.2039\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.8374 - acc: 0.2197 - val_loss: 1.0641 - val_acc: 0.2000\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.8241 - acc: 0.2277 - val_loss: 1.0609 - val_acc: 0.2039\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.8109 - acc: 0.2285 - val_loss: 1.0483 - val_acc: 0.2039\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7986 - acc: 0.2279 - val_loss: 1.0291 - val_acc: 0.2000\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7872 - acc: 0.2273 - val_loss: 1.0380 - val_acc: 0.2078\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7760 - acc: 0.2303 - val_loss: 1.0074 - val_acc: 0.2078\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7643 - acc: 0.2311 - val_loss: 0.9990 - val_acc: 0.2196\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7537 - acc: 0.2320 - val_loss: 0.9867 - val_acc: 0.2157\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7442 - acc: 0.2313 - val_loss: 0.9852 - val_acc: 0.2078\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7342 - acc: 0.2304 - val_loss: 0.9773 - val_acc: 0.2078\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7256 - acc: 0.2344 - val_loss: 0.9677 - val_acc: 0.2157\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7178 - acc: 0.2372 - val_loss: 0.9567 - val_acc: 0.2196\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7092 - acc: 0.2384 - val_loss: 0.9457 - val_acc: 0.2275\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.7009 - acc: 0.2386 - val_loss: 0.9418 - val_acc: 0.2196\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6945 - acc: 0.2420 - val_loss: 0.9460 - val_acc: 0.2196\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6867 - acc: 0.2415 - val_loss: 0.9276 - val_acc: 0.2353\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6816 - acc: 0.2478 - val_loss: 0.9259 - val_acc: 0.2275\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6711 - acc: 0.2474 - val_loss: 0.9190 - val_acc: 0.2235\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6674 - acc: 0.2495 - val_loss: 0.9095 - val_acc: 0.2510\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6607 - acc: 0.2488 - val_loss: 0.9015 - val_acc: 0.2471\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6552 - acc: 0.2493 - val_loss: 0.8988 - val_acc: 0.2510\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6486 - acc: 0.2542 - val_loss: 0.8950 - val_acc: 0.2353\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6430 - acc: 0.2583 - val_loss: 0.8827 - val_acc: 0.2471\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6371 - acc: 0.2547 - val_loss: 0.8809 - val_acc: 0.2392\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6314 - acc: 0.2580 - val_loss: 0.8754 - val_acc: 0.2588\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6262 - acc: 0.2599 - val_loss: 0.8699 - val_acc: 0.2471\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6221 - acc: 0.2600 - val_loss: 0.8628 - val_acc: 0.2510\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6155 - acc: 0.2630 - val_loss: 0.8632 - val_acc: 0.2706\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 16ms/step - loss: 0.6109 - acc: 0.2647 - val_loss: 0.8623 - val_acc: 0.2588\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6063 - acc: 0.2666 - val_loss: 0.8502 - val_acc: 0.2745\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.6016 - acc: 0.2626 - val_loss: 0.8507 - val_acc: 0.2667\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5954 - acc: 0.2654 - val_loss: 0.8440 - val_acc: 0.2549\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5922 - acc: 0.2721 - val_loss: 0.8423 - val_acc: 0.2706\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5881 - acc: 0.2687 - val_loss: 0.8361 - val_acc: 0.2706\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5816 - acc: 0.2713 - val_loss: 0.8257 - val_acc: 0.2824\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5777 - acc: 0.2696 - val_loss: 0.8204 - val_acc: 0.2667\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5742 - acc: 0.2696 - val_loss: 0.8195 - val_acc: 0.2745\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5811 - acc: 0.2744 - val_loss: 0.5684 - val_acc: 0.2510\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5754 - acc: 0.2723 - val_loss: 0.5709 - val_acc: 0.2588\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5726 - acc: 0.2730 - val_loss: 0.5596 - val_acc: 0.2588\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5667 - acc: 0.2763 - val_loss: 0.5573 - val_acc: 0.2510\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5630 - acc: 0.2732 - val_loss: 0.5503 - val_acc: 0.2549\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5589 - acc: 0.2777 - val_loss: 0.5571 - val_acc: 0.2471\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5531 - acc: 0.2763 - val_loss: 0.5461 - val_acc: 0.2627\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5503 - acc: 0.2792 - val_loss: 0.5459 - val_acc: 0.2510\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5457 - acc: 0.2789 - val_loss: 0.5410 - val_acc: 0.2588\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5415 - acc: 0.2777 - val_loss: 0.5344 - val_acc: 0.2667\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5369 - acc: 0.2808 - val_loss: 0.5294 - val_acc: 0.2745\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5330 - acc: 0.2832 - val_loss: 0.5265 - val_acc: 0.2784\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5298 - acc: 0.2803 - val_loss: 0.5217 - val_acc: 0.2588\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5232 - acc: 0.2841 - val_loss: 0.5360 - val_acc: 0.2667\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5207 - acc: 0.2848 - val_loss: 0.5154 - val_acc: 0.2745\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5143 - acc: 0.2882 - val_loss: 0.5116 - val_acc: 0.2784\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5128 - acc: 0.2881 - val_loss: 0.5078 - val_acc: 0.2706\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5074 - acc: 0.2903 - val_loss: 0.5071 - val_acc: 0.2745\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.5028 - acc: 0.2919 - val_loss: 0.4978 - val_acc: 0.2784\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4972 - acc: 0.2920 - val_loss: 0.4931 - val_acc: 0.2941\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4979 - acc: 0.2901 - val_loss: 0.4888 - val_acc: 0.3020\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4895 - acc: 0.2955 - val_loss: 0.4848 - val_acc: 0.2980\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4886 - acc: 0.2967 - val_loss: 0.4844 - val_acc: 0.3020\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4809 - acc: 0.2993 - val_loss: 0.4783 - val_acc: 0.2902\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4815 - acc: 0.2983 - val_loss: 0.4749 - val_acc: 0.2980\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4753 - acc: 0.3043 - val_loss: 0.4956 - val_acc: 0.2902\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4710 - acc: 0.3002 - val_loss: 0.4687 - val_acc: 0.2980\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4657 - acc: 0.3017 - val_loss: 0.4607 - val_acc: 0.2941\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4620 - acc: 0.3016 - val_loss: 0.4616 - val_acc: 0.2902\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4593 - acc: 0.3055 - val_loss: 0.4574 - val_acc: 0.2941\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4546 - acc: 0.3067 - val_loss: 0.4568 - val_acc: 0.2902\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4519 - acc: 0.3054 - val_loss: 0.4545 - val_acc: 0.2863\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4463 - acc: 0.3066 - val_loss: 0.4515 - val_acc: 0.2941\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4448 - acc: 0.3074 - val_loss: 0.4442 - val_acc: 0.3059\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4403 - acc: 0.3081 - val_loss: 0.4423 - val_acc: 0.3059\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4392 - acc: 0.3064 - val_loss: 0.4349 - val_acc: 0.3098\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4329 - acc: 0.3135 - val_loss: 0.4512 - val_acc: 0.2902\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4295 - acc: 0.3121 - val_loss: 0.4312 - val_acc: 0.3098\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4260 - acc: 0.3114 - val_loss: 0.4288 - val_acc: 0.3020\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4241 - acc: 0.3151 - val_loss: 0.4251 - val_acc: 0.3098\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4185 - acc: 0.3151 - val_loss: 0.4177 - val_acc: 0.3176\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4152 - acc: 0.3157 - val_loss: 0.4211 - val_acc: 0.3294\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4119 - acc: 0.3180 - val_loss: 0.4244 - val_acc: 0.3098\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4105 - acc: 0.3159 - val_loss: 0.4189 - val_acc: 0.3098\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4041 - acc: 0.3218 - val_loss: 0.4129 - val_acc: 0.3176\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.4013 - acc: 0.3218 - val_loss: 0.4359 - val_acc: 0.3216\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3983 - acc: 0.3223 - val_loss: 0.4149 - val_acc: 0.3176\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3934 - acc: 0.3225 - val_loss: 0.4092 - val_acc: 0.3176\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3953 - acc: 0.3242 - val_loss: 0.4166 - val_acc: 0.3216\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3881 - acc: 0.3263 - val_loss: 0.4047 - val_acc: 0.3216\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3849 - acc: 0.3277 - val_loss: 0.4053 - val_acc: 0.3137\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3872 - acc: 0.3268 - val_loss: 0.4034 - val_acc: 0.3333\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3785 - acc: 0.3304 - val_loss: 0.3986 - val_acc: 0.3216\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3770 - acc: 0.3325 - val_loss: 0.4011 - val_acc: 0.3137\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3732 - acc: 0.3311 - val_loss: 0.4002 - val_acc: 0.3333\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3709 - acc: 0.3304 - val_loss: 0.3960 - val_acc: 0.3294\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3693 - acc: 0.3324 - val_loss: 0.3923 - val_acc: 0.3294\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3644 - acc: 0.3344 - val_loss: 0.3955 - val_acc: 0.3255\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3599 - acc: 0.3344 - val_loss: 0.3883 - val_acc: 0.3176\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3571 - acc: 0.3337 - val_loss: 0.3826 - val_acc: 0.3255\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3566 - acc: 0.3349 - val_loss: 0.3864 - val_acc: 0.3255\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3549 - acc: 0.3349 - val_loss: 0.3782 - val_acc: 0.3294\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3505 - acc: 0.3384 - val_loss: 0.3768 - val_acc: 0.3216\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3476 - acc: 0.3379 - val_loss: 0.3805 - val_acc: 0.3333\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3450 - acc: 0.3386 - val_loss: 0.3854 - val_acc: 0.3294\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3449 - acc: 0.3389 - val_loss: 0.4020 - val_acc: 0.3333\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3424 - acc: 0.3396 - val_loss: 0.3659 - val_acc: 0.3373\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3382 - acc: 0.3386 - val_loss: 0.3675 - val_acc: 0.3294\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3377 - acc: 0.3391 - val_loss: 0.3708 - val_acc: 0.3294\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3340 - acc: 0.3403 - val_loss: 0.3636 - val_acc: 0.3333\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3330 - acc: 0.3408 - val_loss: 0.3725 - val_acc: 0.3333\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3276 - acc: 0.3417 - val_loss: 0.3619 - val_acc: 0.3373\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3286 - acc: 0.3434 - val_loss: 0.3626 - val_acc: 0.3373\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3256 - acc: 0.3429 - val_loss: 0.3574 - val_acc: 0.3333\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3200 - acc: 0.3458 - val_loss: 0.3730 - val_acc: 0.3216\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3203 - acc: 0.3464 - val_loss: 0.3572 - val_acc: 0.3333\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3164 - acc: 0.3465 - val_loss: 0.3552 - val_acc: 0.3294\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3144 - acc: 0.3460 - val_loss: 0.3522 - val_acc: 0.3333\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3142 - acc: 0.3478 - val_loss: 0.3578 - val_acc: 0.3294\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3102 - acc: 0.3493 - val_loss: 0.3541 - val_acc: 0.3333\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3145 - acc: 0.3481 - val_loss: 0.2304 - val_acc: 0.3569\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3143 - acc: 0.3458 - val_loss: 0.2355 - val_acc: 0.3451\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3091 - acc: 0.3521 - val_loss: 0.2194 - val_acc: 0.3529\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3093 - acc: 0.3505 - val_loss: 0.2189 - val_acc: 0.3529\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3048 - acc: 0.3505 - val_loss: 0.2283 - val_acc: 0.3490\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3042 - acc: 0.3512 - val_loss: 0.2130 - val_acc: 0.3569\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2998 - acc: 0.3538 - val_loss: 0.3396 - val_acc: 0.3137\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.3016 - acc: 0.3512 - val_loss: 0.2129 - val_acc: 0.3569\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2965 - acc: 0.3547 - val_loss: 0.2094 - val_acc: 0.3529\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2962 - acc: 0.3510 - val_loss: 0.2286 - val_acc: 0.3490\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2917 - acc: 0.3561 - val_loss: 0.2169 - val_acc: 0.3529\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2932 - acc: 0.3535 - val_loss: 0.2094 - val_acc: 0.3569\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2900 - acc: 0.3529 - val_loss: 0.2148 - val_acc: 0.3647\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2909 - acc: 0.3566 - val_loss: 0.2015 - val_acc: 0.3647\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2860 - acc: 0.3561 - val_loss: 0.1988 - val_acc: 0.3569\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2831 - acc: 0.3567 - val_loss: 0.2016 - val_acc: 0.3608\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2819 - acc: 0.3580 - val_loss: 0.2070 - val_acc: 0.3529\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2825 - acc: 0.3569 - val_loss: 0.1984 - val_acc: 0.3647\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2800 - acc: 0.3567 - val_loss: 0.1967 - val_acc: 0.3686\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2754 - acc: 0.3599 - val_loss: 0.1966 - val_acc: 0.3608\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2737 - acc: 0.3597 - val_loss: 0.1996 - val_acc: 0.3765\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2755 - acc: 0.3593 - val_loss: 0.1944 - val_acc: 0.3647\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2705 - acc: 0.3604 - val_loss: 0.2005 - val_acc: 0.3569\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2702 - acc: 0.3588 - val_loss: 0.1925 - val_acc: 0.3608\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2688 - acc: 0.3616 - val_loss: 0.1888 - val_acc: 0.3608\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2646 - acc: 0.3638 - val_loss: 0.1887 - val_acc: 0.3686\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2651 - acc: 0.3623 - val_loss: 0.2174 - val_acc: 0.3765\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2625 - acc: 0.3631 - val_loss: 0.1862 - val_acc: 0.3725\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2600 - acc: 0.3656 - val_loss: 0.1974 - val_acc: 0.3608\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2595 - acc: 0.3649 - val_loss: 0.1862 - val_acc: 0.3686\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2561 - acc: 0.3654 - val_loss: 0.1858 - val_acc: 0.3843\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2559 - acc: 0.3659 - val_loss: 0.1772 - val_acc: 0.3765\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2546 - acc: 0.3676 - val_loss: 0.1782 - val_acc: 0.3725\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2522 - acc: 0.3694 - val_loss: 0.1775 - val_acc: 0.3725\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2508 - acc: 0.3664 - val_loss: 0.1933 - val_acc: 0.3647\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2509 - acc: 0.3694 - val_loss: 0.1775 - val_acc: 0.3765\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2471 - acc: 0.3666 - val_loss: 0.1773 - val_acc: 0.3765\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2462 - acc: 0.3701 - val_loss: 0.1874 - val_acc: 0.3725\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2454 - acc: 0.3696 - val_loss: 0.1767 - val_acc: 0.3608\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2408 - acc: 0.3730 - val_loss: 0.1796 - val_acc: 0.3765\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2350 - acc: 0.3706 - val_loss: 0.3205 - val_acc: 0.3686\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2332 - acc: 0.3725 - val_loss: 0.3275 - val_acc: 0.3608\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2305 - acc: 0.3749 - val_loss: 0.3210 - val_acc: 0.3647\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2284 - acc: 0.3773 - val_loss: 0.3460 - val_acc: 0.3608\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2269 - acc: 0.3744 - val_loss: 0.3274 - val_acc: 0.3686\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2256 - acc: 0.3772 - val_loss: 0.3268 - val_acc: 0.3608\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2269 - acc: 0.3775 - val_loss: 0.3346 - val_acc: 0.3608\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2203 - acc: 0.3810 - val_loss: 0.3360 - val_acc: 0.3686\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2206 - acc: 0.3796 - val_loss: 0.3492 - val_acc: 0.3412\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2204 - acc: 0.3787 - val_loss: 0.3252 - val_acc: 0.3725\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2158 - acc: 0.3803 - val_loss: 0.3417 - val_acc: 0.3569\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2179 - acc: 0.3791 - val_loss: 0.3302 - val_acc: 0.3725\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2144 - acc: 0.3818 - val_loss: 0.3259 - val_acc: 0.3725\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2128 - acc: 0.3820 - val_loss: 0.3820 - val_acc: 0.3216\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2104 - acc: 0.3825 - val_loss: 0.3228 - val_acc: 0.3686\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2102 - acc: 0.3837 - val_loss: 0.3283 - val_acc: 0.3647\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2059 - acc: 0.3837 - val_loss: 0.3302 - val_acc: 0.3725\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2062 - acc: 0.3841 - val_loss: 0.3536 - val_acc: 0.3647\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2052 - acc: 0.3844 - val_loss: 0.3266 - val_acc: 0.3725\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2010 - acc: 0.3867 - val_loss: 0.3393 - val_acc: 0.3608\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.2037 - acc: 0.3856 - val_loss: 0.3456 - val_acc: 0.3647\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1990 - acc: 0.3869 - val_loss: 0.3273 - val_acc: 0.3725\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1979 - acc: 0.3858 - val_loss: 0.3280 - val_acc: 0.3725\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1950 - acc: 0.3875 - val_loss: 0.3331 - val_acc: 0.3608\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1952 - acc: 0.3894 - val_loss: 0.3357 - val_acc: 0.3647\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1937 - acc: 0.3875 - val_loss: 0.3244 - val_acc: 0.3686\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1908 - acc: 0.3912 - val_loss: 0.3266 - val_acc: 0.3686\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1928 - acc: 0.3865 - val_loss: 0.3391 - val_acc: 0.3686\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1899 - acc: 0.3882 - val_loss: 0.3194 - val_acc: 0.3725\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1851 - acc: 0.3910 - val_loss: 0.3394 - val_acc: 0.3647\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1873 - acc: 0.3903 - val_loss: 0.3471 - val_acc: 0.3608\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1838 - acc: 0.3920 - val_loss: 0.3233 - val_acc: 0.3647\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1815 - acc: 0.3927 - val_loss: 0.3204 - val_acc: 0.3686\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1808 - acc: 0.3908 - val_loss: 0.3250 - val_acc: 0.3647\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1817 - acc: 0.3920 - val_loss: 0.3186 - val_acc: 0.3725\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1790 - acc: 0.3933 - val_loss: 0.3147 - val_acc: 0.3765\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1767 - acc: 0.3938 - val_loss: 0.3249 - val_acc: 0.3647\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1767 - acc: 0.3936 - val_loss: 0.3243 - val_acc: 0.3686\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1743 - acc: 0.3939 - val_loss: 0.3324 - val_acc: 0.3686\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1728 - acc: 0.3945 - val_loss: 0.3366 - val_acc: 0.3686\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1797 - acc: 0.3934 - val_loss: 0.1294 - val_acc: 0.4078\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1796 - acc: 0.3955 - val_loss: 0.1302 - val_acc: 0.4039\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1785 - acc: 0.3938 - val_loss: 0.1343 - val_acc: 0.4039\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1737 - acc: 0.3974 - val_loss: 0.1333 - val_acc: 0.4078\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1743 - acc: 0.3953 - val_loss: 0.1324 - val_acc: 0.4039\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1727 - acc: 0.3957 - val_loss: 0.1331 - val_acc: 0.4039\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1727 - acc: 0.3958 - val_loss: 0.1328 - val_acc: 0.4039\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1729 - acc: 0.3957 - val_loss: 0.1303 - val_acc: 0.4078\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1695 - acc: 0.3964 - val_loss: 0.1352 - val_acc: 0.4039\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1682 - acc: 0.3972 - val_loss: 0.1320 - val_acc: 0.4039\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1668 - acc: 0.3974 - val_loss: 0.1313 - val_acc: 0.4078\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1647 - acc: 0.3976 - val_loss: 0.1339 - val_acc: 0.4039\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1624 - acc: 0.3984 - val_loss: 0.1373 - val_acc: 0.4000\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1660 - acc: 0.3967 - val_loss: 0.1313 - val_acc: 0.4078\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1619 - acc: 0.3969 - val_loss: 0.1370 - val_acc: 0.4039\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1604 - acc: 0.3981 - val_loss: 0.1305 - val_acc: 0.4078\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1602 - acc: 0.3972 - val_loss: 0.1306 - val_acc: 0.4078\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1567 - acc: 0.3998 - val_loss: 0.1307 - val_acc: 0.4078\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1582 - acc: 0.3986 - val_loss: 0.1310 - val_acc: 0.4078\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1556 - acc: 0.4012 - val_loss: 0.1335 - val_acc: 0.4078\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1560 - acc: 0.3997 - val_loss: 0.1317 - val_acc: 0.4078\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1531 - acc: 0.3997 - val_loss: 0.1295 - val_acc: 0.4039\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1506 - acc: 0.4005 - val_loss: 0.1443 - val_acc: 0.3961\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1509 - acc: 0.4003 - val_loss: 0.1294 - val_acc: 0.4039\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1498 - acc: 0.4009 - val_loss: 0.1278 - val_acc: 0.4039\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1495 - acc: 0.4014 - val_loss: 0.1295 - val_acc: 0.4039\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1473 - acc: 0.4002 - val_loss: 0.1328 - val_acc: 0.4039\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1457 - acc: 0.4024 - val_loss: 0.1284 - val_acc: 0.4039\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1450 - acc: 0.4021 - val_loss: 0.1293 - val_acc: 0.4039\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1426 - acc: 0.4017 - val_loss: 0.1312 - val_acc: 0.4039\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1450 - acc: 0.4005 - val_loss: 0.1310 - val_acc: 0.4039\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1421 - acc: 0.4029 - val_loss: 0.1298 - val_acc: 0.4039\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1405 - acc: 0.4033 - val_loss: 0.1311 - val_acc: 0.4039\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1407 - acc: 0.4021 - val_loss: 0.1262 - val_acc: 0.4039\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1389 - acc: 0.4036 - val_loss: 0.1271 - val_acc: 0.4078\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1398 - acc: 0.4017 - val_loss: 0.1325 - val_acc: 0.4039\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1373 - acc: 0.4029 - val_loss: 0.1256 - val_acc: 0.4039\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1383 - acc: 0.4021 - val_loss: 0.1586 - val_acc: 0.3843\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1343 - acc: 0.4036 - val_loss: 0.1275 - val_acc: 0.4039\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1350 - acc: 0.4045 - val_loss: 0.1253 - val_acc: 0.4039\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1333 - acc: 0.4038 - val_loss: 0.1182 - val_acc: 0.4196\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1348 - acc: 0.4033 - val_loss: 0.1141 - val_acc: 0.4157\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1293 - acc: 0.4048 - val_loss: 0.1129 - val_acc: 0.4157\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1314 - acc: 0.4033 - val_loss: 0.1136 - val_acc: 0.4157\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1301 - acc: 0.4036 - val_loss: 0.1119 - val_acc: 0.4157\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1286 - acc: 0.4045 - val_loss: 0.1178 - val_acc: 0.4157\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1279 - acc: 0.4055 - val_loss: 0.1190 - val_acc: 0.4196\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1272 - acc: 0.4043 - val_loss: 0.1156 - val_acc: 0.4157\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1253 - acc: 0.4052 - val_loss: 0.1195 - val_acc: 0.4196\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1260 - acc: 0.4043 - val_loss: 0.1136 - val_acc: 0.4196\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1234 - acc: 0.4062 - val_loss: 0.1221 - val_acc: 0.4118\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1249 - acc: 0.4052 - val_loss: 0.1166 - val_acc: 0.4196\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1206 - acc: 0.4057 - val_loss: 0.1152 - val_acc: 0.4196\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1225 - acc: 0.4061 - val_loss: 0.1128 - val_acc: 0.4196\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1200 - acc: 0.4061 - val_loss: 0.1112 - val_acc: 0.4196\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1197 - acc: 0.4069 - val_loss: 0.1141 - val_acc: 0.4196\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1208 - acc: 0.4052 - val_loss: 0.1221 - val_acc: 0.4157\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1174 - acc: 0.4073 - val_loss: 0.1384 - val_acc: 0.4078\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1184 - acc: 0.4059 - val_loss: 0.1085 - val_acc: 0.4196\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1150 - acc: 0.4076 - val_loss: 0.1184 - val_acc: 0.4078\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1154 - acc: 0.4073 - val_loss: 0.1274 - val_acc: 0.4078\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1154 - acc: 0.4066 - val_loss: 0.1075 - val_acc: 0.4235\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1136 - acc: 0.4078 - val_loss: 0.1147 - val_acc: 0.4196\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1124 - acc: 0.4092 - val_loss: 0.1146 - val_acc: 0.4196\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1128 - acc: 0.4081 - val_loss: 0.1062 - val_acc: 0.4196\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1116 - acc: 0.4081 - val_loss: 0.1051 - val_acc: 0.4196\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1097 - acc: 0.4097 - val_loss: 0.1086 - val_acc: 0.4196\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1106 - acc: 0.4095 - val_loss: 0.1041 - val_acc: 0.4157\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1080 - acc: 0.4099 - val_loss: 0.1027 - val_acc: 0.4196\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1092 - acc: 0.4092 - val_loss: 0.1049 - val_acc: 0.4196\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1064 - acc: 0.4104 - val_loss: 0.1030 - val_acc: 0.4196\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1065 - acc: 0.4087 - val_loss: 0.1064 - val_acc: 0.4235\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1061 - acc: 0.4081 - val_loss: 0.1058 - val_acc: 0.4235\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1053 - acc: 0.4095 - val_loss: 0.1015 - val_acc: 0.4196\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1053 - acc: 0.4107 - val_loss: 0.1060 - val_acc: 0.4235\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1026 - acc: 0.4100 - val_loss: 0.1003 - val_acc: 0.4235\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1057 - acc: 0.4085 - val_loss: 0.1003 - val_acc: 0.4196\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1012 - acc: 0.4109 - val_loss: 0.1037 - val_acc: 0.4235\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1017 - acc: 0.4104 - val_loss: 0.1100 - val_acc: 0.4196\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1003 - acc: 0.4112 - val_loss: 0.1206 - val_acc: 0.4118\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.1023 - acc: 0.4106 - val_loss: 0.0951 - val_acc: 0.4235\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0990 - acc: 0.4107 - val_loss: 0.0937 - val_acc: 0.4275\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0982 - acc: 0.4114 - val_loss: 0.0961 - val_acc: 0.4235\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0978 - acc: 0.4106 - val_loss: 0.0972 - val_acc: 0.4235\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0964 - acc: 0.4121 - val_loss: 0.1003 - val_acc: 0.4235\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0974 - acc: 0.4119 - val_loss: 0.1016 - val_acc: 0.4235\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0963 - acc: 0.4123 - val_loss: 0.1005 - val_acc: 0.4118\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0944 - acc: 0.4121 - val_loss: 0.0975 - val_acc: 0.4196\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0958 - acc: 0.4111 - val_loss: 0.1013 - val_acc: 0.4196\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0940 - acc: 0.4126 - val_loss: 0.1145 - val_acc: 0.4078\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0914 - acc: 0.4137 - val_loss: 0.0993 - val_acc: 0.4235\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0913 - acc: 0.4131 - val_loss: 0.0994 - val_acc: 0.4157\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0903 - acc: 0.4126 - val_loss: 0.0950 - val_acc: 0.4157\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0918 - acc: 0.4123 - val_loss: 0.1058 - val_acc: 0.4118\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0925 - acc: 0.4123 - val_loss: 0.0958 - val_acc: 0.4235\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0896 - acc: 0.4131 - val_loss: 0.1138 - val_acc: 0.4078\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0884 - acc: 0.4133 - val_loss: 0.1025 - val_acc: 0.4157\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0886 - acc: 0.4142 - val_loss: 0.1026 - val_acc: 0.4196\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0883 - acc: 0.4126 - val_loss: 0.1054 - val_acc: 0.4118\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0885 - acc: 0.4114 - val_loss: 0.0932 - val_acc: 0.4235\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0868 - acc: 0.4131 - val_loss: 0.0935 - val_acc: 0.4196\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0857 - acc: 0.4131 - val_loss: 0.1012 - val_acc: 0.4196\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0860 - acc: 0.4135 - val_loss: 0.1031 - val_acc: 0.4118\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0834 - acc: 0.4144 - val_loss: 0.0952 - val_acc: 0.4235\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0840 - acc: 0.4140 - val_loss: 0.0935 - val_acc: 0.4157\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0829 - acc: 0.4144 - val_loss: 0.0911 - val_acc: 0.4235\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0813 - acc: 0.4154 - val_loss: 0.0968 - val_acc: 0.4235\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0834 - acc: 0.4138 - val_loss: 0.0968 - val_acc: 0.4196\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0809 - acc: 0.4152 - val_loss: 0.0956 - val_acc: 0.4157\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0804 - acc: 0.4144 - val_loss: 0.0949 - val_acc: 0.4118\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0812 - acc: 0.4145 - val_loss: 0.0867 - val_acc: 0.4275\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0791 - acc: 0.4144 - val_loss: 0.0941 - val_acc: 0.4196\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0790 - acc: 0.4149 - val_loss: 0.1051 - val_acc: 0.4196\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0801 - acc: 0.4147 - val_loss: 0.0925 - val_acc: 0.4196\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0772 - acc: 0.4152 - val_loss: 0.0857 - val_acc: 0.4275\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0784 - acc: 0.4154 - val_loss: 0.0942 - val_acc: 0.4157\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0761 - acc: 0.4159 - val_loss: 0.0865 - val_acc: 0.4235\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0759 - acc: 0.4151 - val_loss: 0.1042 - val_acc: 0.4196\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0769 - acc: 0.4149 - val_loss: 0.0864 - val_acc: 0.4196\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0748 - acc: 0.4156 - val_loss: 0.0965 - val_acc: 0.4157\n",
            "Train on 340 samples, validate on 15 samples\n",
            "Epoch 1/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0744 - acc: 0.4151 - val_loss: 0.0900 - val_acc: 0.4353\n",
            "Epoch 2/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0755 - acc: 0.4144 - val_loss: 0.0786 - val_acc: 0.4431\n",
            "Epoch 3/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0739 - acc: 0.4138 - val_loss: 0.0798 - val_acc: 0.4471\n",
            "Epoch 4/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0734 - acc: 0.4152 - val_loss: 0.0890 - val_acc: 0.4392\n",
            "Epoch 5/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0727 - acc: 0.4152 - val_loss: 0.0988 - val_acc: 0.4353\n",
            "Epoch 6/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0711 - acc: 0.4154 - val_loss: 0.0831 - val_acc: 0.4392\n",
            "Epoch 7/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0710 - acc: 0.4157 - val_loss: 0.0803 - val_acc: 0.4471\n",
            "Epoch 8/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0705 - acc: 0.4163 - val_loss: 0.0810 - val_acc: 0.4471\n",
            "Epoch 9/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0697 - acc: 0.4156 - val_loss: 0.0845 - val_acc: 0.4392\n",
            "Epoch 10/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0714 - acc: 0.4154 - val_loss: 0.0951 - val_acc: 0.4392\n",
            "Epoch 11/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0692 - acc: 0.4152 - val_loss: 0.0872 - val_acc: 0.4471\n",
            "Epoch 12/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0680 - acc: 0.4168 - val_loss: 0.0908 - val_acc: 0.4353\n",
            "Epoch 13/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0679 - acc: 0.4171 - val_loss: 0.0805 - val_acc: 0.4471\n",
            "Epoch 14/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0689 - acc: 0.4166 - val_loss: 0.0775 - val_acc: 0.4471\n",
            "Epoch 15/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0677 - acc: 0.4164 - val_loss: 0.0786 - val_acc: 0.4471\n",
            "Epoch 16/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0657 - acc: 0.4173 - val_loss: 0.0985 - val_acc: 0.4353\n",
            "Epoch 17/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0662 - acc: 0.4157 - val_loss: 0.0891 - val_acc: 0.4314\n",
            "Epoch 18/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0662 - acc: 0.4157 - val_loss: 0.0855 - val_acc: 0.4431\n",
            "Epoch 19/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0675 - acc: 0.4152 - val_loss: 0.0857 - val_acc: 0.4392\n",
            "Epoch 20/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0645 - acc: 0.4171 - val_loss: 0.0888 - val_acc: 0.4353\n",
            "Epoch 21/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0641 - acc: 0.4178 - val_loss: 0.0814 - val_acc: 0.4431\n",
            "Epoch 22/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0637 - acc: 0.4180 - val_loss: 0.0838 - val_acc: 0.4471\n",
            "Epoch 23/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0645 - acc: 0.4170 - val_loss: 0.1007 - val_acc: 0.4314\n",
            "Epoch 24/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0625 - acc: 0.4180 - val_loss: 0.0771 - val_acc: 0.4510\n",
            "Epoch 25/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0614 - acc: 0.4182 - val_loss: 0.0885 - val_acc: 0.4392\n",
            "Epoch 26/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0631 - acc: 0.4176 - val_loss: 0.0822 - val_acc: 0.4431\n",
            "Epoch 27/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0612 - acc: 0.4171 - val_loss: 0.0764 - val_acc: 0.4471\n",
            "Epoch 28/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0597 - acc: 0.4182 - val_loss: 0.0891 - val_acc: 0.4431\n",
            "Epoch 29/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0610 - acc: 0.4178 - val_loss: 0.0901 - val_acc: 0.4314\n",
            "Epoch 30/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0614 - acc: 0.4171 - val_loss: 0.1055 - val_acc: 0.4196\n",
            "Epoch 31/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0578 - acc: 0.4189 - val_loss: 0.0848 - val_acc: 0.4431\n",
            "Epoch 32/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0596 - acc: 0.4175 - val_loss: 0.0801 - val_acc: 0.4510\n",
            "Epoch 33/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0595 - acc: 0.4180 - val_loss: 0.0786 - val_acc: 0.4431\n",
            "Epoch 34/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0583 - acc: 0.4185 - val_loss: 0.0770 - val_acc: 0.4431\n",
            "Epoch 35/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0575 - acc: 0.4176 - val_loss: 0.0934 - val_acc: 0.4314\n",
            "Epoch 36/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0580 - acc: 0.4180 - val_loss: 0.0876 - val_acc: 0.4392\n",
            "Epoch 37/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0564 - acc: 0.4187 - val_loss: 0.0980 - val_acc: 0.4353\n",
            "Epoch 38/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0565 - acc: 0.4190 - val_loss: 0.0821 - val_acc: 0.4392\n",
            "Epoch 39/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0557 - acc: 0.4183 - val_loss: 0.0898 - val_acc: 0.4353\n",
            "Epoch 40/40\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0552 - acc: 0.4190 - val_loss: 0.0839 - val_acc: 0.4431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy6g62mHBF5M",
        "colab_type": "code",
        "outputId": "a09a62b5-1b6c-461d-f2b6-47fda99d52ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print([\"%.4f\" % d for d in avg_acc_after_exfty_2])\n",
        "print([\"%.4f\" % d for d in bleu_after_exfty_2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0.1785', '0.1957', '0.1919', '0.1864', '0.1840', '0.1829', '0.1814', '0.1800', '0.1805', '0.1812']\n",
            "['0.4775', '0.4410', '0.4025', '0.4046', '0.4142', '0.4044', '0.3938', '0.3837', '0.3837', '0.3758']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BNtsMRXgzL5",
        "colab_type": "code",
        "outputId": "a6766cb9-a699-4ad2-9355-bb3c007c32b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "## Evaluate the first example:\n",
        "\n",
        "print(\"Encoder inputs:\")\n",
        "print(encoder_test[14])\n",
        "print(\"Decoder outputs:\")\n",
        "print(decoder_after_exfty_test[14])\n",
        "print(\"Predicted decoder:\")\n",
        "for x in range(14,150,15):\n",
        "  print(pred_after_exfty_2[x])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder inputs:\n",
            "['ws', '30%', 'jp', '70%', 'jp', 'global sourcing', 'ws', 'china']\n",
            "Decoder outputs:\n",
            "['jp', 'global sourcing', '70%', 'ws', 'china', '30%']\n",
            "Predicted decoder:\n",
            "['jp', 'global sourcing', 'ws', 'ws', 'china', 'china', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['jp', 'global sourcing', '70%', 'ws', 'china', '30%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '0%', '0%', '0%', '0%', '0%']\n",
            "['jp', 'global sourcing', '70%', 'ws', 'china', '70%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '0%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['jp', 'global sourcing', '30%', 'ws', 'china', '70%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['jp', 'global sourcing', '30%', 'ws', 'china', '70%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['jp', 'global sourcing', '30%', 'ws', 'china', '30%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['jp', 'global sourcing', '30%', 'ws', 'china', '30%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['jp', 'global sourcing', '30%', 'ws', 'china', '30%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['jp', 'global sourcing', '30%', 'ws', 'china', '70%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['jp', 'global sourcing', '30%', 'ws', 'china', '30%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLHgBU94lcVQ",
        "colab_type": "code",
        "outputId": "31c89ee0-5bcd-48e2-b8f6-f60459d03694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "## Evaluate the second example:\n",
        "\n",
        "print(\"Encoder inputs:\")\n",
        "print(encoder_test[10])\n",
        "print(\"Decoder outputs:\")\n",
        "print(decoder_after_exfty_test[10])\n",
        "print(\"Predicted decoder:\")\n",
        "for x in range(10,150,15):\n",
        "  print(pred_after_exfty_2[x])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder inputs:\n",
            "['dream', 'dual', 'with', 'plush', 'mb', 'china', 'plush', 'global sourcing', 'dream', 'global sourcing']\n",
            "Decoder outputs:\n",
            "['mb', 'china', '0%', 'plush', 'global sourcing', '50%', 'dream', 'global sourcing', '50%']\n",
            "Predicted decoder:\n",
            "['mp', 'global sourcing', 'global sourcing', 'china', 'china', 'global sourcing', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['mp', 'global sourcing', '50%', 'wf', 'china', '50%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['mp', 'global sourcing', '50%', 'wf', 'china', '50%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['rs (vietnam)', 'global sourcing', '50%', 'plush', 'global sourcing', '50%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['dream', 'global sourcing', '50%', 'plush', 'global sourcing', '50%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['dream', 'global sourcing', '50%', 'plush', 'global sourcing', '50%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['dream', 'global sourcing', '50%', 'plush', 'global sourcing', '50%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['dream', 'global sourcing', '0%', 'plush', 'global sourcing', '50%', '<EOS>', '<EOS>', '0%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['dream', 'global sourcing', '0%', 'plush', 'global sourcing', '50%', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "['dream', 'global sourcing', '0%', 'plush', 'global sourcing', '50%', '<EOS>', '<EOS>', 'global sourcing', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}